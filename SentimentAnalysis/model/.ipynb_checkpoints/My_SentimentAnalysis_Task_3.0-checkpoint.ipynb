{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58247fa5",
   "metadata": {},
   "source": [
    "# 自己的情感分析任务\n",
    "针对自己的数据集的情感分析任务，加载之前训练好的预训练模型，用自己的游记文本数据再次训练模型，学习游记文本中的语义\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e86045",
   "metadata": {},
   "source": [
    "## 参数设置和变量设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8853e2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/home/chenli/pre_model/checkpoint-14400/\"\n",
    "batch_size = 2 # 每一批次的数量\n",
    "num_labels = 2 # 多少分类，这里是二分类问题，积极和消极\n",
    "output_dir = \"/home/chenli/pre_model/20221112\" # 模型保存路径\n",
    "learning_rate = 1e-5 # 学习率\n",
    "num_train_epochs = 10 # 训练轮次"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53b1920",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0705a5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import load_from_disk\n",
    "# 加载一个评估标准，默认的评估标准\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5197142e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5602383f9cde0ea3\n",
      "Reusing dataset csv (/home/chenli/.cache/huggingface/datasets/csv/default-5602383f9cde0ea3/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n",
      "Using custom data configuration default-062c84d526dcea84\n",
      "Reusing dataset csv (/home/chenli/.cache/huggingface/datasets/csv/default-062c84d526dcea84/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n",
      "Using custom data configuration default-0f8395db45727ded\n",
      "Reusing dataset csv (/home/chenli/.cache/huggingface/datasets/csv/default-0f8395db45727ded/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset('csv',data_files='../data/MyDataset/data2/train_dataset.csv',split='train')\n",
    "valid_dataset = load_dataset('csv',data_files='../data/MyDataset/data2/valid_dataset.csv',split='train')\n",
    "test_dataset = load_dataset('csv',data_files='../data/MyDataset/data2/test_dataset.csv',split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db2c35d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 2755\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1c86c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ea500be2064ab6ae8ccf1fd43f94d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/1.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Metric(name: \"glue\", features: {'predictions': Value(dtype='int64', id=None), 'references': Value(dtype='int64', id=None)}, usage: \"\"\"\n",
       "Compute GLUE evaluation metric associated to each GLUE dataset.\n",
       "Args:\n",
       "    predictions: list of predictions to score.\n",
       "        Each translation should be tokenized into a list of tokens.\n",
       "    references: list of lists of references for each translation.\n",
       "        Each reference should be tokenized into a list of tokens.\n",
       "Returns: depending on the GLUE subset, one or several of:\n",
       "    \"accuracy\": Accuracy\n",
       "    \"f1\": F1 score\n",
       "    \"pearson\": Pearson Correlation\n",
       "    \"spearmanr\": Spearman Correlation\n",
       "    \"matthews_correlation\": Matthew Correlation\n",
       "Examples:\n",
       "\n",
       "    >>> glue_metric = datasets.load_metric('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'accuracy': 1.0}\n",
       "\n",
       "    >>> glue_metric = datasets.load_metric('glue', 'mrpc')  # 'mrpc' or 'qqp'\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'accuracy': 1.0, 'f1': 1.0}\n",
       "\n",
       "    >>> glue_metric = datasets.load_metric('glue', 'stsb')\n",
       "    >>> references = [0., 1., 2., 3., 4., 5.]\n",
       "    >>> predictions = [0., 1., 2., 3., 4., 5.]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n",
       "    {'pearson': 1.0, 'spearmanr': 1.0}\n",
       "\n",
       "    >>> glue_metric = datasets.load_metric('glue', 'cola')\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'matthews_correlation': 1.0}\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = load_metric(\"glue\",\"mrpc\")\n",
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2edcd8",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40a068b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "# 加载分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60dc166c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='/home/chenli/pre_model/checkpoint-14400/', vocab_size=21128, model_max_len=4096, is_fast=True, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc684d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分词\n",
    "def preprocess_function(data):\n",
    "    return tokenizer(data['text'],padding='max_length',max_length=1500,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5597ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/chenli/.cache/huggingface/datasets/csv/default-5602383f9cde0ea3/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-748542c6017cdd78.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 2755\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_dataset = train_dataset.map(function=preprocess_function,\n",
    "                     batched=True,\n",
    "                     remove_columns=['text'])\n",
    "encoded_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29a266cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded_train_dataset[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29251d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 2755\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the label column to labels because the model expects the argument to be named labels\n",
    "encoded_train_dataset = encoded_train_dataset.rename_column(\"label\", \"labels\")\n",
    "encoded_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7cc554a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f186335c279411199a836eb4e394cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 344\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_valid_dataset = valid_dataset.map(function=preprocess_function,\n",
    "                     batched=True,\n",
    "                     remove_columns=['text'])\n",
    "encoded_valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6f76094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 344\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the label column to labels because the model expects the argument to be named labels\n",
    "encoded_valid_dataset = encoded_valid_dataset.rename_column(\"label\", \"labels\")\n",
    "encoded_valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4744236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/chenli/.cache/huggingface/datasets/csv/default-0f8395db45727ded/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-8755639d5d2841f2.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 345\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_test_dataset = test_dataset.map(function=preprocess_function,\n",
    "                     batched=True,\n",
    "                     remove_columns=['text'])\n",
    "encoded_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3333cf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 345\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename the label column to labels because the model expects the argument to be named labels\n",
    "encoded_test_dataset = encoded_test_dataset.rename_column(\"label\", \"labels\")\n",
    "encoded_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629eb9b6",
   "metadata": {},
   "source": [
    "## 微调预训练模型\n",
    "针对自己数据集进行微调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e40647e",
   "metadata": {},
   "source": [
    "是这样加载模型吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c078bb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(4096, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')\n",
    "# 加载原始模型\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir, num_labels=num_labels)\n",
    "model.to(device)\n",
    "# 启动模型\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbb5614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch\n",
    "metric_name = \"accuracy\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate = learning_rate,\n",
    "    weight_decay=0.01,\n",
    "    #save_strategy = \"epoch\",\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    num_train_epochs = num_train_epochs,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb3541a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_metrics(eval_preds):\n",
    "    metric = load_metric('glue','mrpc')\n",
    "    logits,labels = eval_preds # 预测值和真实值\n",
    "    predictions = np.argmax(logits,axis=-1)\n",
    "    return metric.compute(predictions=predictions,references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbae1bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c475067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20c7be1f",
   "metadata": {},
   "source": [
    "## 训练前先评估一下"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b14213",
   "metadata": {},
   "source": [
    "### 20221111 训练前评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "edf844bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 236\n",
      "  Batch size = 2\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='146' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 12:19:47]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Mon Nov  7 19:47:24 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.103043794631958,\n",
       " 'eval_accuracy': 0.6059322033898306,\n",
       " 'eval_f1': 0.6618181818181819,\n",
       " 'eval_runtime': 4249.1272,\n",
       " 'eval_samples_per_second': 0.056,\n",
       " 'eval_steps_per_second': 0.028}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a36a47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='356' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 04:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.2056150436401367,\n",
       " 'eval_accuracy': 0.5932203389830508,\n",
       " 'eval_f1': 0.6444444444444445,\n",
       " 'eval_runtime': 56.4997,\n",
       " 'eval_samples_per_second': 4.177}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20221111 GPU服务器评估的\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c4ab34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Fri Nov 11 21:04:53 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.3177285194396973,\n",
       " 'eval_accuracy': 0.5654008438818565,\n",
       " 'eval_f1': 0.6308243727598566,\n",
       " 'eval_runtime': 154.2689,\n",
       " 'eval_samples_per_second': 1.536}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=encoded_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9087d413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(output_dir=/home/chenli/pre_model/20221111, overwrite_output_dir=False, do_train=False, do_eval=None, do_predict=False, evaluation_strategy=EvaluationStrategy.EPOCH, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=1, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_steps=0, logging_dir=runs/Nov11_21-53-03_yuanshan-ai01, logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=/home/chenli/pre_model/20221111, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model=accuracy, greater_is_better=True, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, _n_gpu=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型训练参数\n",
    "trainer.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de20a76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 1.7803435 , -1.6993524 ],\n",
       "       [ 4.3600445 , -3.9928086 ],\n",
       "       [-4.6731315 ,  4.2382636 ],\n",
       "       [ 4.312089  , -3.9896758 ],\n",
       "       [ 4.4367046 , -4.036243  ],\n",
       "       [-2.7386227 ,  2.8976026 ],\n",
       "       [ 4.208422  , -3.7916079 ],\n",
       "       [ 3.5128722 , -3.1391063 ],\n",
       "       [-4.6174827 ,  4.064423  ],\n",
       "       [-3.6724384 ,  3.6719346 ],\n",
       "       [ 4.358325  , -4.000134  ],\n",
       "       [ 3.9915786 , -3.4594805 ],\n",
       "       [ 4.39191   , -4.031818  ],\n",
       "       [ 4.391055  , -4.0118213 ],\n",
       "       [ 4.3339343 , -3.972685  ],\n",
       "       [-4.1531625 ,  3.919069  ],\n",
       "       [-4.3742166 ,  4.0700526 ],\n",
       "       [-3.2580388 ,  3.0946445 ],\n",
       "       [ 4.2600293 , -3.928056  ],\n",
       "       [-3.8968449 ,  3.7068942 ],\n",
       "       [-4.570051  ,  4.1923323 ],\n",
       "       [ 3.8919013 , -3.378051  ],\n",
       "       [-3.1564581 ,  3.230141  ],\n",
       "       [ 4.248337  , -3.8271031 ],\n",
       "       [ 4.4168496 , -4.0184016 ],\n",
       "       [ 4.24119   , -3.8115687 ],\n",
       "       [-3.855914  ,  3.646643  ],\n",
       "       [-4.349819  ,  4.0877843 ],\n",
       "       [-3.7773728 ,  3.669451  ],\n",
       "       [-3.1205604 ,  3.199963  ],\n",
       "       [ 4.081823  , -3.645878  ],\n",
       "       [-2.688467  ,  2.8713672 ],\n",
       "       [-4.4783254 ,  4.158961  ],\n",
       "       [-2.1885705 ,  2.1502666 ],\n",
       "       [-4.2449903 ,  3.9101512 ],\n",
       "       [-3.5609987 ,  3.3131256 ],\n",
       "       [ 4.196552  , -3.835253  ],\n",
       "       [ 4.443821  , -4.030415  ],\n",
       "       [ 3.3606641 , -2.8774703 ],\n",
       "       [ 4.23875   , -3.9002154 ],\n",
       "       [ 4.3383145 , -3.9822013 ],\n",
       "       [ 3.4232557 , -3.0316114 ],\n",
       "       [ 3.9104717 , -3.456058  ],\n",
       "       [ 4.279405  , -3.88988   ],\n",
       "       [ 4.258846  , -3.82889   ],\n",
       "       [-4.3324394 ,  3.961674  ],\n",
       "       [ 1.4638594 , -1.371602  ],\n",
       "       [ 2.9862685 , -2.63987   ],\n",
       "       [ 4.2027855 , -3.8029861 ],\n",
       "       [-2.4903514 ,  2.5087829 ],\n",
       "       [ 4.3218784 , -3.976267  ],\n",
       "       [ 4.265785  , -3.9466143 ],\n",
       "       [ 3.6958733 , -3.429314  ],\n",
       "       [-4.3335915 ,  4.015753  ],\n",
       "       [-3.4371247 ,  3.207609  ],\n",
       "       [ 4.3802156 , -4.030026  ],\n",
       "       [ 4.2926006 , -3.9382296 ],\n",
       "       [ 4.2356296 , -3.8651373 ],\n",
       "       [ 4.349096  , -3.994262  ],\n",
       "       [ 4.356226  , -3.9911835 ],\n",
       "       [-3.7298646 ,  3.495754  ],\n",
       "       [ 4.2302814 , -3.8104942 ],\n",
       "       [-4.83055   ,  4.314982  ],\n",
       "       [-4.455824  ,  4.0588245 ],\n",
       "       [ 4.211925  , -3.8191533 ],\n",
       "       [ 4.413906  , -4.0163393 ],\n",
       "       [ 3.536331  , -3.151901  ],\n",
       "       [-3.735315  ,  3.6870735 ],\n",
       "       [ 4.3059163 , -3.961679  ],\n",
       "       [-0.04680511, -0.06409752],\n",
       "       [ 4.3913445 , -4.0393243 ],\n",
       "       [ 4.300016  , -3.9450333 ],\n",
       "       [ 4.353583  , -4.024248  ],\n",
       "       [ 4.4310474 , -4.0362787 ],\n",
       "       [ 4.3129673 , -3.898474  ],\n",
       "       [ 4.426547  , -4.0307617 ],\n",
       "       [-4.6966643 ,  4.207047  ],\n",
       "       [-3.5860615 ,  3.4016545 ],\n",
       "       [-4.4914303 ,  4.1407714 ],\n",
       "       [ 4.129226  , -3.7342665 ],\n",
       "       [ 3.989365  , -3.5458786 ],\n",
       "       [ 4.351626  , -3.941715  ],\n",
       "       [ 4.297815  , -3.9502308 ],\n",
       "       [ 4.3757076 , -3.9821813 ],\n",
       "       [-4.282827  ,  3.9570875 ],\n",
       "       [-4.1449285 ,  3.9002779 ],\n",
       "       [ 4.3101077 , -3.9439507 ],\n",
       "       [-3.6775842 ,  3.6033807 ],\n",
       "       [-4.049599  ,  3.762518  ],\n",
       "       [ 4.048241  , -3.5955307 ],\n",
       "       [-3.9952269 ,  3.7621346 ],\n",
       "       [ 4.3083277 , -3.9313412 ],\n",
       "       [-3.9208622 ,  3.6889086 ],\n",
       "       [-4.042515  ,  3.6862183 ],\n",
       "       [-2.7496035 ,  2.77498   ],\n",
       "       [ 4.308334  , -3.944144  ],\n",
       "       [ 4.4155335 , -4.024587  ],\n",
       "       [-4.890299  ,  4.3386693 ],\n",
       "       [-3.8049748 ,  3.4210355 ],\n",
       "       [-4.77479   ,  4.2739077 ],\n",
       "       [ 4.255678  , -3.8988254 ],\n",
       "       [-2.912656  ,  2.976585  ],\n",
       "       [-4.356049  ,  3.9195707 ],\n",
       "       [-4.76658   ,  4.1832404 ],\n",
       "       [-4.404716  ,  4.0573134 ],\n",
       "       [-3.4735103 ,  3.336388  ],\n",
       "       [ 4.3423843 , -3.9858518 ],\n",
       "       [ 3.694723  , -3.3498764 ],\n",
       "       [-3.3382201 ,  3.3469956 ],\n",
       "       [ 4.332284  , -4.002211  ],\n",
       "       [ 4.3057504 , -3.9146714 ],\n",
       "       [ 4.2713323 , -3.8909793 ],\n",
       "       [ 4.3366256 , -4.0008025 ],\n",
       "       [-4.836232  ,  4.319345  ],\n",
       "       [ 4.082255  , -3.6415176 ],\n",
       "       [-3.9837236 ,  3.7215078 ],\n",
       "       [ 4.183315  , -3.768484  ],\n",
       "       [ 4.235906  , -3.874547  ],\n",
       "       [ 4.336362  , -3.9040377 ],\n",
       "       [ 4.3430333 , -3.9645905 ],\n",
       "       [ 4.391114  , -3.9665742 ],\n",
       "       [ 4.340719  , -3.9861944 ],\n",
       "       [ 4.3684134 , -3.995751  ],\n",
       "       [-4.2232046 ,  3.8715067 ],\n",
       "       [-3.196983  ,  3.1464899 ],\n",
       "       [-4.659967  ,  4.202045  ],\n",
       "       [-2.7225728 ,  2.7717006 ],\n",
       "       [ 2.9867291 , -2.7537425 ],\n",
       "       [-3.9262328 ,  3.752784  ],\n",
       "       [-4.6772046 ,  4.1772604 ],\n",
       "       [-4.1220155 ,  3.7313154 ],\n",
       "       [ 4.4158683 , -4.039524  ],\n",
       "       [-4.7533197 ,  4.242789  ],\n",
       "       [ 4.3645186 , -3.9994977 ],\n",
       "       [ 4.321655  , -3.9623368 ],\n",
       "       [ 4.2861986 , -3.9888217 ],\n",
       "       [ 4.130302  , -3.7408414 ],\n",
       "       [ 4.361277  , -4.019162  ],\n",
       "       [-4.094893  ,  3.6502109 ],\n",
       "       [ 4.129719  , -3.6361072 ],\n",
       "       [ 3.7434068 , -3.5166762 ],\n",
       "       [ 3.9670455 , -3.6067843 ],\n",
       "       [ 4.217436  , -3.8127322 ],\n",
       "       [ 4.3932114 , -4.0143304 ],\n",
       "       [ 4.2896695 , -3.854265  ],\n",
       "       [ 4.3545117 , -4.011206  ],\n",
       "       [ 3.570171  , -3.1311696 ],\n",
       "       [-4.7424874 ,  4.2609053 ],\n",
       "       [-2.815174  ,  2.8937328 ],\n",
       "       [-3.474036  ,  3.5149548 ],\n",
       "       [ 4.470061  , -4.0281935 ],\n",
       "       [-4.366202  ,  4.0203586 ],\n",
       "       [-3.9663324 ,  3.7988403 ],\n",
       "       [-4.550533  ,  4.2322507 ],\n",
       "       [-4.1073346 ,  3.7979639 ],\n",
       "       [ 4.254929  , -3.9311378 ],\n",
       "       [ 4.037009  , -3.5856693 ],\n",
       "       [ 4.288916  , -3.9383945 ],\n",
       "       [ 4.287019  , -3.9158723 ],\n",
       "       [ 4.3127446 , -4.0030885 ],\n",
       "       [-4.1498866 ,  3.8169448 ],\n",
       "       [-4.411944  ,  4.093803  ],\n",
       "       [-1.6742349 ,  1.7773906 ],\n",
       "       [-2.0139904 ,  2.2010822 ],\n",
       "       [ 4.4056935 , -4.0469985 ],\n",
       "       [ 3.004318  , -2.7053094 ],\n",
       "       [ 4.3628235 , -4.006916  ],\n",
       "       [-4.3753705 ,  3.968937  ],\n",
       "       [-4.1280594 ,  3.9502048 ],\n",
       "       [ 3.9033704 , -3.4792426 ],\n",
       "       [ 4.399377  , -4.0129857 ],\n",
       "       [ 4.29693   , -3.9304907 ],\n",
       "       [-4.8092694 ,  4.3049893 ],\n",
       "       [ 4.237496  , -3.8829424 ],\n",
       "       [ 4.302646  , -3.9662557 ],\n",
       "       [ 4.419136  , -3.9917405 ],\n",
       "       [ 4.3941236 , -3.974374  ],\n",
       "       [-4.419554  ,  4.01723   ],\n",
       "       [-4.5512514 ,  4.061181  ],\n",
       "       [-4.3538613 ,  4.0130258 ],\n",
       "       [ 3.0456028 , -3.1879587 ],\n",
       "       [ 4.46706   , -4.0614834 ],\n",
       "       [-0.968505  ,  1.1221014 ],\n",
       "       [ 4.4438643 , -4.0403733 ],\n",
       "       [-2.4315119 ,  2.6103194 ],\n",
       "       [-4.6531453 ,  4.145009  ],\n",
       "       [ 3.2945995 , -2.8183038 ],\n",
       "       [-4.1346025 ,  3.9035542 ],\n",
       "       [ 1.6324024 , -1.5514375 ],\n",
       "       [ 4.388519  , -4.012641  ],\n",
       "       [ 3.8517637 , -3.5007584 ],\n",
       "       [-3.1562848 ,  3.1636713 ],\n",
       "       [-4.139005  ,  3.80661   ],\n",
       "       [ 4.3067956 , -3.9831946 ],\n",
       "       [-4.849453  ,  4.324962  ],\n",
       "       [-3.7281008 ,  3.4629653 ],\n",
       "       [ 4.436775  , -4.0292153 ],\n",
       "       [ 4.461067  , -4.046144  ],\n",
       "       [ 4.3737783 , -4.006466  ],\n",
       "       [ 4.2959833 , -3.959595  ],\n",
       "       [-4.542182  ,  4.1686172 ],\n",
       "       [ 4.31106   , -3.9548984 ],\n",
       "       [ 4.2245483 , -3.8113086 ],\n",
       "       [-1.4437438 ,  1.8580703 ],\n",
       "       [ 4.287532  , -3.926478  ],\n",
       "       [ 4.2832336 , -3.8269613 ],\n",
       "       [-4.1770215 ,  3.8939922 ],\n",
       "       [ 4.3076644 , -3.9590194 ],\n",
       "       [ 4.049111  , -3.65276   ],\n",
       "       [ 4.3117647 , -3.9888024 ],\n",
       "       [-3.4957967 ,  3.1310344 ],\n",
       "       [ 4.032947  , -3.6614423 ],\n",
       "       [ 4.168023  , -3.7528517 ],\n",
       "       [ 4.4393106 , -4.024273  ],\n",
       "       [-4.2705393 ,  3.866212  ],\n",
       "       [ 4.078304  , -3.7399986 ],\n",
       "       [ 4.3556485 , -3.9943793 ],\n",
       "       [-3.6383026 ,  3.4336534 ],\n",
       "       [ 3.396032  , -3.0359979 ],\n",
       "       [ 3.9604952 , -3.562281  ],\n",
       "       [ 4.3247375 , -3.983765  ],\n",
       "       [-4.4193015 ,  3.9609623 ],\n",
       "       [ 4.3643823 , -4.002306  ],\n",
       "       [ 4.3566604 , -3.9772184 ],\n",
       "       [-4.6469035 ,  4.2096214 ],\n",
       "       [ 4.3719487 , -3.9977467 ],\n",
       "       [-4.032985  ,  3.700679  ],\n",
       "       [ 4.32256   , -4.0113225 ],\n",
       "       [-4.420606  ,  4.0818853 ],\n",
       "       [ 4.3190885 , -3.9434168 ],\n",
       "       [ 4.3233657 , -3.962151  ],\n",
       "       [ 4.1373653 , -3.7236173 ],\n",
       "       [ 4.3645167 , -4.0167413 ],\n",
       "       [ 4.250067  , -3.841966  ],\n",
       "       [-4.3198028 ,  4.041604  ],\n",
       "       [ 3.9949872 , -3.5859573 ],\n",
       "       [ 4.001056  , -3.5671074 ]], dtype=float32), label_ids=array([1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), metrics={'eval_loss': 3.3177285194396973, 'eval_accuracy': 0.5654008438818565, 'eval_f1': 0.6308243727598566, 'eval_runtime': 54.7296, 'eval_samples_per_second': 4.33})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(test_dataset=encoded_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f6b8de",
   "metadata": {},
   "source": [
    "### 20221111 训练后的评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b79b0ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='237' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 03:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Fri Nov 11 21:04:53 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9832331538200378,\n",
       " 'eval_accuracy': 0.7542372881355932,\n",
       " 'eval_f1': 0.8599033816425121,\n",
       " 'eval_runtime': 131.7387,\n",
       " 'eval_samples_per_second': 1.791,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20221111 GPU服务器评估的\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e28e06e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.879255473613739,\n",
       " 'eval_accuracy': 0.7805907172995781,\n",
       " 'eval_f1': 0.8767772511848342,\n",
       " 'eval_runtime': 31.7737,\n",
       " 'eval_samples_per_second': 7.459,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=encoded_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a65f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.predict(test_dataset=encoded_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896a0f77",
   "metadata": {},
   "source": [
    "### 20221112 训练前评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c83b243c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(output_dir=/home/chenli/pre_model/20221112, overwrite_output_dir=False, do_train=False, do_eval=None, do_predict=False, evaluation_strategy=EvaluationStrategy.EPOCH, prediction_loss_only=False, per_device_train_batch_size=2, per_device_eval_batch_size=2, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_steps=0, logging_dir=runs/Nov12_13-25-32_yuanshan-ai01, logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=/home/chenli/pre_model/20221112, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model=accuracy, greater_is_better=True, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, _n_gpu=2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型训练参数\n",
    "trainer.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cba7e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='346' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 16:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Fri Nov 11 21:04:53 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.3056046962738037,\n",
       " 'eval_accuracy': 0.6831395348837209,\n",
       " 'eval_f1': 0.6784660766961652,\n",
       " 'eval_runtime': 131.928,\n",
       " 'eval_samples_per_second': 2.607}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20221112 GPU服务器评估的\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb4c294d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.5707414150238037,\n",
       " 'eval_accuracy': 0.6521739130434783,\n",
       " 'eval_f1': 0.6511627906976745,\n",
       " 'eval_runtime': 30.5454,\n",
       " 'eval_samples_per_second': 11.295}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20221112 对测试集进行评估\n",
    "trainer.evaluate(eval_dataset=encoded_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba58070d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[-3.9755266 ,  3.7398612 ],\n",
       "       [-2.1951642 ,  2.1820455 ],\n",
       "       [ 3.8285606 , -3.4650245 ],\n",
       "       [ 4.1110287 , -3.685024  ],\n",
       "       [ 4.2735567 , -3.9067492 ],\n",
       "       [-4.836384  ,  4.317507  ],\n",
       "       [-4.4138474 ,  4.0330114 ],\n",
       "       [ 1.8987294 , -2.1746373 ],\n",
       "       [-2.729421  ,  2.5207024 ],\n",
       "       [ 4.360242  , -3.958197  ],\n",
       "       [ 4.376498  , -4.011953  ],\n",
       "       [ 3.8747442 , -3.5028982 ],\n",
       "       [ 4.475733  , -4.000242  ],\n",
       "       [-4.348307  ,  4.0007772 ],\n",
       "       [ 4.107893  , -3.6853325 ],\n",
       "       [ 4.329009  , -3.9644237 ],\n",
       "       [-4.4139233 ,  3.9566133 ],\n",
       "       [ 3.904513  , -3.576008  ],\n",
       "       [ 4.384933  , -4.024852  ],\n",
       "       [-4.8293667 ,  4.4141774 ],\n",
       "       [ 2.49205   , -2.5287247 ],\n",
       "       [-4.880908  ,  4.32991   ],\n",
       "       [ 2.4057236 , -2.498466  ],\n",
       "       [-4.8401446 ,  4.332661  ],\n",
       "       [-2.7338622 ,  2.6253526 ],\n",
       "       [ 4.3459554 , -3.9959042 ],\n",
       "       [ 4.469338  , -4.064098  ],\n",
       "       [-4.339988  ,  3.9662628 ],\n",
       "       [ 0.78480726, -1.1528686 ],\n",
       "       [-2.428773  ,  2.315261  ],\n",
       "       [-4.3846707 ,  3.9819937 ],\n",
       "       [ 4.2852287 , -3.9695792 ],\n",
       "       [ 4.5098886 , -4.069846  ],\n",
       "       [ 4.201258  , -3.778131  ],\n",
       "       [-3.587509  ,  3.3792467 ],\n",
       "       [-4.0281863 ,  3.8145802 ],\n",
       "       [-4.416807  ,  4.0348034 ],\n",
       "       [ 4.4872556 , -4.0474405 ],\n",
       "       [-4.6203814 ,  4.1945763 ],\n",
       "       [ 4.3287635 , -3.957077  ],\n",
       "       [-4.3903794 ,  3.9495053 ],\n",
       "       [ 4.313895  , -3.974052  ],\n",
       "       [-3.1010032 ,  3.0865867 ],\n",
       "       [ 4.473655  , -4.070931  ],\n",
       "       [ 4.4159217 , -4.033653  ],\n",
       "       [ 4.4416127 , -3.9701293 ],\n",
       "       [-4.342452  ,  3.9333591 ],\n",
       "       [ 4.2674847 , -3.9009268 ],\n",
       "       [-4.826101  ,  4.2882066 ],\n",
       "       [-2.4027727 ,  2.211988  ],\n",
       "       [ 4.122243  , -3.6695032 ],\n",
       "       [-3.6373837 ,  3.4603648 ],\n",
       "       [ 4.3322453 , -3.9240043 ],\n",
       "       [ 3.8473628 , -3.3451984 ],\n",
       "       [ 4.3772764 , -3.9660828 ],\n",
       "       [-3.9295752 ,  3.7722309 ],\n",
       "       [-2.612601  ,  2.7886813 ],\n",
       "       [ 4.3017144 , -3.9669416 ],\n",
       "       [ 4.1636405 , -3.7388577 ],\n",
       "       [ 4.251545  , -3.8497813 ],\n",
       "       [-4.4186306 ,  4.0256653 ],\n",
       "       [ 3.5047045 , -3.2779772 ],\n",
       "       [-3.4533849 ,  3.248513  ],\n",
       "       [-3.9344049 ,  3.6572692 ],\n",
       "       [-4.5765886 ,  4.0918016 ],\n",
       "       [-4.4901996 ,  4.051986  ],\n",
       "       [-4.4089622 ,  3.9631894 ],\n",
       "       [-4.531385  ,  4.1535873 ],\n",
       "       [-4.082036  ,  3.7976744 ],\n",
       "       [ 1.8398502 , -1.9566305 ],\n",
       "       [ 4.330045  , -3.9596257 ],\n",
       "       [ 4.2907777 , -3.9004788 ],\n",
       "       [-4.2367    ,  3.9052668 ],\n",
       "       [-3.5007088 ,  3.325002  ],\n",
       "       [ 4.4414124 , -4.04132   ],\n",
       "       [ 4.3301134 , -3.950992  ],\n",
       "       [ 4.3541727 , -4.0070243 ],\n",
       "       [-3.8904164 ,  3.6141305 ],\n",
       "       [ 4.220078  , -3.909099  ],\n",
       "       [-3.1513915 ,  3.224422  ],\n",
       "       [-4.582998  ,  4.0626554 ],\n",
       "       [-4.079102  ,  3.8382976 ],\n",
       "       [-3.4103012 ,  3.3707037 ],\n",
       "       [-4.6777453 ,  4.2376866 ],\n",
       "       [ 3.2170682 , -2.917953  ],\n",
       "       [ 4.3827715 , -3.9723835 ],\n",
       "       [-3.2188888 ,  3.1505659 ],\n",
       "       [ 4.3433065 , -3.9960685 ],\n",
       "       [-4.455889  ,  4.062911  ],\n",
       "       [ 4.2357955 , -3.8871615 ],\n",
       "       [-3.5717332 ,  3.32186   ],\n",
       "       [-4.479541  ,  4.091212  ],\n",
       "       [-4.5769577 ,  4.1536946 ],\n",
       "       [ 3.8520489 , -3.511444  ],\n",
       "       [-4.6360116 ,  4.3068404 ],\n",
       "       [-4.474484  ,  4.013743  ],\n",
       "       [ 4.3446374 , -3.9336352 ],\n",
       "       [ 4.245689  , -3.8201344 ],\n",
       "       [ 4.3243127 , -3.9584806 ],\n",
       "       [ 4.295712  , -3.8830802 ],\n",
       "       [-2.5708706 ,  2.3470066 ],\n",
       "       [-4.870896  ,  4.3530884 ],\n",
       "       [ 4.330566  , -4.011462  ],\n",
       "       [ 4.3287635 , -3.957077  ],\n",
       "       [-4.416281  ,  4.023634  ],\n",
       "       [ 4.25519   , -3.8638968 ],\n",
       "       [-2.3936481 ,  2.5360796 ],\n",
       "       [ 4.3628783 , -3.9443066 ],\n",
       "       [ 1.1104228 , -1.2531624 ],\n",
       "       [-4.0810256 ,  3.8347259 ],\n",
       "       [ 4.3675895 , -4.0018883 ],\n",
       "       [-4.236113  ,  3.8403409 ],\n",
       "       [ 4.448427  , -4.0381346 ],\n",
       "       [ 2.8253198 , -2.6074324 ],\n",
       "       [ 4.3064938 , -3.9571111 ],\n",
       "       [-4.6357956 ,  4.178334  ],\n",
       "       [-4.4113693 ,  3.9528134 ],\n",
       "       [-4.7201505 ,  4.291272  ],\n",
       "       [ 0.86803234, -0.8320687 ],\n",
       "       [-4.6923184 ,  4.2121005 ],\n",
       "       [ 4.2647896 , -3.8778245 ],\n",
       "       [-3.7520669 ,  3.5779703 ],\n",
       "       [ 4.224104  , -3.9134905 ],\n",
       "       [ 4.393898  , -3.9898386 ],\n",
       "       [ 4.030321  , -3.6699555 ],\n",
       "       [-4.6047273 ,  4.151035  ],\n",
       "       [ 4.344233  , -3.9751964 ],\n",
       "       [-4.380746  ,  3.8907864 ],\n",
       "       [-4.662625  ,  4.199923  ],\n",
       "       [ 4.344692  , -4.0083833 ],\n",
       "       [ 3.9795942 , -3.5468915 ],\n",
       "       [ 4.409988  , -4.0169826 ],\n",
       "       [ 4.3188853 , -3.9419394 ],\n",
       "       [-4.544433  ,  4.202408  ],\n",
       "       [ 3.9392529 , -3.5968497 ],\n",
       "       [-4.4238224 ,  4.113069  ],\n",
       "       [ 4.3575377 , -3.988082  ],\n",
       "       [-4.866872  ,  4.352917  ],\n",
       "       [ 3.966256  , -3.6244228 ],\n",
       "       [ 4.4137263 , -4.0014462 ],\n",
       "       [ 4.2899847 , -3.9678242 ],\n",
       "       [ 4.327571  , -3.9315405 ],\n",
       "       [ 4.3197017 , -3.9713056 ],\n",
       "       [ 4.4810967 , -4.0388093 ],\n",
       "       [ 4.451717  , -4.038281  ],\n",
       "       [-4.617921  ,  4.14015   ],\n",
       "       [ 4.3764005 , -3.9832864 ],\n",
       "       [ 4.2400193 , -3.8363063 ],\n",
       "       [-2.9790165 ,  2.9049764 ],\n",
       "       [ 4.3181477 , -3.9132476 ],\n",
       "       [ 4.398077  , -4.021078  ],\n",
       "       [-3.35372   ,  3.1761541 ],\n",
       "       [-3.8931007 ,  3.6528704 ],\n",
       "       [ 4.258846  , -3.82889   ],\n",
       "       [ 4.0384116 , -3.5319014 ],\n",
       "       [ 3.759616  , -3.4884927 ],\n",
       "       [-4.2171082 ,  3.9063997 ],\n",
       "       [ 4.259578  , -3.9284687 ],\n",
       "       [ 2.6381664 , -2.3901289 ],\n",
       "       [ 4.4003086 , -4.0032563 ],\n",
       "       [ 4.1729403 , -3.8052957 ],\n",
       "       [ 4.454342  , -4.005586  ],\n",
       "       [-4.024266  ,  3.6367276 ],\n",
       "       [ 4.39777   , -3.9701502 ],\n",
       "       [ 4.359868  , -4.021853  ],\n",
       "       [-4.80404   ,  4.2931724 ],\n",
       "       [-4.404716  ,  4.0573134 ],\n",
       "       [ 4.3850656 , -4.014903  ],\n",
       "       [-4.419302  ,  3.960962  ],\n",
       "       [ 4.396384  , -4.011666  ],\n",
       "       [-4.3741093 ,  3.9913065 ],\n",
       "       [ 3.8178446 , -3.4346147 ],\n",
       "       [ 4.3892784 , -4.0245724 ],\n",
       "       [ 3.189725  , -3.121323  ],\n",
       "       [ 4.2888393 , -3.9329982 ],\n",
       "       [-1.6025556 ,  1.739662  ],\n",
       "       [-4.5603333 ,  4.0403595 ],\n",
       "       [-3.1376226 ,  3.1708252 ],\n",
       "       [ 4.483677  , -4.0664196 ],\n",
       "       [ 4.485376  , -4.0684795 ],\n",
       "       [-4.6972485 ,  4.2096677 ],\n",
       "       [-4.6995635 ,  4.175603  ],\n",
       "       [-4.16815   ,  3.8146174 ],\n",
       "       [ 4.414703  , -4.010083  ],\n",
       "       [ 4.1552258 , -3.7009442 ],\n",
       "       [-2.5056324 ,  2.48736   ],\n",
       "       [ 4.430911  , -3.994312  ],\n",
       "       [-3.4957962 ,  3.1310344 ],\n",
       "       [-4.2758026 ,  4.057104  ],\n",
       "       [-2.8443055 ,  2.8255343 ],\n",
       "       [ 1.3987933 , -1.7928578 ],\n",
       "       [-4.626651  ,  4.1469173 ],\n",
       "       [-4.082036  ,  3.7976744 ],\n",
       "       [ 4.369333  , -4.019473  ],\n",
       "       [ 4.427484  , -3.9951453 ],\n",
       "       [ 0.86729157, -0.97735393],\n",
       "       [-4.2941027 ,  3.9172835 ],\n",
       "       [-4.3034368 ,  3.8703737 ],\n",
       "       [ 4.4380293 , -4.045186  ],\n",
       "       [ 3.656103  , -3.2935598 ],\n",
       "       [ 4.2326255 , -3.8938656 ],\n",
       "       [ 4.036099  , -3.6325161 ],\n",
       "       [-4.6187563 ,  4.141654  ],\n",
       "       [ 4.4217935 , -3.9435792 ],\n",
       "       [ 3.7672918 , -3.5162928 ],\n",
       "       [ 4.484748  , -4.0449786 ],\n",
       "       [ 4.1263056 , -3.8210337 ],\n",
       "       [ 4.362032  , -4.0086985 ],\n",
       "       [-3.88545   ,  3.5618618 ],\n",
       "       [-3.796052  ,  3.5620952 ],\n",
       "       [ 4.3049965 , -3.9644213 ],\n",
       "       [-4.640412  ,  4.170388  ],\n",
       "       [-4.028751  ,  3.783727  ],\n",
       "       [-4.689943  ,  4.214547  ],\n",
       "       [ 4.2337985 , -3.8880494 ],\n",
       "       [-2.7995136 ,  2.8637753 ],\n",
       "       [ 4.284223  , -3.766022  ],\n",
       "       [-4.1400933 ,  3.819983  ],\n",
       "       [ 4.3832493 , -3.9888742 ],\n",
       "       [ 4.2400193 , -3.8363063 ],\n",
       "       [ 4.425997  , -4.0239134 ],\n",
       "       [-4.865997  ,  4.3331814 ],\n",
       "       [ 4.480361  , -4.0521145 ],\n",
       "       [ 3.72415   , -3.4799547 ],\n",
       "       [-4.8644924 ,  4.2910266 ],\n",
       "       [ 1.2059258 , -1.5980363 ],\n",
       "       [-4.279819  ,  3.8555956 ],\n",
       "       [ 4.3477097 , -3.974864  ],\n",
       "       [ 4.2356844 , -3.8947809 ],\n",
       "       [ 1.3866919 , -1.3585413 ],\n",
       "       [-4.4516997 ,  4.0931563 ],\n",
       "       [ 4.389489  , -4.007385  ],\n",
       "       [-3.691655  ,  3.4046586 ],\n",
       "       [-2.5641026 ,  2.6949205 ],\n",
       "       [ 2.4716191 , -2.5825455 ],\n",
       "       [ 4.3370466 , -3.9925938 ],\n",
       "       [ 3.7753904 , -3.3734393 ],\n",
       "       [-4.799525  ,  4.3143806 ],\n",
       "       [-4.8140063 ,  4.290352  ],\n",
       "       [ 4.394323  , -3.9441984 ],\n",
       "       [-4.4732943 ,  3.9966438 ],\n",
       "       [-3.3321667 ,  3.122283  ],\n",
       "       [-4.4295387 ,  3.96466   ],\n",
       "       [ 4.4693694 , -3.9778607 ],\n",
       "       [ 4.4759808 , -4.0621295 ],\n",
       "       [ 4.309169  , -3.9761152 ],\n",
       "       [-3.2329066 ,  3.2098384 ],\n",
       "       [ 4.322056  , -3.9404895 ],\n",
       "       [-2.5700738 ,  2.5536613 ],\n",
       "       [-3.8494725 ,  3.4931972 ],\n",
       "       [-4.6433406 ,  4.1491137 ],\n",
       "       [-4.2848115 ,  3.949046  ],\n",
       "       [-2.3203392 ,  2.467854  ],\n",
       "       [-4.7375355 ,  4.255785  ],\n",
       "       [-4.5779853 ,  4.046309  ],\n",
       "       [-4.7907    ,  4.271732  ],\n",
       "       [-3.6416762 ,  3.5259292 ],\n",
       "       [ 0.34522104, -0.505179  ],\n",
       "       [-3.7796686 ,  3.5536487 ],\n",
       "       [ 4.381472  , -4.026732  ],\n",
       "       [-4.039313  ,  3.7230737 ],\n",
       "       [ 4.3424726 , -3.9199064 ],\n",
       "       [-4.715206  ,  4.1745076 ],\n",
       "       [ 4.170098  , -3.8182242 ],\n",
       "       [-4.756048  ,  4.282487  ],\n",
       "       [ 4.36035   , -4.029895  ],\n",
       "       [ 2.0370207 , -2.1621606 ],\n",
       "       [ 4.301736  , -3.9651263 ],\n",
       "       [ 4.3596163 , -4.0213757 ],\n",
       "       [-4.8793073 ,  4.363193  ],\n",
       "       [-4.032929  ,  3.8159277 ],\n",
       "       [-4.4740477 ,  4.0459375 ],\n",
       "       [-4.24264   ,  3.8848486 ],\n",
       "       [-3.8934672 ,  3.581802  ],\n",
       "       [ 4.384674  , -4.0233274 ],\n",
       "       [ 4.2042656 , -3.7468224 ],\n",
       "       [ 4.280898  , -3.9429228 ],\n",
       "       [-4.7398305 ,  4.292635  ],\n",
       "       [ 0.18112473, -0.0710817 ],\n",
       "       [-1.6654154 ,  1.5873309 ],\n",
       "       [ 4.2521152 , -3.797106  ],\n",
       "       [ 4.500057  , -4.0700493 ],\n",
       "       [-4.401783  ,  3.9713166 ],\n",
       "       [ 4.3120837 , -3.9827642 ],\n",
       "       [-4.502004  ,  4.010257  ],\n",
       "       [ 3.4852643 , -3.0423741 ],\n",
       "       [ 4.3109837 , -3.971622  ],\n",
       "       [ 4.4340787 , -4.0410237 ],\n",
       "       [-3.612708  ,  3.366068  ],\n",
       "       [-4.1380715 ,  3.828944  ],\n",
       "       [-3.0410633 ,  3.0309772 ],\n",
       "       [-4.711106  ,  4.2516284 ],\n",
       "       [-4.1655817 ,  3.8381562 ],\n",
       "       [ 4.3493505 , -3.9888122 ],\n",
       "       [-0.9447557 ,  1.039066  ],\n",
       "       [-3.2867212 ,  3.1319065 ],\n",
       "       [ 0.82376623, -1.3113916 ],\n",
       "       [ 4.3454494 , -3.9842272 ],\n",
       "       [-4.360601  ,  3.9173658 ],\n",
       "       [-3.0147874 ,  2.9388678 ],\n",
       "       [-3.6826184 ,  3.3194242 ],\n",
       "       [ 3.8542845 , -3.5633316 ],\n",
       "       [-4.539189  ,  4.052073  ],\n",
       "       [ 4.3142157 , -3.9457452 ],\n",
       "       [ 4.4520288 , -3.9895842 ],\n",
       "       [ 4.3332753 , -3.970653  ],\n",
       "       [ 4.3225904 , -3.8881094 ],\n",
       "       [ 4.0105357 , -3.587362  ],\n",
       "       [ 4.2081084 , -3.7767215 ],\n",
       "       [ 4.3836374 , -4.047409  ],\n",
       "       [ 4.2675977 , -3.927152  ],\n",
       "       [ 4.405625  , -4.028691  ],\n",
       "       [-3.560998  ,  3.313125  ],\n",
       "       [ 4.483993  , -4.0542693 ],\n",
       "       [-4.2749176 ,  3.9530587 ],\n",
       "       [ 4.431355  , -4.0291877 ],\n",
       "       [-1.9707922 ,  1.7895597 ],\n",
       "       [ 3.9994826 , -3.613612  ],\n",
       "       [-3.5640805 ,  3.4860144 ],\n",
       "       [ 4.2253256 , -3.8914964 ],\n",
       "       [ 4.255457  , -3.887861  ],\n",
       "       [ 4.3481045 , -4.0060325 ],\n",
       "       [-4.903956  ,  4.3390102 ],\n",
       "       [ 4.208333  , -3.7762556 ],\n",
       "       [ 1.7003089 , -1.8970228 ],\n",
       "       [ 4.3105364 , -3.9438043 ],\n",
       "       [ 4.3346457 , -3.9924946 ],\n",
       "       [-3.2417746 ,  3.2136228 ],\n",
       "       [ 3.8249686 , -3.4479792 ],\n",
       "       [-3.9802454 ,  3.6031284 ],\n",
       "       [ 4.5008135 , -4.0764832 ],\n",
       "       [ 4.3575506 , -3.994349  ],\n",
       "       [ 4.3994    , -3.9982548 ],\n",
       "       [ 3.6062543 , -3.3254614 ],\n",
       "       [-2.712315  ,  2.8037755 ],\n",
       "       [ 1.143421  , -1.2704233 ],\n",
       "       [ 4.315703  , -3.9745872 ],\n",
       "       [-4.8278956 ,  4.3192754 ],\n",
       "       [ 4.408843  , -4.0389895 ],\n",
       "       [ 4.367821  , -4.021868  ],\n",
       "       [ 4.31421   , -3.9682288 ],\n",
       "       [ 4.3630958 , -3.989049  ],\n",
       "       [ 4.3085866 , -3.8374825 ],\n",
       "       [ 1.0167956 , -0.7450654 ],\n",
       "       [ 4.4426713 , -4.013431  ]], dtype=float32), label_ids=array([1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0]), metrics={'eval_loss': 2.5707414150238037, 'eval_accuracy': 0.6521739130434783, 'eval_f1': 0.6511627906976745, 'eval_runtime': 30.1236, 'eval_samples_per_second': 11.453})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(test_dataset=encoded_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde28da5",
   "metadata": {},
   "source": [
    "## 20221112 训练后评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2109a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(output_dir=/home/chenli/pre_model/20221112, overwrite_output_dir=False, do_train=False, do_eval=None, do_predict=False, evaluation_strategy=EvaluationStrategy.EPOCH, prediction_loss_only=False, per_device_train_batch_size=2, per_device_eval_batch_size=2, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=1e-05, weight_decay=0.01, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_steps=0, logging_dir=runs/Nov12_13-25-32_yuanshan-ai01, logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=/home/chenli/pre_model/20221112, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model=accuracy, greater_is_better=True, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, _n_gpu=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型训练参数\n",
    "trainer.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d493aad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='173' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 03:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.13330306112766266,\n",
       " 'eval_accuracy': 0.9767441860465116,\n",
       " 'eval_f1': 0.9792746113989639,\n",
       " 'eval_runtime': 129.3818,\n",
       " 'eval_samples_per_second': 2.659,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20221112 GPU服务器评估的\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36538f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.17834007740020752,\n",
       " 'eval_accuracy': 0.9652173913043478,\n",
       " 'eval_f1': 0.9693877551020408,\n",
       " 'eval_runtime': 29.6151,\n",
       " 'eval_samples_per_second': 11.649,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20221112 对测试集进行评估\n",
    "trainer.evaluate(eval_dataset=encoded_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51c683e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93fb3e8b",
   "metadata": {},
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4171f7a",
   "metadata": {},
   "source": [
    "## 20221110 训练\n",
    "model_dir = \"/home/chenli/pre_model/20221108/checkpoint-14400/\" <br/>\n",
    "batch_size = 1 # 每一批次的数量 <br/>\n",
    "num_labels = 2 # 多少分类，这里是二分类问题，积极和消极 <br/>\n",
    "output_dir = \"/home/chenli/pre_model/20221109\" # 模型保存路径 <br/>\n",
    "num_train_epochs = 5 # 训练轮次 <br/>\n",
    "把文本统一成3000，并且batch_size=1才跑通"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e4f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenli/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1889\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9445\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1945' max='9445' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1945/9445 27:16:32 < 105:17:03, 0.02 it/s, Epoch 1.03/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.178300</td>\n",
       "      <td>1.275712</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.859903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 236\n",
      "  Batch size = 1\n",
      "/tmp/ipykernel_3676783/1844987744.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric('glue','mrpc')\n",
      "Saving model checkpoint to /home/chenli/pre_model/20221109/checkpoint-1889\n",
      "Configuration saved in /home/chenli/pre_model/20221109/checkpoint-1889/config.json\n",
      "Model weights saved in /home/chenli/pre_model/20221109/checkpoint-1889/pytorch_model.bin\n",
      "tokenizer config file saved in /home/chenli/pre_model/20221109/checkpoint-1889/tokenizer_config.json\n",
      "Special tokens file saved in /home/chenli/pre_model/20221109/checkpoint-1889/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f00723c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48d03c0d",
   "metadata": {},
   "source": [
    "## 20221111 训练\n",
    "GPU服务器训练 <br/>\n",
    "model_dir = \"/home/chenli/pre_model/checkpoint-14400/\" <br/>\n",
    "batch_size = 1 # 每一批次的数量 <br/>\n",
    "num_labels = 2 # 多少分类，这里是二分类问题，积极和消极 <br/>\n",
    "output_dir = \"/home/chenli/pre_model/20221111\" # 模型保存路径 <br/>\n",
    "learning_rate = 1e-5 # 学习率 <br/>\n",
    "num_train_epochs = 10 # 训练轮次 <br/>\n",
    "GPU 两块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c335e0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='9450' max='9450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9450/9450 2:00:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.389000</td>\n",
       "      <td>0.983233</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>132.391000</td>\n",
       "      <td>1.783000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.901600</td>\n",
       "      <td>0.895185</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>31.863500</td>\n",
       "      <td>7.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.968500</td>\n",
       "      <td>1.140204</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>134.223800</td>\n",
       "      <td>1.758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.908900</td>\n",
       "      <td>0.872491</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>32.696400</td>\n",
       "      <td>7.218000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.978200</td>\n",
       "      <td>1.101258</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>31.961800</td>\n",
       "      <td>7.384000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.986800</td>\n",
       "      <td>0.994989</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>32.087000</td>\n",
       "      <td>7.355000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.891800</td>\n",
       "      <td>1.001408</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>33.458300</td>\n",
       "      <td>7.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.009200</td>\n",
       "      <td>1.008894</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>40.936000</td>\n",
       "      <td>5.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.907700</td>\n",
       "      <td>1.028743</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>31.837900</td>\n",
       "      <td>7.413000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.990200</td>\n",
       "      <td>0.993204</td>\n",
       "      <td>0.754237</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>31.816700</td>\n",
       "      <td>7.417000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Fri Nov 11 21:04:53 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Fri Nov 11 21:04:53 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9450, training_loss=0.8838690266281208, metrics={'train_runtime': 7203.9919, 'train_samples_per_second': 1.312, 'total_flos': 23806318502640000, 'epoch': 10.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "414a2211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(output_dir=/home/chenli/pre_model/20221111, overwrite_output_dir=False, do_train=False, do_eval=None, do_predict=False, evaluation_strategy=EvaluationStrategy.EPOCH, prediction_loss_only=False, per_device_train_batch_size=1, per_device_eval_batch_size=1, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=10, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_steps=0, logging_dir=runs/Nov11_22-01-32_yuanshan-ai01, logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level=O1, fp16_backend=auto, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name=/home/chenli/pre_model/20221111, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model=accuracy, greater_is_better=True, ignore_data_skip=False, sharded_ddp=False, deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, _n_gpu=2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型训练参数\n",
    "trainer.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5ab6b",
   "metadata": {},
   "source": [
    "## 20221112 训练\n",
    "model_dir = \"/home/chenli/pre_model/checkpoint-14400/\" <br/>\n",
    "batch_size = 2 # 每一批次的数量 <br/>\n",
    "num_labels = 2 # 多少分类，这里是二分类问题，积极和消极 <br/>\n",
    "output_dir = \"/home/chenli/pre_model/20221112\" # 模型保存路径 <br/>\n",
    "learning_rate = 1e-5 # 学习率 <br/>\n",
    "weight_decay=0.01 <br/>\n",
    "num_train_epochs = 10 # 训练轮次 <br/>\n",
    "GPU两块 <br/>\n",
    "添加了消极文本数据1000篇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c1f41a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='6890' max='6890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6890/6890 1:53:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.180300</td>\n",
       "      <td>0.161894</td>\n",
       "      <td>0.973837</td>\n",
       "      <td>0.976623</td>\n",
       "      <td>30.362500</td>\n",
       "      <td>11.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.095600</td>\n",
       "      <td>0.133303</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.979275</td>\n",
       "      <td>30.606100</td>\n",
       "      <td>11.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.078700</td>\n",
       "      <td>0.184718</td>\n",
       "      <td>0.962209</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>30.930500</td>\n",
       "      <td>11.122000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.142353</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.979275</td>\n",
       "      <td>130.743900</td>\n",
       "      <td>2.631000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.143575</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.979275</td>\n",
       "      <td>129.980400</td>\n",
       "      <td>2.647000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.170800</td>\n",
       "      <td>0.970930</td>\n",
       "      <td>0.974093</td>\n",
       "      <td>30.417200</td>\n",
       "      <td>11.309000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.231094</td>\n",
       "      <td>0.970930</td>\n",
       "      <td>0.973958</td>\n",
       "      <td>32.324200</td>\n",
       "      <td>10.642000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.220399</td>\n",
       "      <td>0.973837</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>140.755800</td>\n",
       "      <td>2.444000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.244575</td>\n",
       "      <td>0.968023</td>\n",
       "      <td>0.970976</td>\n",
       "      <td>30.251900</td>\n",
       "      <td>11.371000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.219517</td>\n",
       "      <td>0.973837</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>30.570700</td>\n",
       "      <td>11.253000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Fri Nov 11 21:04:53 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Fri Nov 11 21:04:53 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Fri Nov 11 21:04:53 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6890, training_loss=0.05755438195603679, metrics={'train_runtime': 6806.2861, 'train_samples_per_second': 1.012, 'total_flos': 26040130019100000, 'epoch': 10.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87d1de0",
   "metadata": {},
   "source": [
    "## 超参数搜索\n",
    "Trainer同样支持超参搜索，使用optuna or Ray Tune代码库。\n",
    "\n",
    "反注释下面两行安装依赖："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31297f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting optuna\n",
      "  Downloading optuna-3.0.3-py3-none-any.whl (348 kB)\n",
      "\u001b[K     |████████████████████████████████| 348 kB 20 kB/s eta 0:00:012\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/anaconda/anaconda3/lib/python3.8/site-packages (from optuna) (4.63.0)\n",
      "Requirement already satisfied: PyYAML in /home/anaconda/anaconda3/lib/python3.8/site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: numpy in /home/anaconda/anaconda3/lib/python3.8/site-packages (from optuna) (1.21.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from optuna) (1.4.32)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: importlib-metadata<5.0.0 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from optuna) (4.8.2)\n",
      "Collecting cliff\n",
      "  Downloading cliff-4.0.0-py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 25 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy<1.9.0,>=1.7.0 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from optuna) (1.7.3)\n",
      "Collecting colorlog\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Downloading cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
      "Collecting alembic>=1.5.0\n",
      "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
      "\u001b[K     |████████████████████████████████| 209 kB 35 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources\n",
      "  Downloading importlib_resources-5.10.0-py3-none-any.whl (34 kB)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.2.3-py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 39 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from importlib-metadata<5.0.0->optuna) (3.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->optuna) (3.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from sqlalchemy>=1.3.0->optuna) (1.1.1)\n",
      "Collecting autopage>=0.4.0\n",
      "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
      "Collecting PrettyTable>=0.7.2\n",
      "  Downloading prettytable-3.5.0-py3-none-any.whl (26 kB)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
      "\u001b[K     |████████████████████████████████| 147 kB 24 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting stevedore>=2.0.1\n",
      "  Downloading stevedore-4.1.1-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 37 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=16.3.0 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Collecting pyperclip>=1.6\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[K     |████████████████████████████████| 112 kB 32 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from Mako->alembic>=1.5.0->optuna) (1.1.1)\n",
      "Building wheels for collected packages: pyperclip\n",
      "  Building wheel for pyperclip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=e716bc1c200aae0c184c26e28afa87b78793fae8fee3046257ecf7e4f2b3a2ae\n",
      "  Stored in directory: /home/chenli/.cache/pip/wheels/7f/1a/65/84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
      "Successfully built pyperclip\n",
      "Installing collected packages: pyperclip, pbr, stevedore, PrettyTable, Mako, importlib-resources, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
      "Successfully installed Mako-1.2.3 PrettyTable-3.5.0 alembic-1.8.1 autopage-0.5.1 cliff-4.0.0 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 importlib-resources-5.10.0 optuna-3.0.3 pbr-5.11.0 pyperclip-1.8.2 stevedore-4.1.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/anaconda/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting ray[tune]\n",
      "  Downloading ray-2.1.0-cp38-cp38-manylinux2014_x86_64.whl (58.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 58.9 MB 28 kB/s eta 0:00:0118\n",
      "\u001b[?25hRequirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from ray[tune]) (3.19.1)\n",
      "Collecting virtualenv>=20.0.24\n",
      "  Downloading virtualenv-20.16.6-py3-none-any.whl (8.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.8 MB 27 kB/s eta 0:00:014\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/anaconda/anaconda3/lib/python3.8/site-packages (from ray[tune]) (3.6.0)\n",
      "Requirement already satisfied: pyyaml in /home/anaconda/anaconda3/lib/python3.8/site-packages (from ray[tune]) (6.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from ray[tune]) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.16 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from ray[tune]) (1.21.2)\n",
      "Requirement already satisfied: grpcio>=1.32.0 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from ray[tune]) (1.42.0)\n",
      "Requirement already satisfied: requests in /home/anaconda/anaconda3/lib/python3.8/site-packages (from ray[tune]) (2.27.1)\n",
      "Requirement already satisfied: click<=8.0.4,>=7.0 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from ray[tune]) (8.0.4)\n",
      "Requirement already satisfied: frozenlist in /home/anaconda/anaconda3/lib/python3.8/site-packages (from ray[tune]) (1.2.0)\n",
      "Requirement already satisfied: jsonschema in /home/anaconda/anaconda3/lib/python3.8/site-packages (from ray[tune]) (3.2.0)\n",
      "Requirement already satisfied: aiosignal in /home/anaconda/anaconda3/lib/python3.8/site-packages (from ray[tune]) (1.2.0)\n",
      "Requirement already satisfied: attrs in /home/anaconda/anaconda3/lib/python3.8/site-packages (from ray[tune]) (21.4.0)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from ray[tune]) (2.5.1)\n",
      "Requirement already satisfied: pandas in /home/anaconda/anaconda3/lib/python3.8/site-packages (from ray[tune]) (1.4.1)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: six>=1.5.2 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from grpcio>=1.32.0->ray[tune]) (1.16.0)\n",
      "Collecting distlib<1,>=0.3.6\n",
      "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
      "\u001b[K     |████████████████████████████████| 468 kB 15 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: platformdirs<3,>=2.4 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from virtualenv>=20.0.24->ray[tune]) (2.4.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from jsonschema->ray[tune]) (0.18.0)\n",
      "Requirement already satisfied: setuptools in /home/anaconda/anaconda3/lib/python3.8/site-packages (from jsonschema->ray[tune]) (58.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from pandas->ray[tune]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from pandas->ray[tune]) (2021.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from requests->ray[tune]) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from requests->ray[tune]) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from requests->ray[tune]) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anaconda/anaconda3/lib/python3.8/site-packages (from requests->ray[tune]) (2021.10.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: distlib, virtualenv, tabulate, ray\n",
      "Successfully installed distlib-0.3.6 ray-2.1.0 tabulate-0.9.0 virtualenv-20.16.6\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/anaconda/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install optuna\n",
    "! pip install ray[tune]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268151a5",
   "metadata": {},
   "source": [
    "超参搜索时，Trainer将会返回多个训练好的模型，所以需要传入一个定义好的模型从而让Trainer可以不断重新初始化该传入的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87638e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_dir, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a6b44e",
   "metadata": {},
   "source": [
    "和之前调用 Trainer类似:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a78d5c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018fe430",
   "metadata": {},
   "source": [
    "调用方法hyperparameter_search。注意，这个过程可能很久，我们可以先用部分数据集进行超参搜索，再进行全量训练。 比如使用1/10的数据进行搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4f5d3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-12 15:49:06,605]\u001b[0m A new study created in memory with name: no-name-22dfba30-7ebc-496f-a5cc-7c8aef494c61\u001b[0m\n",
      "\u001b[33m[W 2022-11-12 15:49:12,325]\u001b[0m Trial 0 failed because of the following error: RuntimeError('Caught RuntimeError in replica 0 on device 0.\\nOriginal Traceback (most recent call last):\\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\\n    output = module(*input, **kwargs)\\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 1505, in forward\\n    return_dict=return_dict,\\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 976, in forward\\n    return_dict=return_dict,\\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 574, in forward\\n    output_attentions,\\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 460, in forward\\n    past_key_value=self_attn_past_key_value,\\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 393, in forward\\n    output_attentions,\\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 308, in forward\\n    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\\nRuntimeError: CUDA out of memory. Tried to allocate 6.44 GiB (GPU 0; 14.76 GiB total capacity; 8.83 GiB already allocated; 4.73 GiB free; 8.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\\n')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/integrations.py\", line 135, in _objective\n",
      "    trainer.train(resume_from_checkpoint=checkpoint, trial=trial)\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/trainer.py\", line 940, in train\n",
      "    tr_loss += self.training_step(model, inputs)\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/trainer.py\", line 1304, in training_step\n",
      "    loss = self.compute_loss(model, inputs)\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/trainer.py\", line 1334, in compute_loss\n",
      "    outputs = model(**inputs)\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\", line 168, in forward\n",
      "    outputs = self.parallel_apply(replicas, inputs, kwargs)\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\", line 178, in parallel_apply\n",
      "    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 86, in parallel_apply\n",
      "    output.reraise()\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/_utils.py\", line 434, in reraise\n",
      "    raise exception\n",
      "RuntimeError: Caught RuntimeError in replica 0 on device 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n",
      "    output = module(*input, **kwargs)\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 1505, in forward\n",
      "    return_dict=return_dict,\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 976, in forward\n",
      "    return_dict=return_dict,\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 574, in forward\n",
      "    output_attentions,\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 460, in forward\n",
      "    past_key_value=self_attn_past_key_value,\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 393, in forward\n",
      "    output_attentions,\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 308, in forward\n",
      "    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 6.44 GiB (GPU 0; 14.76 GiB total capacity; 8.83 GiB already allocated; 4.73 GiB free; 8.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 1505, in forward\n    return_dict=return_dict,\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 976, in forward\n    return_dict=return_dict,\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 574, in forward\n    output_attentions,\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 460, in forward\n    past_key_value=self_attn_past_key_value,\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 393, in forward\n    output_attentions,\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 308, in forward\n    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\nRuntimeError: CUDA out of memory. Tried to allocate 6.44 GiB (GPU 0; 14.76 GiB total capacity; 8.83 GiB already allocated; 4.73 GiB free; 8.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3747304/2132301516.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameter_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mhyperparameter_search\u001b[0;34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001b[0m\n\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0mrun_hp_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_hp_search_optuna\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mHPSearchBackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOPTUNA\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrun_hp_search_ray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m         \u001b[0mbest_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp_search_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/integrations.py\u001b[0m in \u001b[0;36mrun_hp_search_optuna\u001b[0;34m(trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n_jobs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mBestRun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         )\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     ):\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/integrations.py\u001b[0m in \u001b[0;36m_objective\u001b[0;34m(trial, checkpoint_dir)\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;31m# If there hasn't been any evaluation during the training loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1302\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1332\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 1505, in forward\n    return_dict=return_dict,\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 976, in forward\n    return_dict=return_dict,\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 574, in forward\n    output_attentions,\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 460, in forward\n    past_key_value=self_attn_past_key_value,\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 393, in forward\n    output_attentions,\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\", line 308, in forward\n    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\nRuntimeError: CUDA out of memory. Tried to allocate 6.44 GiB (GPU 0; 14.76 GiB total capacity; 8.83 GiB already allocated; 4.73 GiB free; 8.87 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "best_run = trainer.hyperparameter_search(n_trials=10, direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d972562c",
   "metadata": {},
   "source": [
    "hyperparameter_search会返回效果最好的模型相关的参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e18bb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd193a66",
   "metadata": {},
   "source": [
    "将Trainner设置为搜索到的最好参数，进行训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3176f306",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, v in best_run.hyperparameters.items():\n",
    "    setattr(trainer.args, n, v)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f507e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
