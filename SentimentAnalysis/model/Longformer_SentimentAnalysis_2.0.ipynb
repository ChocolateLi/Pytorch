{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf286778",
   "metadata": {},
   "source": [
    "# å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bd675d",
   "metadata": {},
   "source": [
    "## å‚æ•°è®¾ç½®æˆ–å˜é‡è®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "679fd9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"schen/longformer-chinese-base-4096\"\n",
    "batch_size = 2 # æ¯ä¸€æ‰¹æ¬¡çš„æ•°é‡\n",
    "num_labels = 2 # å¤šå°‘åˆ†ç±»ï¼Œè¿™é‡Œæ˜¯äºŒåˆ†ç±»é—®é¢˜ï¼Œç§¯æå’Œæ¶ˆæ\n",
    "output_dir = \"/home/chenli/pre_model/20221108\" # æ¨¡å‹ä¿å­˜è·¯å¾„\n",
    "learning_rate = 1e-5 # å­¦ä¹ ç‡\n",
    "num_train_epochs = 10 # è®­ç»ƒè½®æ¬¡ï¼Œå·®ä¸å¤šè®¾ç½®ä¸º5å·¦å³ã€‚è½®æ•°ä¸è¦è®¾ç½®å¤ªå¤§ã€‚è½®æ•°è®¾ç½®çš„å¤ªå¤§ï¼ŒLossæ˜¯ä¸‹é™äº†ï¼Œä½†æ˜¯å¾®è°ƒçš„æ—¶å€™æ•ˆæœä¸æ˜¯å¾ˆå¥½ï¼Œæœ‰å¯èƒ½è®­ç»ƒè¿‡å¤´äº†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d732d7",
   "metadata": {},
   "source": [
    "## å‚æ•°è®¾ç½®æˆ–å˜é‡è®¾ç½®\n",
    "è·‘è‡ªå·±çš„æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3679f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"schen/longformer-chinese-base-4096\"\n",
    "batch_size = 2 # æ¯ä¸€æ‰¹æ¬¡çš„æ•°é‡\n",
    "num_labels = 2 # å¤šå°‘åˆ†ç±»ï¼Œè¿™é‡Œæ˜¯äºŒåˆ†ç±»é—®é¢˜ï¼Œç§¯æå’Œæ¶ˆæ\n",
    "output_dir = \"/home/chenli/pre_model/20221109\" # æ¨¡å‹ä¿å­˜è·¯å¾„\n",
    "learning_rate = 1e-5 # å­¦ä¹ ç‡\n",
    "num_train_epochs = 5 # è®­ç»ƒè½®æ¬¡ï¼Œå·®ä¸å¤šè®¾ç½®ä¸º5å·¦å³ã€‚è½®æ•°ä¸è¦è®¾ç½®å¤ªå¤§ã€‚è½®æ•°è®¾ç½®çš„å¤ªå¤§ï¼ŒLossæ˜¯ä¸‹é™äº†ï¼Œä½†æ˜¯å¾®è°ƒçš„æ—¶å€™æ•ˆæœä¸æ˜¯å¾ˆå¥½ï¼Œæœ‰å¯èƒ½è®­ç»ƒè¿‡å¤´äº†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abae26de",
   "metadata": {},
   "source": [
    "## å‚æ•°è®¾ç½®æˆ–å˜é‡è®¾ç½®\n",
    "20221114 <br/>\n",
    "ç”¨è‡ªå·±çš„æ•°æ®é›†è¿›è¡Œå¾®è°ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a41ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"schen/longformer-chinese-base-4096\"\n",
    "batch_size = 2 # æ¯ä¸€æ‰¹æ¬¡çš„æ•°é‡\n",
    "num_labels = 2 # å¤šå°‘åˆ†ç±»ï¼Œè¿™é‡Œæ˜¯äºŒåˆ†ç±»é—®é¢˜ï¼Œç§¯æå’Œæ¶ˆæ\n",
    "output_dir = \"/home/chenli/pre_model/20221114\" # æ¨¡å‹ä¿å­˜è·¯å¾„\n",
    "learning_rate = 1e-5 # å­¦ä¹ ç‡\n",
    "weight_decay=0.01 # å­¦ä¹ ç‡è¡°å‡ï¼Œè®¾ç½®0.01å³å¯ã€‚å¦‚æœweight_decayè®¾ç½®å¤ªå°ï¼Œå‡ ä¹å°±ä¸èµ·ä½œç”¨äº†ã€‚\n",
    "num_train_epochs = 10 # è®­ç»ƒè½®æ¬¡ï¼Œå·®ä¸å¤šè®¾ç½®ä¸º5å·¦å³ã€‚è½®æ•°ä¸è¦è®¾ç½®å¤ªå¤§ã€‚è½®æ•°è®¾ç½®çš„å¤ªå¤§ï¼ŒLossæ˜¯ä¸‹é™äº†ï¼Œä½†æ˜¯å¾®è°ƒçš„æ—¶å€™æ•ˆæœä¸æ˜¯å¾ˆå¥½ï¼Œæœ‰å¯èƒ½è®­ç»ƒè¿‡å¤´äº†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f78de9",
   "metadata": {},
   "source": [
    "## åŠ è½½æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5957b840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenli/anaconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import load_from_disk\n",
    "# åŠ è½½ä¸€ä¸ªè¯„ä¼°æ ‡å‡†ï¼Œé»˜è®¤çš„è¯„ä¼°æ ‡å‡†\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf28545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_946268/2584357093.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"glue\",\"mrpc\")\n",
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Mon Nov  7 19:47:24 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½æ•°æ®é›†\n",
    "dataset = load_from_disk('./data/ChnSentiCorp')\n",
    "metric = load_metric(\"glue\",\"mrpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bb49a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 9600\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eebb5821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metric(name: \"glue\", features: {'predictions': Value(dtype='int64', id=None), 'references': Value(dtype='int64', id=None)}, usage: \"\"\"\n",
       "Compute GLUE evaluation metric associated to each GLUE dataset.\n",
       "Args:\n",
       "    predictions: list of predictions to score.\n",
       "        Each translation should be tokenized into a list of tokens.\n",
       "    references: list of lists of references for each translation.\n",
       "        Each reference should be tokenized into a list of tokens.\n",
       "Returns: depending on the GLUE subset, one or several of:\n",
       "    \"accuracy\": Accuracy\n",
       "    \"f1\": F1 score\n",
       "    \"pearson\": Pearson Correlation\n",
       "    \"spearmanr\": Spearman Correlation\n",
       "    \"matthews_correlation\": Matthew Correlation\n",
       "Examples:\n",
       "\n",
       "    >>> glue_metric = datasets.load_metric('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'accuracy': 1.0}\n",
       "\n",
       "    >>> glue_metric = datasets.load_metric('glue', 'mrpc')  # 'mrpc' or 'qqp'\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'accuracy': 1.0, 'f1': 1.0}\n",
       "\n",
       "    >>> glue_metric = datasets.load_metric('glue', 'stsb')\n",
       "    >>> references = [0., 1., 2., 3., 4., 5.]\n",
       "    >>> predictions = [0., 1., 2., 3., 4., 5.]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n",
       "    {'pearson': 1.0, 'spearmanr': 1.0}\n",
       "\n",
       "    >>> glue_metric = datasets.load_metric('glue', 'cola')\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'matthews_correlation': 1.0}\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f47ce3",
   "metadata": {},
   "source": [
    "ç›´æ¥è°ƒç”¨metricçš„computeæ–¹æ³•ï¼Œä¼ å…¥labelså’Œpredictionså³å¯å¾—åˆ°metricçš„å€¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "968a0d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.53125, 'f1': 0.5}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "fake_preds = np.random.randint(0, 2, size=(64,))\n",
    "fake_labels = np.random.randint(0, 2, size=(64,))\n",
    "metric.compute(predictions=fake_preds, references=fake_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858469e2",
   "metadata": {},
   "source": [
    "## åŠ è½½æ•°æ®\n",
    "åŠ è½½è‡ªå·±çš„æ•°æ®é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4e8ffae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-5602383f9cde0ea3\n",
      "Reusing dataset csv (/home/chenli/.cache/huggingface/datasets/csv/default-5602383f9cde0ea3/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n",
      "Using custom data configuration default-062c84d526dcea84\n",
      "Reusing dataset csv (/home/chenli/.cache/huggingface/datasets/csv/default-062c84d526dcea84/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n",
      "Using custom data configuration default-0f8395db45727ded\n",
      "Reusing dataset csv (/home/chenli/.cache/huggingface/datasets/csv/default-0f8395db45727ded/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import load_from_disk\n",
    "# åŠ è½½ä¸€ä¸ªè¯„ä¼°æ ‡å‡†ï¼Œé»˜è®¤çš„è¯„ä¼°æ ‡å‡†\n",
    "from datasets import load_metric\n",
    "\n",
    "train_dataset = load_dataset('csv',data_files='../data/MyDataset/data2/train_dataset.csv',split='train')\n",
    "valid_dataset = load_dataset('csv',data_files='../data/MyDataset/data2/valid_dataset.csv',split='train')\n",
    "test_dataset = load_dataset('csv',data_files='../data/MyDataset/data2/test_dataset.csv',split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a61983",
   "metadata": {},
   "source": [
    "## æ•°æ®é¢„å¤„ç†\n",
    "åœ¨å°†æ•°æ®å–‚å…¥æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ã€‚é¢„å¤„ç†çš„å·¥å…·å«Tokenizerã€‚Tokenizeré¦–å…ˆå¯¹è¾“å…¥è¿›è¡Œtokenizeï¼Œç„¶åå°†tokensè½¬åŒ–ä¸ºé¢„æ¨¡å‹ä¸­éœ€è¦å¯¹åº”çš„token IDï¼Œå†è½¬åŒ–ä¸ºæ¨¡å‹éœ€è¦çš„è¾“å…¥æ ¼å¼ã€‚\n",
    "\n",
    "ä¸ºäº†è¾¾åˆ°æ•°æ®é¢„å¤„ç†çš„ç›®çš„ï¼Œæˆ‘ä»¬ä½¿ç”¨AutoTokenizer.from_pretrainedæ–¹æ³•å®ä¾‹åŒ–æˆ‘ä»¬çš„tokenizerï¼Œè¿™æ ·å¯ä»¥ç¡®ä¿ï¼š\n",
    "\n",
    "æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªä¸é¢„è®­ç»ƒæ¨¡å‹ä¸€ä¸€å¯¹åº”çš„tokenizerã€‚\n",
    "ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹checkpointå¯¹åº”çš„tokenizerçš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¹Ÿä¸‹è½½äº†æ¨¡å‹éœ€è¦çš„è¯è¡¨åº“vocabularyï¼Œå‡†ç¡®æ¥è¯´æ˜¯tokens vocabularyã€‚\n",
    "è¿™ä¸ªè¢«ä¸‹è½½çš„tokens vocabularyä¼šè¢«ç¼“å­˜èµ·æ¥ï¼Œä»è€Œå†æ¬¡ä½¿ç”¨çš„æ—¶å€™ä¸ä¼šé‡æ–°ä¸‹è½½ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76b4c5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7258e521",
   "metadata": {},
   "source": [
    "æ³¨æ„ï¼šuse_fast=Trueè¦æ±‚tokenizerå¿…é¡»æ˜¯transformers.PreTrainedTokenizerFastç±»å‹ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨é¢„å¤„ç†çš„æ—¶å€™éœ€è¦ç”¨åˆ°fast tokenizerçš„ä¸€äº›ç‰¹æ®Šç‰¹æ€§ï¼ˆæ¯”å¦‚å¤šçº¿ç¨‹å¿«é€Ÿtokenizerï¼‰ã€‚å¦‚æœå¯¹åº”çš„æ¨¡å‹æ²¡æœ‰fast tokenizerï¼Œå»æ‰è¿™ä¸ªé€‰é¡¹å³å¯ã€‚\n",
    "\n",
    "å‡ ä¹æ‰€æœ‰æ¨¡å‹å¯¹åº”çš„tokenizeréƒ½æœ‰å¯¹åº”çš„fast tokenizerã€‚\n",
    "\n",
    "tokenizeræ—¢å¯ä»¥å¯¹å•ä¸ªæ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œä¹Ÿå¯ä»¥å¯¹ä¸€å¯¹æ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œtokenizeré¢„å¤„ç†åå¾—åˆ°çš„æ•°æ®æ»¡è¶³é¢„è®­ç»ƒæ¨¡å‹è¾“å…¥æ ¼å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ae05e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†è¯\n",
    "def preprocess_function(data):\n",
    "    return tokenizer(data['text'],truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c1ef7d",
   "metadata": {},
   "source": [
    "æ¥ä¸‹æ¥å¯¹æ•°æ®é›†datasetsé‡Œé¢çš„æ‰€æœ‰æ ·æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œå¤„ç†çš„æ–¹å¼æ˜¯ä½¿ç”¨mapå‡½æ•°ï¼Œå°†é¢„å¤„ç†å‡½æ•°prepare_train_featuresåº”ç”¨åˆ°ï¼ˆmap)æ‰€æœ‰æ ·æœ¬ä¸Šã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21ab9caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 10.14ba/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.18ba/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 16.51ba/s]\n"
     ]
    }
   ],
   "source": [
    "encoded_dataset = dataset.map(function=preprocess_function,\n",
    "                     batched=True,\n",
    "                     remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6e322c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9600\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dc3acb",
   "metadata": {},
   "source": [
    "## æ•°æ®é¢„å¤„ç†\n",
    "é¢„å¤„ç†è‡ªå·±çš„æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01c43cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec16f71b28924859b302eefb35f7e678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/839 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e93dd6c03a4161856c884b1af33a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/131k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1738c6c0d157454d9ee9a10d3e952e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "772bd2e9d80d4d07a7ea53c83ac3680f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/88.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "# åŠ è½½åˆ†è¯å™¨\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfc1084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†è¯\n",
    "def preprocess_function(data):\n",
    "    return tokenizer(data['text'],padding='max_length',max_length=1500,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a1f8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b99a78ee9263492faa1632b87051be96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 2755\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_train_dataset = train_dataset.map(function=preprocess_function,\n",
    "                     batched=True,\n",
    "                     remove_columns=['text'])\n",
    "encoded_train_dataset = encoded_train_dataset.rename_column(\"label\", \"labels\")\n",
    "encoded_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f45bf08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef112d6340044dc83fa26665367801d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 344\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_valid_dataset = valid_dataset.map(function=preprocess_function,\n",
    "                     batched=True,\n",
    "                     remove_columns=['text'])\n",
    "encoded_valid_dataset = encoded_valid_dataset.rename_column(\"label\", \"labels\")\n",
    "encoded_valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ed88f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17bedfaff0e45339834c7d23bb11ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 345\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_test_dataset = test_dataset.map(function=preprocess_function,\n",
    "                     batched=True,\n",
    "                     remove_columns=['text'])\n",
    "encoded_test_dataset = encoded_test_dataset.rename_column(\"label\", \"labels\")\n",
    "encoded_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9437f88e",
   "metadata": {},
   "source": [
    "## å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976cea3b",
   "metadata": {},
   "source": [
    "æ—¢ç„¶æ•°æ®å·²ç»å‡†å¤‡å¥½äº†ï¼Œç°åœ¨æˆ‘ä»¬éœ€è¦ä¸‹è½½å¹¶åŠ è½½æˆ‘ä»¬çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œç„¶åå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ã€‚æ—¢ç„¶æˆ‘ä»¬æ˜¯åšseq2seqä»»åŠ¡ï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦ä¸€ä¸ªèƒ½è§£å†³è¿™ä¸ªä»»åŠ¡çš„æ¨¡å‹ç±»ã€‚æˆ‘ä»¬ä½¿ç”¨AutoModelForSequenceClassification è¿™ä¸ªç±»ã€‚å’Œtokenizerç›¸ä¼¼ï¼Œfrom_pretrainedæ–¹æ³•åŒæ ·å¯ä»¥å¸®åŠ©æˆ‘ä»¬ä¸‹è½½å¹¶åŠ è½½æ¨¡å‹ï¼ŒåŒæ—¶ä¹Ÿä¼šå¯¹æ¨¡å‹è¿›è¡Œç¼“å­˜ï¼Œå°±ä¸ä¼šé‡å¤ä¸‹è½½æ¨¡å‹å•¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d897310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at schen/longformer-chinese-base-4096 were not used when initializing BertForSequenceClassification: ['bert.encoder.layer.4.attention.self.value_global.weight', 'bert.encoder.layer.8.attention.self.value_global.weight', 'cls.predictions.bias', 'bert.encoder.layer.3.attention.self.key_global.bias', 'bert.encoder.layer.4.attention.self.value_global.bias', 'bert.encoder.layer.3.attention.self.query_global.weight', 'bert.encoder.layer.0.attention.self.key_global.weight', 'bert.encoder.layer.1.attention.self.query_global.weight', 'bert.encoder.layer.1.attention.self.value_global.weight', 'bert.encoder.layer.2.attention.self.query_global.bias', 'bert.encoder.layer.3.attention.self.key_global.weight', 'bert.encoder.layer.10.attention.self.query_global.weight', 'bert.encoder.layer.5.attention.self.value_global.bias', 'cls.seq_relationship.bias', 'bert.encoder.layer.5.attention.self.key_global.weight', 'bert.encoder.layer.2.attention.self.query_global.weight', 'bert.encoder.layer.7.attention.self.key_global.weight', 'bert.encoder.layer.8.attention.self.value_global.bias', 'cls.seq_relationship.weight', 'bert.encoder.layer.4.attention.self.key_global.weight', 'bert.encoder.layer.2.attention.self.key_global.weight', 'bert.encoder.layer.9.attention.self.query_global.weight', 'bert.encoder.layer.6.attention.self.value_global.weight', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.9.attention.self.query_global.bias', 'bert.encoder.layer.10.attention.self.key_global.weight', 'bert.encoder.layer.4.attention.self.query_global.weight', 'cls.predictions.decoder.bias', 'bert.encoder.layer.11.attention.self.value_global.weight', 'bert.encoder.layer.9.attention.self.value_global.weight', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.11.attention.self.query_global.bias', 'bert.encoder.layer.1.attention.self.query_global.bias', 'bert.encoder.layer.11.attention.self.query_global.weight', 'bert.encoder.layer.4.attention.self.query_global.bias', 'bert.encoder.layer.1.attention.self.key_global.bias', 'bert.encoder.layer.2.attention.self.key_global.bias', 'bert.encoder.layer.11.attention.self.key_global.weight', 'bert.encoder.layer.11.attention.self.key_global.bias', 'bert.encoder.layer.6.attention.self.key_global.weight', 'bert.encoder.layer.10.attention.self.query_global.bias', 'bert.encoder.layer.9.attention.self.value_global.bias', 'bert.encoder.layer.10.attention.self.value_global.weight', 'bert.encoder.layer.4.attention.self.key_global.bias', 'bert.encoder.layer.7.attention.self.query_global.weight', 'bert.encoder.layer.0.attention.self.value_global.weight', 'bert.encoder.layer.5.attention.self.query_global.weight', 'bert.encoder.layer.3.attention.self.query_global.bias', 'bert.encoder.layer.8.attention.self.query_global.weight', 'cls.predictions.decoder.weight', 'bert.encoder.layer.9.attention.self.key_global.bias', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.6.attention.self.query_global.bias', 'bert.encoder.layer.7.attention.self.value_global.weight', 'bert.encoder.layer.5.attention.self.query_global.bias', 'bert.encoder.layer.5.attention.self.key_global.bias', 'bert.encoder.layer.3.attention.self.value_global.bias', 'bert.encoder.layer.2.attention.self.value_global.weight', 'bert.encoder.layer.11.attention.self.value_global.bias', 'bert.encoder.layer.7.attention.self.query_global.bias', 'bert.encoder.layer.1.attention.self.value_global.bias', 'bert.encoder.layer.7.attention.self.value_global.bias', 'bert.encoder.layer.0.attention.self.query_global.weight', 'bert.encoder.layer.8.attention.self.key_global.weight', 'bert.encoder.layer.8.attention.self.query_global.bias', 'bert.encoder.layer.7.attention.self.key_global.bias', 'bert.encoder.layer.10.attention.self.key_global.bias', 'bert.encoder.layer.3.attention.self.value_global.weight', 'bert.encoder.layer.1.attention.self.key_global.weight', 'bert.encoder.layer.10.attention.self.value_global.bias', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query_global.bias', 'bert.encoder.layer.8.attention.self.key_global.bias', 'bert.encoder.layer.5.attention.self.value_global.weight', 'bert.encoder.layer.0.attention.self.value_global.bias', 'bert.encoder.layer.0.attention.self.key_global.bias', 'bert.encoder.layer.9.attention.self.key_global.weight', 'bert.encoder.layer.6.attention.self.value_global.bias', 'bert.encoder.layer.6.attention.self.key_global.bias', 'bert.encoder.layer.6.attention.self.query_global.weight', 'bert.encoder.layer.2.attention.self.value_global.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at schen/longformer-chinese-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5728201c",
   "metadata": {},
   "source": [
    "ç”±äºæˆ‘ä»¬å¾®è°ƒçš„ä»»åŠ¡æ˜¯æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œè€Œæˆ‘ä»¬åŠ è½½çš„æ˜¯é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼Œæ‰€ä»¥ä¼šæç¤ºæˆ‘ä»¬åŠ è½½æ¨¡å‹çš„æ—¶å€™æ‰”æ‰äº†ä¸€äº›ä¸åŒ¹é…çš„ç¥ç»ç½‘ç»œå‚æ•°ï¼ˆæ¯”å¦‚ï¼šé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„ç¥ç»ç½‘ç»œheadè¢«æ‰”æ‰äº†ï¼ŒåŒæ—¶éšæœºåˆå§‹åŒ–äº†æ–‡æœ¬åˆ†ç±»çš„ç¥ç»ç½‘ç»œheadï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb2d23d",
   "metadata": {},
   "source": [
    "ä¸ºäº†èƒ½å¤Ÿå¾—åˆ°ä¸€ä¸ªTrainerè®­ç»ƒå·¥å…·ï¼Œæˆ‘ä»¬è¿˜éœ€è¦3ä¸ªè¦ç´ ï¼Œå…¶ä¸­æœ€é‡è¦çš„æ˜¯è®­ç»ƒçš„è®¾å®š/å‚æ•° TrainingArgumentsã€‚è¿™ä¸ªè®­ç»ƒè®¾å®šåŒ…å«äº†èƒ½å¤Ÿå®šä¹‰è®­ç»ƒè¿‡ç¨‹çš„æ‰€æœ‰å±æ€§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7438571",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = \"accuracy\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate = learning_rate,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    num_train_epochs = num_train_epochs,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d823f5c",
   "metadata": {},
   "source": [
    "ä¸Šé¢evaluation_strategy = \"epoch\"å‚æ•°å‘Šè¯‰è®­ç»ƒä»£ç ï¼šæˆ‘ä»¬æ¯ä¸ªepcohä¼šåšä¸€æ¬¡éªŒè¯è¯„ä¼°ã€‚\n",
    "\n",
    "ä¸Šé¢batch_sizeåœ¨è¿™ä¸ªnotebookä¹‹å‰å®šä¹‰å¥½äº†ã€‚\n",
    "\n",
    "æœ€åï¼Œç”±äºä¸åŒçš„ä»»åŠ¡éœ€è¦ä¸åŒçš„è¯„æµ‹æŒ‡æ ‡ï¼Œæˆ‘ä»¬å®šä¸€ä¸ªå‡½æ•°æ¥æ ¹æ®ä»»åŠ¡åå­—å¾—åˆ°è¯„ä»·æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df8b208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = load_metric('glue','mrpc')\n",
    "    logits,labels = eval_preds # é¢„æµ‹å€¼å’ŒçœŸå®å€¼\n",
    "    predictions = np.argmax(logits,axis=-1)\n",
    "    return metric.compute(predictions=predictions,references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e600280",
   "metadata": {},
   "source": [
    "å…¨éƒ¨ä¼ ç»™ Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71c7bc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90fb09d",
   "metadata": {},
   "source": [
    "## å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹\n",
    "æ ¹æ®è‡ªå·±çš„æ•°æ®è¿›è¡Œå¾®è°ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bffcde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a97eed15b14e4ebbdcee5e9dbd3e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/423M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at schen/longformer-chinese-base-4096 were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.encoder.layer.0.attention.self.query_global.weight', 'bert.encoder.layer.0.attention.self.query_global.bias', 'bert.encoder.layer.0.attention.self.key_global.weight', 'bert.encoder.layer.0.attention.self.key_global.bias', 'bert.encoder.layer.0.attention.self.value_global.weight', 'bert.encoder.layer.0.attention.self.value_global.bias', 'bert.encoder.layer.1.attention.self.query_global.weight', 'bert.encoder.layer.1.attention.self.query_global.bias', 'bert.encoder.layer.1.attention.self.key_global.weight', 'bert.encoder.layer.1.attention.self.key_global.bias', 'bert.encoder.layer.1.attention.self.value_global.weight', 'bert.encoder.layer.1.attention.self.value_global.bias', 'bert.encoder.layer.2.attention.self.query_global.weight', 'bert.encoder.layer.2.attention.self.query_global.bias', 'bert.encoder.layer.2.attention.self.key_global.weight', 'bert.encoder.layer.2.attention.self.key_global.bias', 'bert.encoder.layer.2.attention.self.value_global.weight', 'bert.encoder.layer.2.attention.self.value_global.bias', 'bert.encoder.layer.3.attention.self.query_global.weight', 'bert.encoder.layer.3.attention.self.query_global.bias', 'bert.encoder.layer.3.attention.self.key_global.weight', 'bert.encoder.layer.3.attention.self.key_global.bias', 'bert.encoder.layer.3.attention.self.value_global.weight', 'bert.encoder.layer.3.attention.self.value_global.bias', 'bert.encoder.layer.4.attention.self.query_global.weight', 'bert.encoder.layer.4.attention.self.query_global.bias', 'bert.encoder.layer.4.attention.self.key_global.weight', 'bert.encoder.layer.4.attention.self.key_global.bias', 'bert.encoder.layer.4.attention.self.value_global.weight', 'bert.encoder.layer.4.attention.self.value_global.bias', 'bert.encoder.layer.5.attention.self.query_global.weight', 'bert.encoder.layer.5.attention.self.query_global.bias', 'bert.encoder.layer.5.attention.self.key_global.weight', 'bert.encoder.layer.5.attention.self.key_global.bias', 'bert.encoder.layer.5.attention.self.value_global.weight', 'bert.encoder.layer.5.attention.self.value_global.bias', 'bert.encoder.layer.6.attention.self.query_global.weight', 'bert.encoder.layer.6.attention.self.query_global.bias', 'bert.encoder.layer.6.attention.self.key_global.weight', 'bert.encoder.layer.6.attention.self.key_global.bias', 'bert.encoder.layer.6.attention.self.value_global.weight', 'bert.encoder.layer.6.attention.self.value_global.bias', 'bert.encoder.layer.7.attention.self.query_global.weight', 'bert.encoder.layer.7.attention.self.query_global.bias', 'bert.encoder.layer.7.attention.self.key_global.weight', 'bert.encoder.layer.7.attention.self.key_global.bias', 'bert.encoder.layer.7.attention.self.value_global.weight', 'bert.encoder.layer.7.attention.self.value_global.bias', 'bert.encoder.layer.8.attention.self.query_global.weight', 'bert.encoder.layer.8.attention.self.query_global.bias', 'bert.encoder.layer.8.attention.self.key_global.weight', 'bert.encoder.layer.8.attention.self.key_global.bias', 'bert.encoder.layer.8.attention.self.value_global.weight', 'bert.encoder.layer.8.attention.self.value_global.bias', 'bert.encoder.layer.9.attention.self.query_global.weight', 'bert.encoder.layer.9.attention.self.query_global.bias', 'bert.encoder.layer.9.attention.self.key_global.weight', 'bert.encoder.layer.9.attention.self.key_global.bias', 'bert.encoder.layer.9.attention.self.value_global.weight', 'bert.encoder.layer.9.attention.self.value_global.bias', 'bert.encoder.layer.10.attention.self.query_global.weight', 'bert.encoder.layer.10.attention.self.query_global.bias', 'bert.encoder.layer.10.attention.self.key_global.weight', 'bert.encoder.layer.10.attention.self.key_global.bias', 'bert.encoder.layer.10.attention.self.value_global.weight', 'bert.encoder.layer.10.attention.self.value_global.bias', 'bert.encoder.layer.11.attention.self.query_global.weight', 'bert.encoder.layer.11.attention.self.query_global.bias', 'bert.encoder.layer.11.attention.self.key_global.weight', 'bert.encoder.layer.11.attention.self.key_global.bias', 'bert.encoder.layer.11.attention.self.value_global.weight', 'bert.encoder.layer.11.attention.self.value_global.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at schen/longformer-chinese-base-4096 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74a3e690",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = \"accuracy\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    # save_strategy = \"epoch\",\n",
    "    learning_rate = learning_rate,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    num_train_epochs = num_train_epochs,\n",
    "    weight_decay=weight_decay,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6ec4613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_metrics(eval_preds):\n",
    "    metric = load_metric('glue','mrpc')\n",
    "    logits,labels = eval_preds # é¢„æµ‹å€¼å’ŒçœŸå®å€¼\n",
    "    predictions = np.argmax(logits,axis=-1)\n",
    "    return metric.compute(predictions=predictions,references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a48202e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_train_dataset,\n",
    "    eval_dataset=encoded_valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79552be",
   "metadata": {},
   "source": [
    "## å¼€å§‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370b618e",
   "metadata": {},
   "source": [
    "### 20221108 è®­ç»ƒ\n",
    "å„ä¸ªå‚æ•°å’Œå˜é‡å¦‚ä¸‹ï¼š<br/>\n",
    "model_checkpoint = \"schen/longformer-chinese-base-4096\" <br/>\n",
    "batch_size = 2 # æ¯ä¸€æ‰¹æ¬¡çš„æ•°é‡ <br/>\n",
    "num_labels = 2 # å¤šå°‘åˆ†ç±»ï¼Œè¿™é‡Œæ˜¯äºŒåˆ†ç±»é—®é¢˜ï¼Œç§¯æå’Œæ¶ˆæ <br/>\n",
    "output_dir = \"/home/chenli/pre_model/20221108\" # æ¨¡å‹ä¿å­˜è·¯å¾„ <br/>\n",
    "learning_rate = 1e-5 # å­¦ä¹ ç‡ <br/>\n",
    "num_train_epochs = 10 # è®­ç»ƒè½®æ¬¡ <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75cd8b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenli/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 9600\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 48000\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48000' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48000/48000 34:58:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.448200</td>\n",
       "      <td>0.436606</td>\n",
       "      <td>0.923333</td>\n",
       "      <td>0.921635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.239200</td>\n",
       "      <td>0.361255</td>\n",
       "      <td>0.938333</td>\n",
       "      <td>0.936968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.204600</td>\n",
       "      <td>0.413974</td>\n",
       "      <td>0.944167</td>\n",
       "      <td>0.943268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.473601</td>\n",
       "      <td>0.938333</td>\n",
       "      <td>0.936860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.506522</td>\n",
       "      <td>0.944167</td>\n",
       "      <td>0.942784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.033200</td>\n",
       "      <td>0.488925</td>\n",
       "      <td>0.942500</td>\n",
       "      <td>0.941772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.035600</td>\n",
       "      <td>0.540889</td>\n",
       "      <td>0.940833</td>\n",
       "      <td>0.938846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.544506</td>\n",
       "      <td>0.940833</td>\n",
       "      <td>0.938315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.536422</td>\n",
       "      <td>0.947500</td>\n",
       "      <td>0.945923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.563689</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.945299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 2\n",
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Mon Nov  7 19:47:24 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n",
      "Saving model checkpoint to /home/chenli/pre_model/20221108/checkpoint-4800\n",
      "Configuration saved in /home/chenli/pre_model/20221108/checkpoint-4800/config.json\n",
      "Model weights saved in /home/chenli/pre_model/20221108/checkpoint-4800/pytorch_model.bin\n",
      "tokenizer config file saved in /home/chenli/pre_model/20221108/checkpoint-4800/tokenizer_config.json\n",
      "Special tokens file saved in /home/chenli/pre_model/20221108/checkpoint-4800/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 2\n",
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Mon Nov  7 19:47:24 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n",
      "Saving model checkpoint to /home/chenli/pre_model/20221108/checkpoint-9600\n",
      "Configuration saved in /home/chenli/pre_model/20221108/checkpoint-9600/config.json\n",
      "Model weights saved in /home/chenli/pre_model/20221108/checkpoint-9600/pytorch_model.bin\n",
      "tokenizer config file saved in /home/chenli/pre_model/20221108/checkpoint-9600/tokenizer_config.json\n",
      "Special tokens file saved in /home/chenli/pre_model/20221108/checkpoint-9600/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to /home/chenli/pre_model/20221108/checkpoint-14400\n",
      "Configuration saved in /home/chenli/pre_model/20221108/checkpoint-14400/config.json\n",
      "Model weights saved in /home/chenli/pre_model/20221108/checkpoint-14400/pytorch_model.bin\n",
      "tokenizer config file saved in /home/chenli/pre_model/20221108/checkpoint-14400/tokenizer_config.json\n",
      "Special tokens file saved in /home/chenli/pre_model/20221108/checkpoint-14400/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to /home/chenli/pre_model/20221108/checkpoint-19200\n",
      "Configuration saved in /home/chenli/pre_model/20221108/checkpoint-19200/config.json\n",
      "Model weights saved in /home/chenli/pre_model/20221108/checkpoint-19200/pytorch_model.bin\n",
      "tokenizer config file saved in /home/chenli/pre_model/20221108/checkpoint-19200/tokenizer_config.json\n",
      "Special tokens file saved in /home/chenli/pre_model/20221108/checkpoint-19200/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to /home/chenli/pre_model/20221108/checkpoint-24000\n",
      "Configuration saved in /home/chenli/pre_model/20221108/checkpoint-24000/config.json\n",
      "Model weights saved in /home/chenli/pre_model/20221108/checkpoint-24000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/chenli/pre_model/20221108/checkpoint-24000/tokenizer_config.json\n",
      "Special tokens file saved in /home/chenli/pre_model/20221108/checkpoint-24000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 2\n",
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Mon Nov  7 19:47:24 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n",
      "Saving model checkpoint to /home/chenli/pre_model/20221108/checkpoint-28800\n",
      "Configuration saved in /home/chenli/pre_model/20221108/checkpoint-28800/config.json\n",
      "Model weights saved in /home/chenli/pre_model/20221108/checkpoint-28800/pytorch_model.bin\n",
      "tokenizer config file saved in /home/chenli/pre_model/20221108/checkpoint-28800/tokenizer_config.json\n",
      "Special tokens file saved in /home/chenli/pre_model/20221108/checkpoint-28800/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to /home/chenli/pre_model/20221108/checkpoint-33600\n",
      "Configuration saved in /home/chenli/pre_model/20221108/checkpoint-33600/config.json\n",
      "Model weights saved in /home/chenli/pre_model/20221108/checkpoint-33600/pytorch_model.bin\n",
      "tokenizer config file saved in /home/chenli/pre_model/20221108/checkpoint-33600/tokenizer_config.json\n",
      "Special tokens file saved in /home/chenli/pre_model/20221108/checkpoint-33600/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to /home/chenli/pre_model/20221108/checkpoint-38400\n",
      "Configuration saved in /home/chenli/pre_model/20221108/checkpoint-38400/config.json\n",
      "Model weights saved in /home/chenli/pre_model/20221108/checkpoint-38400/pytorch_model.bin\n",
      "tokenizer config file saved in /home/chenli/pre_model/20221108/checkpoint-38400/tokenizer_config.json\n",
      "Special tokens file saved in /home/chenli/pre_model/20221108/checkpoint-38400/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 2\n",
      "Saving model checkpoint to /home/chenli/pre_model/20221108/checkpoint-43200\n",
      "Configuration saved in /home/chenli/pre_model/20221108/checkpoint-43200/config.json\n",
      "Model weights saved in /home/chenli/pre_model/20221108/checkpoint-43200/pytorch_model.bin\n",
      "tokenizer config file saved in /home/chenli/pre_model/20221108/checkpoint-43200/tokenizer_config.json\n",
      "Special tokens file saved in /home/chenli/pre_model/20221108/checkpoint-43200/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 2\n",
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Mon Nov  7 19:47:24 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n",
      "Saving model checkpoint to /home/chenli/pre_model/20221108/checkpoint-48000\n",
      "Configuration saved in /home/chenli/pre_model/20221108/checkpoint-48000/config.json\n",
      "Model weights saved in /home/chenli/pre_model/20221108/checkpoint-48000/pytorch_model.bin\n",
      "tokenizer config file saved in /home/chenli/pre_model/20221108/checkpoint-48000/tokenizer_config.json\n",
      "Special tokens file saved in /home/chenli/pre_model/20221108/checkpoint-48000/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/chenli/pre_model/20221108/checkpoint-43200 (score: 0.9475).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=48000, training_loss=0.1149462267626077, metrics={'train_runtime': 125940.975, 'train_samples_per_second': 0.762, 'train_steps_per_second': 0.381, 'total_flos': 7428788537010720.0, 'train_loss': 0.1149462267626077, 'epoch': 10.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3be0dd3",
   "metadata": {},
   "source": [
    "è®­ç»ƒå®Œæˆåè¿›è¡Œè¯„ä¼°ï¼Œä½¿ç”¨çš„æ˜¯éªŒè¯é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71545303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Mon Nov  7 19:47:24 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5364220142364502,\n",
       " 'eval_accuracy': 0.9475,\n",
       " 'eval_f1': 0.945922746781116,\n",
       " 'eval_runtime': 476.841,\n",
       " 'eval_samples_per_second': 2.517,\n",
       " 'eval_steps_per_second': 1.258,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11dc7ab",
   "metadata": {},
   "source": [
    "ä½¿ç”¨æµ‹è¯•é›†è¿›è¡Œè¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d628bc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4677197337150574,\n",
       " 'eval_accuracy': 0.9541666666666667,\n",
       " 'eval_f1': 0.9541284403669725,\n",
       " 'eval_runtime': 363.9768,\n",
       " 'eval_samples_per_second': 3.297,\n",
       " 'eval_steps_per_second': 1.648,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=encoded_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60a98a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1200\n",
      "  Batch size = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 5.9555726, -5.709093 ],\n",
       "       [ 6.093847 , -5.8897943],\n",
       "       [ 6.08048  , -5.892603 ],\n",
       "       ...,\n",
       "       [-4.9640007,  4.1808424],\n",
       "       [-6.003969 ,  5.558333 ],\n",
       "       [ 6.074811 , -5.919014 ]], dtype=float32), label_ids=array([1, 0, 0, ..., 1, 1, 0]), metrics={'test_loss': 0.4677197337150574, 'test_accuracy': 0.9541666666666667, 'test_f1': 0.9541284403669725, 'test_runtime': 872.9183, 'test_samples_per_second': 1.375, 'test_steps_per_second': 0.687})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.predict(test_dataset=encoded_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ca34575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=0,\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_pin_memory=True,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_steps=None,\n",
       "evaluation_strategy=epoch,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "greater_is_better=True,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=every_save,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=1e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=True,\n",
       "local_rank=-1,\n",
       "log_level=-1,\n",
       "log_level_replica=-1,\n",
       "log_on_each_node=True,\n",
       "logging_dir=/home/chenli/pre_model/20221108/runs/Nov08_15-57-32_0003,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=500,\n",
       "logging_strategy=steps,\n",
       "lr_scheduler_type=linear,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=accuracy,\n",
       "mp_parameters=,\n",
       "no_cuda=False,\n",
       "num_train_epochs=10,\n",
       "optim=adamw_hf,\n",
       "output_dir=/home/chenli/pre_model/20221108,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=2,\n",
       "per_device_train_batch_size=2,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=[],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=/home/chenli/pre_model/20221108,\n",
       "save_on_each_node=False,\n",
       "save_steps=500,\n",
       "save_strategy=epoch,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "sharded_ddp=[],\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.01,\n",
       "xpu_backend=None,\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d5b1d9",
   "metadata": {},
   "source": [
    "## 2022.11.10 è®­ç»ƒ\n",
    "æ ¹æ®è‡ªå·±çš„è®­ç»ƒé›†è¿›è¡Œè®­ç»ƒ <br/>\n",
    "model_checkpoint = \"schen/longformer-chinese-base-4096\" <br/>\n",
    "batch_size = 2 # æ¯ä¸€æ‰¹æ¬¡çš„æ•°é‡ <br/>\n",
    "num_labels = 2 # å¤šå°‘åˆ†ç±»ï¼Œè¿™é‡Œæ˜¯äºŒåˆ†ç±»é—®é¢˜ï¼Œç§¯æå’Œæ¶ˆæ <br/>\n",
    "output_dir = \"/home/chenli/pre_model/20221109\" # æ¨¡å‹ä¿å­˜è·¯å¾„ <br/>\n",
    "learning_rate = 1e-5 # å­¦ä¹ ç‡ <br/>\n",
    "num_train_epochs = 5 # è®­ç»ƒè½®æ¬¡ï¼Œå·®ä¸å¤šè®¾ç½®ä¸º5å·¦å³ã€‚è½®æ•°ä¸è¦è®¾ç½®å¤ªå¤§ã€‚è½®æ•°è®¾ç½®çš„å¤ªå¤§ï¼ŒLossæ˜¯ä¸‹é™äº†ï¼Œä½†æ˜¯å¾®è°ƒçš„æ—¶å€™æ•ˆæœä¸æ˜¯å¾ˆå¥½ï¼Œæœ‰å¯èƒ½è®­ç»ƒè¿‡å¤´äº†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84481495",
   "metadata": {},
   "source": [
    "è®­ç»ƒå‰å…ˆè¯„ä¼°ä¸€ä¸‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35f2f5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 236\n",
      "  Batch size = 2\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='118' max='118' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [118/118 40:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3282756/1844987744.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric('glue','mrpc')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7960287928581238,\n",
       " 'eval_accuracy': 0.2457627118644068,\n",
       " 'eval_f1': 0.0,\n",
       " 'eval_runtime': 2459.7237,\n",
       " 'eval_samples_per_second': 0.096,\n",
       " 'eval_steps_per_second': 0.048}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98e74140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=0,\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_pin_memory=True,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_steps=None,\n",
       "evaluation_strategy=epoch,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "greater_is_better=True,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=every_save,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=1e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=True,\n",
       "local_rank=-1,\n",
       "log_level=-1,\n",
       "log_level_replica=-1,\n",
       "log_on_each_node=True,\n",
       "logging_dir=/home/chenli/pre_model/20221109/runs/Nov10_10-50-50_0003,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=500,\n",
       "logging_strategy=steps,\n",
       "lr_scheduler_type=linear,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=accuracy,\n",
       "mp_parameters=,\n",
       "no_cuda=False,\n",
       "num_train_epochs=5,\n",
       "optim=adamw_hf,\n",
       "output_dir=/home/chenli/pre_model/20221109,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=2,\n",
       "per_device_train_batch_size=2,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=[],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=/home/chenli/pre_model/20221109,\n",
       "save_on_each_node=False,\n",
       "save_steps=500,\n",
       "save_strategy=epoch,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "sharded_ddp=[],\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.01,\n",
       "xpu_backend=None,\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73022fe7",
   "metadata": {},
   "source": [
    "å¼€å§‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "857de373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenli/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1889\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='4725' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   2/4725 : < :, Epoch 0.00/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:66] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 1610612736 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/trainer.py:1521\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1518\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1519\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1520\u001b[0m )\n\u001b[0;32m-> 1521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/trainer.py:1763\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1761\u001b[0m         tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1763\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1766\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1767\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1768\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1769\u001b[0m ):\n\u001b[1;32m   1770\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1771\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/trainer.py:2499\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2498\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2499\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2502\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/trainer.py:2531\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2529\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2530\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2531\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2532\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2533\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1560\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1555\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1560\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1572\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1574\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1022\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1013\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1015\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m   1016\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1017\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[0;32m-> 1022\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1033\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1035\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:611\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    602\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    603\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    604\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    608\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    609\u001b[0m     )\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 611\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    621\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:497\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    487\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    496\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:427\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    419\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    425\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    426\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 427\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    437\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:359\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    355\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msoftmax(attention_scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# This is actually dropping out entire tokens to attend to, which might\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m attention_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_probs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;66;03m# Mask heads if we want to\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/dropout.py:58\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/nn/functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[0;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:66] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 1610612736 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33628740",
   "metadata": {},
   "source": [
    "## 20221114 è®­ç»ƒ\n",
    "model_checkpoint = \"schen/longformer-chinese-base-4096\" <br/>\n",
    "batch_size = 2 # æ¯ä¸€æ‰¹æ¬¡çš„æ•°é‡ <br/>\n",
    "num_labels = 2 # å¤šå°‘åˆ†ç±»ï¼Œè¿™é‡Œæ˜¯äºŒåˆ†ç±»é—®é¢˜ï¼Œç§¯æå’Œæ¶ˆæ <br/>\n",
    "output_dir = \"/home/chenli/pre_model/20221114\" # æ¨¡å‹ä¿å­˜è·¯å¾„ <br/>\n",
    "learning_rate = 1e-5 # å­¦ä¹ ç‡ <br/>\n",
    "weight_decay=0.01 # å­¦ä¹ ç‡è¡°å‡ï¼Œè®¾ç½®0.01å³å¯ã€‚å¦‚æœweight_decayè®¾ç½®å¤ªå°ï¼Œå‡ ä¹å°±ä¸èµ·ä½œç”¨äº†ã€‚ <br/>\n",
    "num_train_epochs = 10 # è®­ç»ƒè½®æ¬¡ï¼Œå·®ä¸å¤šè®¾ç½®ä¸º5å·¦å³ã€‚è½®æ•°ä¸è¦è®¾ç½®å¤ªå¤§ã€‚è½®æ•°è®¾ç½®çš„å¤ªå¤§ï¼ŒLossæ˜¯ä¸‹é™äº†ï¼Œä½†æ˜¯å¾®è°ƒçš„æ—¶å€™æ•ˆæœä¸æ˜¯å¾ˆå¥½ï¼Œæœ‰å¯èƒ½è®­ç»ƒè¿‡å¤´äº†"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6336372",
   "metadata": {},
   "source": [
    "è®­ç»ƒå‰è¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "980e0aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='259' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 12:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6863282918930054,\n",
       " 'eval_accuracy': 0.5523255813953488,\n",
       " 'eval_f1': 0.7116104868913857,\n",
       " 'eval_runtime': 42.1272,\n",
       " 'eval_samples_per_second': 8.166}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9849885f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6917498111724854,\n",
       " 'eval_accuracy': 0.553623188405797,\n",
       " 'eval_f1': 0.7126865671641791,\n",
       " 'eval_runtime': 30.3158,\n",
       " 'eval_samples_per_second': 11.38}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=encoded_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1723c7",
   "metadata": {},
   "source": [
    "å¼€å§‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03e57945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='6890' max='6890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6890/6890 1:55:11, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.136800</td>\n",
       "      <td>0.224179</td>\n",
       "      <td>0.959302</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>62.094100</td>\n",
       "      <td>5.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.110800</td>\n",
       "      <td>0.176989</td>\n",
       "      <td>0.970930</td>\n",
       "      <td>0.973958</td>\n",
       "      <td>129.898500</td>\n",
       "      <td>2.648000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.085900</td>\n",
       "      <td>0.203063</td>\n",
       "      <td>0.968023</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>30.414600</td>\n",
       "      <td>11.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.075200</td>\n",
       "      <td>0.191595</td>\n",
       "      <td>0.970930</td>\n",
       "      <td>0.973822</td>\n",
       "      <td>30.168500</td>\n",
       "      <td>11.403000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.313224</td>\n",
       "      <td>0.962209</td>\n",
       "      <td>0.965699</td>\n",
       "      <td>30.465400</td>\n",
       "      <td>11.291000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.263096</td>\n",
       "      <td>0.968023</td>\n",
       "      <td>0.970976</td>\n",
       "      <td>31.789500</td>\n",
       "      <td>10.821000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.408470</td>\n",
       "      <td>0.915698</td>\n",
       "      <td>0.919220</td>\n",
       "      <td>130.532700</td>\n",
       "      <td>2.635000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.233864</td>\n",
       "      <td>0.970930</td>\n",
       "      <td>0.973822</td>\n",
       "      <td>130.127900</td>\n",
       "      <td>2.644000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.235423</td>\n",
       "      <td>0.968023</td>\n",
       "      <td>0.971279</td>\n",
       "      <td>129.932900</td>\n",
       "      <td>2.648000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.241471</td>\n",
       "      <td>0.970930</td>\n",
       "      <td>0.973822</td>\n",
       "      <td>30.126600</td>\n",
       "      <td>11.418000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Fri Nov 11 21:04:53 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Fri Nov 11 21:04:53 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Fri Nov 11 21:04:53 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Fri Nov 11 21:04:53 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n",
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6890, training_loss=0.05106816651686182, metrics={'train_runtime': 6912.9123, 'train_samples_per_second': 0.997, 'total_flos': 26040130019100000, 'epoch': 10.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1132155c",
   "metadata": {},
   "source": [
    "è®­ç»ƒåè¯„ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "299c77aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='173' max='86' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [86/86 04:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Fri Nov 11 21:04:53 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.17698924243450165,\n",
       " 'eval_accuracy': 0.9709302325581395,\n",
       " 'eval_f1': 0.9739583333333334,\n",
       " 'eval_runtime': 129.1969,\n",
       " 'eval_samples_per_second': 2.663,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59fde732",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Using the latest cached version of the module from /home/chenli/.cache/huggingface/modules/datasets_modules/metrics/glue/91f3cfc5498873918ecf119dbf806fb10815786c84f41b85a5d3c47c1519b343 (last modified on Fri Nov 11 21:04:53 2022) since it couldn't be found locally at glue, or remotely on the Hugging Face Hub.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2300749123096466,\n",
       " 'eval_accuracy': 0.9623188405797102,\n",
       " 'eval_f1': 0.9669211195928753,\n",
       " 'eval_runtime': 129.4035,\n",
       " 'eval_samples_per_second': 2.666,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=encoded_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f167ff18",
   "metadata": {},
   "source": [
    "## è¶…å‚æ•°æœç´¢"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c031657",
   "metadata": {},
   "source": [
    "TraineråŒæ ·æ”¯æŒè¶…å‚æœç´¢ï¼Œä½¿ç”¨optuna or Ray Tuneä»£ç åº“ã€‚\n",
    "\n",
    "åæ³¨é‡Šä¸‹é¢ä¸¤è¡Œå®‰è£…ä¾èµ–ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51cd9374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting optuna\n",
      "  Using cached optuna-3.0.3-py3-none-any.whl (348 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/chenli/anaconda3/lib/python3.9/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: scipy<1.9.0,>=1.7.0 in /home/chenli/anaconda3/lib/python3.9/site-packages (from optuna) (1.7.1)\n",
      "Requirement already satisfied: tqdm in /home/chenli/anaconda3/lib/python3.9/site-packages (from optuna) (4.64.0)\n",
      "Collecting alembic>=1.5.0\n",
      "  Using cached alembic-1.8.1-py3-none-any.whl (209 kB)\n",
      "Requirement already satisfied: PyYAML in /home/chenli/anaconda3/lib/python3.9/site-packages (from optuna) (6.0)\n",
      "Collecting cliff\n",
      "  Using cached cliff-4.0.0-py3-none-any.whl (80 kB)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Using cached cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
      "Collecting colorlog\n",
      "  Using cached colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /home/chenli/anaconda3/lib/python3.9/site-packages (from optuna) (1.4.32)\n",
      "Requirement already satisfied: importlib-metadata<5.0.0 in /home/chenli/anaconda3/lib/python3.9/site-packages (from optuna) (4.11.3)\n",
      "Requirement already satisfied: numpy in /home/chenli/anaconda3/lib/python3.9/site-packages (from optuna) (1.21.5)\n",
      "Collecting Mako\n",
      "  Using cached Mako-1.2.3-py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/chenli/anaconda3/lib/python3.9/site-packages (from importlib-metadata<5.0.0->optuna) (3.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/chenli/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->optuna) (3.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/chenli/anaconda3/lib/python3.9/site-packages (from sqlalchemy>=1.3.0->optuna) (1.1.1)\n",
      "Collecting autopage>=0.4.0\n",
      "  Using cached autopage-0.5.1-py3-none-any.whl (29 kB)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Using cached cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
      "Collecting PrettyTable>=0.7.2\n",
      "  Using cached prettytable-3.5.0-py3-none-any.whl (26 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Using cached stevedore-4.1.0-py3-none-any.whl (50 kB)\n",
      "Collecting pyperclip>=1.6\n",
      "  Using cached pyperclip-1.8.2-py3-none-any.whl\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /home/chenli/anaconda3/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /home/chenli/anaconda3/lib/python3.9/site-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Using cached pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /home/chenli/anaconda3/lib/python3.9/site-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
      "Installing collected packages: pyperclip, pbr, stevedore, PrettyTable, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
      "Successfully installed Mako-1.2.3 PrettyTable-3.5.0 alembic-1.8.1 autopage-0.5.1 cliff-4.0.0 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 optuna-3.0.3 pbr-5.11.0 pyperclip-1.8.2 stevedore-4.1.0\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement ray[tune] (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for ray[tune]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install optuna\n",
    "! pip install ray[tune]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837f0364",
   "metadata": {},
   "source": [
    "è¶…å‚æœç´¢æ—¶ï¼ŒTrainerå°†ä¼šè¿”å›å¤šä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæ‰€ä»¥éœ€è¦ä¼ å…¥ä¸€ä¸ªå®šä¹‰å¥½çš„æ¨¡å‹ä»è€Œè®©Trainerå¯ä»¥ä¸æ–­é‡æ–°åˆå§‹åŒ–è¯¥ä¼ å…¥çš„æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97eb27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e4fc92",
   "metadata": {},
   "source": [
    "å’Œä¹‹å‰è°ƒç”¨ Trainerç±»ä¼¼:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9aa2628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/chenli/.cache/huggingface/hub/models--schen--longformer-chinese-base-4096/snapshots/f0e53c8afe22f6b7cca5d5278fda13e26951a3b6/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"schen/longformer-chinese-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"BertForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.22.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/chenli/.cache/huggingface/hub/models--schen--longformer-chinese-base-4096/snapshots/f0e53c8afe22f6b7cca5d5278fda13e26951a3b6/pytorch_model.bin\n",
      "Some weights of the model checkpoint at schen/longformer-chinese-base-4096 were not used when initializing BertForSequenceClassification: ['bert.encoder.layer.4.attention.self.value_global.weight', 'bert.encoder.layer.8.attention.self.value_global.weight', 'cls.predictions.bias', 'bert.encoder.layer.3.attention.self.key_global.bias', 'bert.encoder.layer.4.attention.self.value_global.bias', 'bert.encoder.layer.3.attention.self.query_global.weight', 'bert.encoder.layer.0.attention.self.key_global.weight', 'bert.encoder.layer.1.attention.self.query_global.weight', 'bert.encoder.layer.1.attention.self.value_global.weight', 'bert.encoder.layer.2.attention.self.query_global.bias', 'bert.encoder.layer.3.attention.self.key_global.weight', 'bert.encoder.layer.10.attention.self.query_global.weight', 'bert.encoder.layer.5.attention.self.value_global.bias', 'cls.seq_relationship.bias', 'bert.encoder.layer.5.attention.self.key_global.weight', 'bert.encoder.layer.2.attention.self.query_global.weight', 'bert.encoder.layer.7.attention.self.key_global.weight', 'bert.encoder.layer.8.attention.self.value_global.bias', 'cls.seq_relationship.weight', 'bert.encoder.layer.4.attention.self.key_global.weight', 'bert.encoder.layer.2.attention.self.key_global.weight', 'bert.encoder.layer.9.attention.self.query_global.weight', 'bert.encoder.layer.6.attention.self.value_global.weight', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.9.attention.self.query_global.bias', 'bert.encoder.layer.10.attention.self.key_global.weight', 'bert.encoder.layer.4.attention.self.query_global.weight', 'cls.predictions.decoder.bias', 'bert.encoder.layer.11.attention.self.value_global.weight', 'bert.encoder.layer.9.attention.self.value_global.weight', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.11.attention.self.query_global.bias', 'bert.encoder.layer.1.attention.self.query_global.bias', 'bert.encoder.layer.11.attention.self.query_global.weight', 'bert.encoder.layer.4.attention.self.query_global.bias', 'bert.encoder.layer.1.attention.self.key_global.bias', 'bert.encoder.layer.2.attention.self.key_global.bias', 'bert.encoder.layer.11.attention.self.key_global.weight', 'bert.encoder.layer.11.attention.self.key_global.bias', 'bert.encoder.layer.6.attention.self.key_global.weight', 'bert.encoder.layer.10.attention.self.query_global.bias', 'bert.encoder.layer.9.attention.self.value_global.bias', 'bert.encoder.layer.10.attention.self.value_global.weight', 'bert.encoder.layer.4.attention.self.key_global.bias', 'bert.encoder.layer.7.attention.self.query_global.weight', 'bert.encoder.layer.0.attention.self.value_global.weight', 'bert.encoder.layer.5.attention.self.query_global.weight', 'bert.encoder.layer.3.attention.self.query_global.bias', 'bert.encoder.layer.8.attention.self.query_global.weight', 'cls.predictions.decoder.weight', 'bert.encoder.layer.9.attention.self.key_global.bias', 'cls.predictions.transform.dense.weight', 'bert.encoder.layer.6.attention.self.query_global.bias', 'bert.encoder.layer.7.attention.self.value_global.weight', 'bert.encoder.layer.5.attention.self.query_global.bias', 'bert.encoder.layer.5.attention.self.key_global.bias', 'bert.encoder.layer.3.attention.self.value_global.bias', 'bert.encoder.layer.2.attention.self.value_global.weight', 'bert.encoder.layer.11.attention.self.value_global.bias', 'bert.encoder.layer.7.attention.self.query_global.bias', 'bert.encoder.layer.1.attention.self.value_global.bias', 'bert.encoder.layer.7.attention.self.value_global.bias', 'bert.encoder.layer.0.attention.self.query_global.weight', 'bert.encoder.layer.8.attention.self.key_global.weight', 'bert.encoder.layer.8.attention.self.query_global.bias', 'bert.encoder.layer.7.attention.self.key_global.bias', 'bert.encoder.layer.10.attention.self.key_global.bias', 'bert.encoder.layer.3.attention.self.value_global.weight', 'bert.encoder.layer.1.attention.self.key_global.weight', 'bert.encoder.layer.10.attention.self.value_global.bias', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query_global.bias', 'bert.encoder.layer.8.attention.self.key_global.bias', 'bert.encoder.layer.5.attention.self.value_global.weight', 'bert.encoder.layer.0.attention.self.value_global.bias', 'bert.encoder.layer.0.attention.self.key_global.bias', 'bert.encoder.layer.9.attention.self.key_global.weight', 'bert.encoder.layer.6.attention.self.value_global.bias', 'bert.encoder.layer.6.attention.self.key_global.bias', 'bert.encoder.layer.6.attention.self.query_global.weight', 'bert.encoder.layer.2.attention.self.value_global.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at schen/longformer-chinese-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672cfa40",
   "metadata": {},
   "source": [
    "è°ƒç”¨æ–¹æ³•hyperparameter_searchã€‚æ³¨æ„ï¼Œè¿™ä¸ªè¿‡ç¨‹å¯èƒ½å¾ˆä¹…ï¼Œæˆ‘ä»¬å¯ä»¥å…ˆç”¨éƒ¨åˆ†æ•°æ®é›†è¿›è¡Œè¶…å‚æœç´¢ï¼Œå†è¿›è¡Œå…¨é‡è®­ç»ƒã€‚ æ¯”å¦‚ä½¿ç”¨1/10çš„æ•°æ®è¿›è¡Œæœç´¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0012373",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = trainer.hyperparameter_search(n_trials=10, direction=\"maximize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70f162a",
   "metadata": {},
   "source": [
    "hyperparameter_searchä¼šè¿”å›æ•ˆæœæœ€å¥½çš„æ¨¡å‹ç›¸å…³çš„å‚æ•°ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e282786",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26a4ff5",
   "metadata": {},
   "source": [
    "å°†Trainnerè®¾ç½®ä¸ºæœç´¢åˆ°çš„æœ€å¥½å‚æ•°ï¼Œè¿›è¡Œè®­ç»ƒï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f351b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, v in best_run.hyperparameters.items():\n",
    "    setattr(trainer.args, n, v)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9180131a",
   "metadata": {},
   "source": [
    "æœ€ååˆ«å¿˜äº†ï¼ŒæŸ¥çœ‹å¦‚ä½•ä¸Šä¼ æ¨¡å‹ ï¼Œä¸Šä¼ æ¨¡å‹åˆ°](https://huggingface.co/transformers/model_sharing.html) åˆ°ğŸ¤— Model Hubã€‚éšåæ‚¨å°±å¯ä»¥åƒè¿™ä¸ªnotebookä¸€å¼€å§‹ä¸€æ ·ï¼Œç›´æ¥ç”¨æ¨¡å‹åå­—å°±èƒ½ä½¿ç”¨æ‚¨è‡ªå·±ä¸Šä¼ çš„æ¨¡å‹å•¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac4aca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
