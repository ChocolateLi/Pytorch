{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a437faf3",
   "metadata": {},
   "source": [
    "# BERT情感分类模型\n",
    "\n",
    "## 任务目标\n",
    "* 使用BERT模型完成情感分类\n",
    "* 测试任务的时间，做记录"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0476551c",
   "metadata": {},
   "source": [
    "## 业务背景\n",
    "业务背景：期望通过评论信息得到该评论是好评还是差评。\n",
    "\n",
    "数据介绍：文本和对应评价（1是好评，0是差评）,数据集：'seamew/ChnSentiCorp'\n",
    "\n",
    "例子：\n",
    "\n",
    "'房间太小。其他的都一般。。。。。。。。。'，0\n",
    "\n",
    "'15.4寸笔记本的键盘确实爽，基本跟台式机差不多了，蛮喜欢数字小键盘，输数字特方便，样子也很美观，做工也相当不错'，1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6845e8d",
   "metadata": {},
   "source": [
    "## DataSet类加载数据\n",
    "Pytorch 通过 Dataset 类和 DataLoader 类处理数据集和加载数据构建 batch。因此我们首先需要编写继承自 Dataset 类的自定义数据集用于组织样本和标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b46b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import load_from_disk\n",
    "\n",
    "\n",
    "#定义数据集,方便后续模型读取批量数据。\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_type):\n",
    "        self.data = self.load_data(data_type)\n",
    "    \n",
    "    # 核心要变的就是load_data这部分函数\n",
    "    # 改造成适合自己任务的数据集\n",
    "    def load_data(self, data_type):\n",
    "        # 先加载本地数据集\n",
    "        # tmp_dataset = load_dataset('csv',data_files='../data/ChnSentiCorp.csv', split = data_type)\n",
    "        # tmp_dataset = load_dataset(path='seamew/ChnSentiCorp', split = data_type)\n",
    "        # tmp_dataset = load_from_disk('./data/ChnSentiCorp')\n",
    "        Data = {}\n",
    "        for idx, line in enumerate(tmp_dataset):\n",
    "            sample = line\n",
    "            Data[idx] = sample\n",
    "        return Data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "276d893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('./data/ChnSentiCorp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b9c94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 9600\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1200\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "412ab96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "valid_data = dataset['validation']\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25d55057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般',\n",
       " 'label': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26157ce",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "创建好数据集之后，就需要通过 DataLoader 库来按批 (batch) 加载数据，将样本组织成模型可以接受的输入格式。对于 NLP 任务来说，这个环节就是对一个 batch 中的句子（这里是“句子对”）按照预训练模型的要求进行编码（包括 Padding、截断等操作）通过在 DataLoader 中设置批处理函数 collate_fn 来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7f177ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_X shape: {'input_ids': torch.Size([2, 97]), 'token_type_ids': torch.Size([2, 97]), 'attention_mask': torch.Size([2, 97])}\n",
      "batch_y shape: torch.Size([2])\n",
      "{'input_ids': tensor([[ 101, 4959, 6632, 4638,  741, 2769,  743,  749, 1962, 1126, 1947,  749,\n",
      "         1762, 2496, 2496, 5381,  677, 4692, 6224,  517, 5913, 5913, 3926, 5850,\n",
      "          518, 4638, 6397, 6389, 6820, 1914, 1962,  749, 2218,  743, 3341, 4692,\n",
      "         4692, 4692,  749, 3152, 4995, 1400, 4696, 4638, 6375,  782, 3300,  763,\n",
      "         1927, 3307, 1091, 2533,  679, 3221, 6929,  720, 4495, 1220, 2697, 6230,\n",
      "         1922, 5042, 1296, 1265,  749, 1353, 5445, 2769, 3683, 6772, 1599, 3614,\n",
      "          517, 3635, 3635, 2661, 2552,  518, 6821, 3315,  741,  738, 3221, 4959,\n",
      "         6632, 4638,  157,  113,  386,  142,  386,  114,  157,  119,  119,  119,\n",
      "          102],\n",
      "        [ 101, 6862, 2428, 3683, 2682, 6496,  704, 2571, 8024, 5445,  684, 6820,\n",
      "         1377,  809, 4500, 6631, 7574, 3563, 2466, 8024, 1872, 1217, 8115,  110,\n",
      "         4638, 8476, 6862, 2428,  511, 4801, 4669, 2595, 5543,  738, 2523, 1962,\n",
      "          511, 4510, 3737, 5447, 4500,  511,  102,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0]])}\n",
      "tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# checkpoint = \"bert-base-chinese\"\n",
    "checkpoint = \"schen/longformer-chinese-base-4096\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "# 批量处理函数\n",
    "def collote_fn(batch_samples):\n",
    "    batch_text= []\n",
    "    batch_label = []\n",
    "    for sample in batch_samples:\n",
    "        batch_text.append(sample['text'])\n",
    "        batch_label.append(int(sample['label']))\n",
    "    X = tokenizer(\n",
    "        batch_text, \n",
    "        padding=True, \n",
    "        truncation=True, \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    y = torch.tensor(batch_label)\n",
    "    return X, y\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=2, shuffle=True, collate_fn=collote_fn)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=1, shuffle=True, collate_fn=collote_fn)\n",
    "test_dataloader = DataLoader(test_data, batch_size=1, shuffle=True, collate_fn=collote_fn)\n",
    "\n",
    "batch_X, batch_y = next(iter(train_dataloader))\n",
    "print('batch_X shape:', {k: v.shape for k, v in batch_X.items()})\n",
    "print('batch_y shape:', batch_y.shape)\n",
    "print(batch_X)\n",
    "print(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "601f5986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n",
      "9600\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))\n",
    "print(len(train_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a3e058",
   "metadata": {},
   "source": [
    "## 模型定义\n",
    "预训练模型仅仅被用作编码器，模型中还会包含很多自定义的模块，因此本文采用自己编写 Pytorch 模型的方式来完成：首先利用 Transformers 库加载 Longformer 模型，然后接一个全连接层完成分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12922105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at schen/longformer-chinese-base-4096 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'bert.encoder.layer.11.attention.self.query_global.weight', 'bert.encoder.layer.3.attention.self.key_global.bias', 'bert.encoder.layer.10.attention.self.query_global.weight', 'bert.encoder.layer.0.attention.self.value_global.weight', 'bert.encoder.layer.7.attention.self.query_global.weight', 'bert.encoder.layer.5.attention.self.value_global.bias', 'bert.encoder.layer.6.attention.self.query_global.bias', 'bert.encoder.layer.7.attention.self.key_global.bias', 'bert.encoder.layer.4.attention.self.key_global.bias', 'bert.encoder.layer.11.attention.self.value_global.bias', 'cls.predictions.decoder.bias', 'bert.encoder.layer.10.attention.self.value_global.weight', 'bert.encoder.layer.8.attention.self.value_global.bias', 'bert.encoder.layer.5.attention.self.value_global.weight', 'bert.encoder.layer.11.attention.self.key_global.weight', 'bert.encoder.layer.1.attention.self.key_global.weight', 'cls.predictions.decoder.weight', 'bert.encoder.layer.6.attention.self.value_global.bias', 'bert.encoder.layer.3.attention.self.value_global.bias', 'bert.encoder.layer.9.attention.self.key_global.weight', 'bert.encoder.layer.2.attention.self.key_global.bias', 'cls.seq_relationship.bias', 'bert.encoder.layer.4.attention.self.query_global.bias', 'bert.encoder.layer.1.attention.self.query_global.bias', 'bert.encoder.layer.3.attention.self.key_global.weight', 'bert.encoder.layer.9.attention.self.query_global.bias', 'bert.encoder.layer.10.attention.self.key_global.bias', 'bert.encoder.layer.0.attention.self.key_global.bias', 'bert.encoder.layer.6.attention.self.value_global.weight', 'bert.encoder.layer.1.attention.self.value_global.bias', 'bert.encoder.layer.2.attention.self.query_global.bias', 'bert.encoder.layer.3.attention.self.value_global.weight', 'bert.encoder.layer.0.attention.self.query_global.bias', 'bert.encoder.layer.4.attention.self.key_global.weight', 'bert.encoder.layer.1.attention.self.value_global.weight', 'bert.encoder.layer.3.attention.self.query_global.weight', 'bert.encoder.layer.10.attention.self.value_global.bias', 'bert.encoder.layer.0.attention.self.value_global.bias', 'bert.encoder.layer.0.attention.self.query_global.weight', 'bert.encoder.layer.6.attention.self.query_global.weight', 'bert.encoder.layer.2.attention.self.value_global.bias', 'bert.encoder.layer.5.attention.self.key_global.bias', 'bert.encoder.layer.9.attention.self.key_global.bias', 'bert.encoder.layer.7.attention.self.key_global.weight', 'bert.encoder.layer.11.attention.self.key_global.bias', 'bert.encoder.layer.10.attention.self.key_global.weight', 'bert.encoder.layer.8.attention.self.query_global.bias', 'bert.encoder.layer.11.attention.self.query_global.bias', 'bert.encoder.layer.1.attention.self.key_global.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.6.attention.self.key_global.bias', 'bert.encoder.layer.9.attention.self.value_global.weight', 'bert.encoder.layer.2.attention.self.value_global.weight', 'bert.encoder.layer.6.attention.self.key_global.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.key_global.weight', 'bert.encoder.layer.7.attention.self.value_global.bias', 'bert.encoder.layer.8.attention.self.value_global.weight', 'bert.encoder.layer.9.attention.self.value_global.bias', 'bert.encoder.layer.1.attention.self.query_global.weight', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.0.attention.self.key_global.weight', 'cls.seq_relationship.weight', 'bert.encoder.layer.2.attention.self.key_global.weight', 'bert.encoder.layer.8.attention.self.query_global.weight', 'bert.encoder.layer.8.attention.self.key_global.bias', 'bert.encoder.layer.9.attention.self.query_global.weight', 'bert.encoder.layer.7.attention.self.query_global.bias', 'bert.encoder.layer.5.attention.self.query_global.weight', 'bert.encoder.layer.11.attention.self.value_global.weight', 'cls.predictions.bias', 'bert.encoder.layer.4.attention.self.value_global.weight', 'bert.encoder.layer.5.attention.self.query_global.bias', 'bert.encoder.layer.3.attention.self.query_global.bias', 'bert.encoder.layer.10.attention.self.query_global.bias', 'bert.encoder.layer.4.attention.self.value_global.bias', 'bert.encoder.layer.8.attention.self.key_global.weight', 'bert.encoder.layer.4.attention.self.query_global.weight', 'bert.encoder.layer.7.attention.self.value_global.weight', 'bert.encoder.layer.2.attention.self.query_global.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (bert_encoder): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(4096, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # 这个可以拿到预训练模型最后一层的结果\n",
    "        self.bert_encoder = AutoModel.from_pretrained(checkpoint)\n",
    "        # 这里可以接分类层，输入768维，最后分为2个类别\n",
    "        # 这里可以添加其他网络模型，提升效果\n",
    "        self.classifier = nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bert_output = self.bert_encoder(**x)\n",
    "        # 取最后一层的第一个，因为我们希望拿到的是整句话的一个语义\n",
    "        cls_vectors = bert_output.last_hidden_state[:, 0]\n",
    "        # 然后输送给分类的linear层\n",
    "        logits = self.classifier(cls_vectors)\n",
    "        return logits\n",
    "\n",
    "# 如果显卡的话就使用显卡\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c310fafc",
   "metadata": {},
   "source": [
    "BERT模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdc6ec06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total param: 102269186\n"
     ]
    }
   ],
   "source": [
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(\"total param:\",total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29ec121",
   "metadata": {},
   "source": [
    "Longformer模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa43b33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total param: 105021698\n"
     ]
    }
   ],
   "source": [
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(\"total param:\",total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd16a4b",
   "metadata": {},
   "source": [
    "## 模型训练\n",
    "我们将每一轮 Epoch 分为训练循环和验证/测试循环。在训练循环中计算损失、优化模型的参数，在验证/测试循环中评估模型的性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0afe1ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm # 显示它的进度条，会更好看点\n",
    "import time\n",
    "\n",
    "# 参数解释\n",
    "# dataloader ： 批量数据的loader\n",
    "# model : 定义的模型\n",
    "# loss_fn ： 定义的损失函数\n",
    "# optimizer ：优化器\n",
    "# lr_scheduler ： 学习率根据步数会下降，动态变化的。如果用一个固定的学习率，其实是没有这种随着迭代次数下降的效果好的\n",
    "# epoch ：训练的轮次\n",
    "# total_loss ：整体loss的情况\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, lr_scheduler, epoch, total_loss):\n",
    "    start_time = time.time()\n",
    "    progress_bar = tqdm(range(len(dataloader)))\n",
    "    progress_bar.set_description(f'loss: {0:>7f}')\n",
    "    finish_batch_num = (epoch-1)*len(dataloader)\n",
    "    \n",
    "    # 获取训练集文本数据量\n",
    "    size = len(dataloader.dataset)\n",
    "    # 统计预测正确的个数\n",
    "    correct = 0\n",
    "    \n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader, start=1):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # 统计准确率\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        optimizer.zero_grad() # 把之前的梯度都清掉\n",
    "        loss.backward() # 向后传播\n",
    "        optimizer.step() # 算完梯度下降之后更改参数\n",
    "        lr_scheduler.step() # 对学习率进行调整\n",
    "\n",
    "        total_loss += loss.item() # 统计一下整体的loss\n",
    "        progress_bar.set_description(f'loss: {total_loss/(finish_batch_num + batch):>7f}')\n",
    "        progress_bar.update(1)\n",
    "        \n",
    "    # 统计训练一轮花费的时间\n",
    "    spend_time = time.time() - start_time\n",
    "    correct /= size\n",
    "    \n",
    "    return total_loss,total_loss/(finish_batch_num + batch),spend_time,correct\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # 损失函数，交叉熵\n",
    "def test_loop(dataloader, model, mode='Test'):\n",
    "    start_time = time.time()\n",
    "    assert mode in ['Valid', 'Test']\n",
    "    size = len(dataloader.dataset)\n",
    "    correct = 0\n",
    "    test_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred,y)\n",
    "            test_loss += loss.item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    spend_time = time.time() - start_time\n",
    "    print(f\"Average loss:{test_loss},{mode} Accuracy: {(100 * correct):>0.2f}%,spend time:{spend_time}\\n\")\n",
    "    return test_loss,correct,spend_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51eff93",
   "metadata": {},
   "source": [
    "最后，将”训练循环”和”验证/测试循环”组合成 Epoch，就可以进行模型的训练和验证了。其实 Transformers 库同样实现了很多的优化器，相比 Pytorch 固定学习率的优化器，Transformers 库实现的优化器会随着训练过程逐步减小学习率（这通常会产生更好的效果）。 这个代码中，我们顺便还增加了torch.save(model.state_dict(),'xx')用于保存模型的参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d5f2b7",
   "metadata": {},
   "source": [
    "## 训练时间：2023.1.29\n",
    "BERT模型，batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09f3cec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb6fbd54da146b4a1273f70da50b53c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.04968813331952939,Valid Accuracy: 93.08%,spend time:14.029417514801025\n",
      "\n",
      "saving new weights...\n",
      "\n",
      "Epoch 2/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3070c9feb1541318c65df23c0f3ef98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.047858832363708644,Valid Accuracy: 94.50%,spend time:14.231317281723022\n",
      "\n",
      "saving new weights...\n",
      "\n",
      "Epoch 3/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd59ad5f2f24be8ba24e3d49a7660c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.050869001614179676,Valid Accuracy: 94.50%,spend time:14.449248313903809\n",
      "\n",
      "Epoch 4/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc6e513c2c74eb0bc48ce1c9384ca05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.05125583186075043,Valid Accuracy: 95.33%,spend time:14.512727737426758\n",
      "\n",
      "saving new weights...\n",
      "\n",
      "Epoch 5/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5395223a8be44d8d89378db27239a253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.07402743661689025,Valid Accuracy: 94.58%,spend time:14.58841323852539\n",
      "\n",
      "Epoch 6/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68618386dca24fb084f6df590a1b07c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.06900786061080338,Valid Accuracy: 95.33%,spend time:14.299227952957153\n",
      "\n",
      "Epoch 7/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245a7761c48e4641888ac65b9712ecdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.07922388693049148,Valid Accuracy: 95.33%,spend time:14.718741655349731\n",
      "\n",
      "Epoch 8/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59514da127c480fa0c11fb87733ac57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.09225498609690892,Valid Accuracy: 95.17%,spend time:14.40510106086731\n",
      "\n",
      "Epoch 9/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "170b2f13ea5e446fbfa992f87ca10665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.09413700093128806,Valid Accuracy: 95.33%,spend time:14.482509851455688\n",
      "\n",
      "Epoch 10/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f94f5c88d44f42a9b474426512f9d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.09501666139626092,Valid Accuracy: 95.00%,spend time:14.658767461776733\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "import pandas as pd\n",
    "\n",
    "learning_rate = 1e-5 # 定义学习率\n",
    "epoch_num = 10 # 批次定义\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # 损失函数，交叉熵\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate) # Adamw一个常用的优化器\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",# 使用线性的方式，慢慢往下降\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=epoch_num*len(train_dataloader),\n",
    ")\n",
    "\n",
    "# 文件名写错了，是BERT.csv文件\n",
    "csv_file_path = \"./output/Longformer.csv\"\n",
    "total_loss = 0.\n",
    "best_acc = 0.\n",
    "for t in range(epoch_num):\n",
    "    print(f\"Epoch {t+1}/{epoch_num}\\n-------------------------------\")\n",
    "    total_loss,mean_loss,train_time,train_correct = train_loop(train_dataloader, model, loss_fn, optimizer, lr_scheduler, t+1, total_loss)\n",
    "    valid_loss,valid_acc,valid_time = test_loop(valid_dataloader, model, mode='Valid')\n",
    "    list = [total_loss,mean_loss,train_time,train_correct,valid_loss,valid_acc,valid_time]\n",
    "    data = pd.DataFrame([list])\n",
    "    data.to_csv(csv_file_path,mode='a',header=False,index=False)\n",
    "    if valid_acc > best_acc:\n",
    "        best_acc = valid_acc\n",
    "        print('saving new weights...\\n')\n",
    "        torch.save(model.state_dict(), f'./output/epoch_{t+1}_valid_acc_{(100*valid_acc):0.1f}_model_weights.bin')\n",
    "print(\"Done!\")\n",
    "\n",
    "# 它会去保存最好的那个模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652d2c4",
   "metadata": {},
   "source": [
    "## 训练时间：2023.1.29\n",
    "BERT模型 batch_size=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64a8631c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675de92d23b640b29e7ccab7a01ccd59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.17263017619154805,Valid Accuracy: 94.17%,spend time:14.83849549293518\n",
      "\n",
      "saving new weights...\n",
      "\n",
      "Epoch 2/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d968e169d7b74fe0adf90e8fd0942a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.17262746797041473,Valid Accuracy: 94.50%,spend time:14.813286542892456\n",
      "\n",
      "saving new weights...\n",
      "\n",
      "Epoch 3/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c081144c4cc54c3cbbf6b94371ef0810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.17637615840415796,Valid Accuracy: 94.50%,spend time:14.840280055999756\n",
      "\n",
      "Epoch 4/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138aef6606d74a0f9240c9e33cf15309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.1844705803383787,Valid Accuracy: 94.83%,spend time:14.884601831436157\n",
      "\n",
      "saving new weights...\n",
      "\n",
      "Epoch 5/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4aecc182b9245ea80386c30dec19ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.2177017953835669,Valid Accuracy: 95.17%,spend time:14.799476146697998\n",
      "\n",
      "saving new weights...\n",
      "\n",
      "Epoch 6/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2ec240b17f420c933a2d3f7de51c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.268607812890942,Valid Accuracy: 94.50%,spend time:14.676802396774292\n",
      "\n",
      "Epoch 7/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27c0e1bcb83944a6bf2587172b56363b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.2878739726404522,Valid Accuracy: 94.58%,spend time:14.853984594345093\n",
      "\n",
      "Epoch 8/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6c1a9ab991403f9e3c654648bc04b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.3614182579467776,Valid Accuracy: 94.75%,spend time:14.744924306869507\n",
      "\n",
      "Epoch 9/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431d3c18649747798acff5bd4e1c9813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.42459279056322685,Valid Accuracy: 94.83%,spend time:14.851120710372925\n",
      "\n",
      "Epoch 10/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe31954be9624c90ab66934f92301ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss:0.40238378551265747,Valid Accuracy: 95.08%,spend time:14.854574203491211\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "import pandas as pd\n",
    "\n",
    "learning_rate = 1e-5 # 定义学习率\n",
    "epoch_num = 10 # 批次定义\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # 损失函数，交叉熵\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate) # Adamw一个常用的优化器\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",# 使用线性的方式，慢慢往下降\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=epoch_num*len(train_dataloader),\n",
    ")\n",
    "\n",
    "# 文件名写错了，是BERT.csv文件\n",
    "csv_file_path = \"./output/BERT_batch_size_2.csv\"\n",
    "total_loss = 0.\n",
    "best_acc = 0.\n",
    "for t in range(epoch_num):\n",
    "    print(f\"Epoch {t+1}/{epoch_num}\\n-------------------------------\")\n",
    "    total_loss,mean_loss,train_time,train_correct = train_loop(train_dataloader, model, loss_fn, optimizer, lr_scheduler, t+1, total_loss)\n",
    "    valid_loss,valid_acc,valid_time = test_loop(valid_dataloader, model, mode='Valid')\n",
    "    list = [total_loss,mean_loss,train_time,train_correct,valid_loss,valid_acc,valid_time]\n",
    "    data = pd.DataFrame([list])\n",
    "    data.to_csv(csv_file_path,mode='a',header=False,index=False)\n",
    "    if valid_acc > best_acc:\n",
    "        best_acc = valid_acc\n",
    "        print('saving new weights...\\n')\n",
    "        torch.save(model.state_dict(), f'./output/epoch_{t+1}_valid_acc_{(100*valid_acc):0.1f}_model_weights.bin')\n",
    "print(\"Done!\")\n",
    "\n",
    "# 它会去保存最好的那个模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33258a1a",
   "metadata": {},
   "source": [
    "## 训练时间：2023.1.30\n",
    "Longformer模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79ed78c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf84923a41b4f408de6f9ee423b3695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 88.00 MiB (GPU 0; 14.76 GiB total capacity; 13.10 GiB already allocated; 77.75 MiB free; 13.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2317137/47209551.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}/{epoch_num}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmean_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_time\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_correct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_acc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_time\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2317137/1624975839.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer, lr_scheduler, epoch, total_loss)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2317137/2892133276.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mbert_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m# 取最后一层的第一个，因为我们希望拿到的是整句话的一个语义\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mcls_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1006\u001b[0m         )\n\u001b[1;32m   1007\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    587\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m                 )\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         )\n\u001b[1;32m    477\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         )\n\u001b[1;32m    410\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;31m# seem a bit unusual, but is taken from the original Transformer paper.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;31m# Mask heads if we want to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anaconda/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 88.00 MiB (GPU 0; 14.76 GiB total capacity; 13.10 GiB already allocated; 77.75 MiB free; 13.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "import pandas as pd\n",
    "\n",
    "learning_rate = 1e-5 # 定义学习率\n",
    "epoch_num = 10 # 批次定义\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # 损失函数，交叉熵\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate) # Adamw一个常用的优化器\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",# 使用线性的方式，慢慢往下降\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=epoch_num*len(train_dataloader),\n",
    ")\n",
    "\n",
    "# 文件名写错了，是BERT.csv文件\n",
    "csv_file_path = \"./output/Longformer_batch_size_2.csv\"\n",
    "total_loss = 0.\n",
    "best_acc = 0.\n",
    "for t in range(epoch_num):\n",
    "    print(f\"Epoch {t+1}/{epoch_num}\\n-------------------------------\")\n",
    "    total_loss,mean_loss,train_time,train_correct = train_loop(train_dataloader, model, loss_fn, optimizer, lr_scheduler, t+1, total_loss)\n",
    "    valid_loss,valid_acc,valid_time = test_loop(valid_dataloader, model, mode='Valid')\n",
    "    list = [total_loss,mean_loss,train_time,train_correct,valid_loss,valid_acc,valid_time]\n",
    "    data = pd.DataFrame([list])\n",
    "    data.to_csv(csv_file_path,mode='a',header=False,index=False)\n",
    "    if valid_acc > best_acc:\n",
    "        best_acc = valid_acc\n",
    "        print('saving new weights...\\n')\n",
    "        torch.save(model.state_dict(), f'./output/epoch_{t+1}_valid_acc_{(100*valid_acc):0.1f}_model_weights.bin')\n",
    "print(\"Done!\")\n",
    "\n",
    "# 它会去保存最好的那个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaab4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8804efb",
   "metadata": {},
   "source": [
    "# 模型保存和加载\n",
    "模型的保存有2种方式，第一种是将模型和权重参数分开保存。第二种是一起保存。通常我们会选用前一种，因为权重参数会有多个版本，我们可以保存一份模型后读取权重参数文件。\n",
    "\n",
    "第一种方法的模型保存已经在上面演示过了。 为了加载保存的权重，我们首先需要创建一个结构完全相同的模型实例，然后通过 Model.load_state_dict() 函数进行加载"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6790fb7f",
   "metadata": {},
   "source": [
    "### BERT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23d2f8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (bert_encoder): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')\n",
    "checkpoint = \"bert-base-chinese\"\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.bert_encoder = AutoModel.from_pretrained(checkpoint)\n",
    "        self.classifier = nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bert_output = self.bert_encoder(**x)\n",
    "        cls_vectors = bert_output.last_hidden_state[:, 0]\n",
    "        logits = self.classifier(cls_vectors)\n",
    "        return logits\n",
    "\n",
    "# 先把模型的类加载一下\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51471be",
   "metadata": {},
   "source": [
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4e2c618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (bert_encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device) # we do not specify pretrained=True, i.e. do not load default weights\n",
    "model.load_state_dict(torch.load('./output/epoch_4_valid_acc_95.3_model_weights.bin'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc69f61f",
   "metadata": {},
   "source": [
    "batch_size=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54f7d0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (bert_encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device) # we do not specify pretrained=True, i.e. do not load default weights\n",
    "model.load_state_dict(torch.load('./output/epoch_5_valid_acc_95.2_model_weights.bin'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abe6a330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "\n",
    "def test_loop(dataloader, model, mode='Test'):\n",
    "    assert mode in ['Valid', 'Test']\n",
    "    size = len(dataloader.dataset)\n",
    "    correct = 0\n",
    "\n",
    "    # 存储真实值和预测值\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch, (X, y) in enumerate(dataloader, start=1):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)     \n",
    "            # 添加到列表里\n",
    "            y_true.append(y.tolist())\n",
    "            y_pred.append(pred.argmax(1).tolist())\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    correct /= size\n",
    "    print(f\"{mode} Accuracy: {(100*correct):>0.1f}%\\n\")\n",
    "    \n",
    "    y_true = [i for k in y_true for i in k]\n",
    "    y_pred = [i for k in y_pred for i in k]\n",
    "    # 混淆矩阵\n",
    "    my_confusion_matrix = confusion_matrix(y_true,y_pred,labels=[0,1])\n",
    "    # 准确率\n",
    "    my_accuracy_score = accuracy_score(y_true,y_pred)\n",
    "    # 精准率\n",
    "    precision_score_micro = precision_score(y_true,y_pred,average='micro')# 推荐使用这个\n",
    "    precision_score_macro = precision_score(y_true,y_pred,average='macro')\n",
    "    precision_score_weighted = precision_score(y_true,y_pred,average='weighted')\n",
    "    precision_score_None = precision_score(y_true,y_pred,average=None)\n",
    "    precision_score_dict = {\n",
    "        \"precision_score_micro\":precision_score_micro,\n",
    "        \"precision_score_macro\":precision_score_macro,\n",
    "        \"precision_score_weighted\":precision_score_weighted,\n",
    "        \"precision_score_None\":precision_score_None\n",
    "    }\n",
    "    # 召回率\n",
    "    recall_score_micro = recall_score(y_true,y_pred,average='micro')\n",
    "    recall_score_macro = recall_score(y_true,y_pred,average='macro')\n",
    "    recall_score_weighted = recall_score(y_true,y_pred,average='weighted')\n",
    "    recall_score_None = recall_score(y_true,y_pred,average=None)\n",
    "    recall_score_dict = {\n",
    "        \"recall_score_micro\":recall_score_micro,\n",
    "        \"recall_score_macro\":recall_score_macro,\n",
    "        \"recall_score_weighted\":recall_score_weighted,\n",
    "        \"recall_score_None\":recall_score_None\n",
    "    }\n",
    "    # F1 score\n",
    "    f1_score_micro = f1_score(y_true,y_pred,average='micro')\n",
    "    f1_score_macro = f1_score(y_true,y_pred,average='macro')\n",
    "    f1_score_weighted = f1_score(y_true,y_pred,average='weighted')\n",
    "    f1_score_None = f1_score(y_true,y_pred,average=None)\n",
    "    f1_score_dict = {\n",
    "        \"f1_score_micro\":f1_score_micro,\n",
    "        \"f1_score_macro\":f1_score_macro,\n",
    "        \"f1_score_weighted\":f1_score_weighted,\n",
    "        \"f1_score_None\":f1_score_None\n",
    "    }\n",
    "    # 综合指标\n",
    "    general_index = {\n",
    "        \"accuracy_score\":my_accuracy_score,\n",
    "        \"precision_score\":precision_score_dict,\n",
    "        \"recall_score\":recall_score_dict,\n",
    "        \"f1_score\":f1_score_dict\n",
    "    }\n",
    "    \n",
    "    \n",
    "    return correct,my_confusion_matrix,general_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0b290f",
   "metadata": {},
   "source": [
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fb8b952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 95.3%\n",
      "\n",
      "valid_acc:0.9533333333333334\n",
      "confusion_matrix:[[569  23]\n",
      " [ 33 575]]\n",
      "general_index:{'accuracy_score': 0.9533333333333334, 'precision_score': {'precision_score_micro': 0.9533333333333334, 'precision_score_macro': 0.9533605928954767, 'precision_score_weighted': 0.9534696311440498, 'precision_score_None': array([0.94518272, 0.96153846])}, 'recall_score': {'recall_score_micro': 0.9533333333333334, 'recall_score_macro': 0.9534361664295875, 'recall_score_weighted': 0.9533333333333334, 'recall_score_None': array([0.96114865, 0.94572368])}, 'f1_score': {'f1_score_micro': 0.9533333333333334, 'f1_score_macro': 0.9533321666374994, 'f1_score_weighted': 0.9533352778263903, 'f1_score_None': array([0.95309883, 0.95356551])}}\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "valid_acc,confusion_matrix,general_index = test_loop(test_dataloader, model, mode='Test')\n",
    "print(f'valid_acc:{valid_acc}')\n",
    "print(f'confusion_matrix:{confusion_matrix}')\n",
    "print(f'general_index:{general_index}')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "171c4314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEZCAYAAAC+bm+MAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmYUlEQVR4nO3dd5xU1f3/8ddnZpZeBCwoTRAxGiPWaEQRsCZiQ40NC5ogaizRGDWJETUajd+Y2BW7/Cyxt6ixocZGxCjYogiioii9t525n98f9y47uzuzzCw7s3fh/fRxHzNz7rnnnrusnzn7uefea+6OiIjEV6KpOyAiIvVToBYRiTkFahGRmFOgFhGJOQVqEZGYU6AWEYk5Bep1lJmdY2aTzWylmc01s1vKtF83s7vKsa+1jZkNin5+JzR1X6S8Uk3dASk/MzsW+D/gH8BfgPbAxmXa/Qjg8zLtq8mY2XrAWcAr7v5KIzX7P8Kf3+uN1J40E6YLXtY90eh5JNDS3Vc2dX/WRma2KfAFcLG7j27a3khzp9THuqklgIK0SPOgQN1EzGwnM3vOzBaZ2Wwze8HMds1Rr7+ZPR3VW2hmj5vZVrXqTDOzV8ysq5k9ZGbzzex7M7vWzCqiOlX5TQeOj8o8a9k0q72ceWQz+7x2uZkdY2bvRv2bZWZP1e5frfr15qjNbI/oWJaa2RwzG2tm3XO1YWZbRD/DxWY23cz+mK/devZX9bP7k5ktMLOJZradmY0zsyVmNjarbkszGx3l9pdF215tZu2y6rwS/Yy/iIouyvoZ31Vr36tyzmbWJfr3mmZmV+Xpa94ctZltHP283jWzRFb5v6KfZb9ifzYSHwrUTcDMhhDmGX8IXA78GegJvGpme2TV2xV4C9geuAK4CtgVGG9m29dqtiPwKuF5h98DU4DTgdOi9VX5zRHAG1HZiKxldgOO4xDg/wHzgPOiPm4BvGhmbRrQ3mHAS4T58ouAMcAhwH/MrGet6j2B14BvgQuAhcDFZnZwsfsl/Jn2J8zZbwO8CfwXmAAMN7Ntono3Rf16hTD//DhwBvDXrLauIPx5nht9foLqn/FtefbfNdrfMGAc8G6xB+DuM6K+bA+cAqt+nvsAf3D3z4ptU2LE3bWUeQE+IwxuXbPK+gAOPJBV9hGwAOhWq94S4J2ssmnRtrdnlXUBKoGncuz/rvCfPm//HLgrR/nn2eXAdVHdjlllOwI3Az2LbLs1MCs6lnZZ5bsCAfBQrTacMABVlfWPyq4r8t9iGjAHaAX0i9r4Z7RuZPR5EOEX4KPAFbW2fwaYmaPdTaNtR9ez70FRnSWEX3ip1fS1qv4J9dR5NPrd2hT4inBAkGjq33kta7Zo1keZmdnmwObAbe7+XVW5u08FLKteX2Ar4A53/ya7npk9ARxlZt2y1q0Ezs+qN8fMZhDO6CiVfwO/Aq41s7uB9919AuFItFgDgPWBa919cVWhu79pZm8DQ80s6e6ZaNV3hH9hVPkgem3I8X7i7svNrCpn/170uiqH7+5pYJiFfkg4ct0DGEwY5NfEt8CIaB9rahThF/x/gLbAEHcPGqFdaUJKfZTfhtHrN/XWgo2i1+k51n1dqw7AZHefVateY/8P2iH7g7s/SJha+RHwHDDHzD6Ipv8Va3XH24owvVPlXXdfkdWXNTnW2gEyZ8A0s18QfkF8CFxJ+MXyyRrst8o17l7ZCO3g7jOB+4ANCP+aWuunQq4LFKjLb2b02q32CjO71KovPPk+eu1eux7Qo1YdaECOuRhm1pXwf/4a3P1Gd9+ecPS2IzAVuMfMdi9yF6s73uWEaaAqJT3e2qLzBbcS5qc3cfdN3P1gYFIjNL949VUKY2ZbAycT/jscbmYDG6ttaToK1GXm7pOByYR/RleNrjGzLsCZhCeziEZCHwOHmtkmWfU2BQ4iHFGublTeUEuATWqV/aF2JTN70cxei/pb6e7vAqOj1TsVuc83CHPFJ5pZ26x97ALsTJg3zuTbuAx+Er3e6uGJO6LZKPvlqT+HKH9fhr4R9acFcC8wA9iB8EvkHjPrUO+GEnvKUTeNUwhPQk0ws5sIc6EnEZ5Qyw6Io4DngXfM7AbCL9bTCQPAqBL2bxzwMzM7mnAmyUmEXw5zatX7NzA6ypk/DySBE4EM4YyMgrn7MjM7FbgfeNfMbgM6Ex7vLOA3DT+cRjExev1zdP6gD+HPpR2AmbV292VVld19kZm9CoyIzhUsIMxrP+TuL5aoj5cRftHv7e7zzWwE8A5wPXBcifYpZaARdRNw95eA3Qjzm78nPAn4JbBLtK6q3r8JZz1MBH5HOAVufFSvISfsCjUKeJZwOtqHhDnoAcD8WvUuIfzS6U4YJP5EOBo/sCH9i3LeexOmhy6N+vEk8GN3n9aA42g0UXA9FVgPuAY4mHBa5V+iKkNzbHYM4c/xt4TBchA10zeNxswGAWcTnqR+Merz+4S59GPN7Oel2K+Uhy4hFxGJOY2oRURiToFaRCTmFKhFRGJOgVpEJOZiOz2v8vtPdZZT6mjdY0hTd0FiKL3yG1t9rfpVzp5acMypWL/PGu+vGLEN1CIiZRU05fVU9VOgFhEBiPG9qxSoRUQAAgVqEZFYi/PdYBWoRUQAMo1xO/DSUKAWEQGdTBQRiT2lPkREYk4nE0VE4k0nE0VE4k4jahGRmMs0yvOFS0KBWkQEdDJRRCT2lPoQEYk5jahFRGJOI2oRkXjzQCcTRUTiTSNqEZGYU45aRCTmdFMmEZGY04haRCTmlKMWEYk5PThARCTmNKIWEYk3d51MFBGJN42oRURiLsazPhJN3QERkVgIgsKXepjZTmY23cxej5b+Zva0mU00s7EWalW7rL42FahFRCCc9VHoUr9OwE3uvpu77wbsBEx39/7Rur2B4TnK8lLqQ0QEGjP10Qk41MwOAr4GVgIPR+teBgYDvYBHapU9n69BjahFRKCo1IeZjTSzCVnLyKyWPgcudPcfAxsDw4AF0bqFQGegS46yvDSiFhGBomZ9uPsYYEye1dOAD7Pebwd0jD53BGYD7XKU5aURtYgIhKmPQpf6nQ0caWYJYGvgHGCfaN0QYBzwUo6yvBSoRUSgMU8mXg+MAMYDjwG3A93MbBIwlzBI35ujLC+lPkREoNEueHH3GcCgWsVDa31ekaMsLwVqERGI9QUvCtQiIqBLyEVEYk+BWkQk5tybugd5KVCLiACk9eAAEZF408lEEZGYU45aRCTmlKMWEYk5jahFRGJOgVpEJN48o4fbiojEm0bUIiIxF+PpebrN6WrY629T0fUHOZfEhZcX1VbykGPztpU84/wSHUHksykkjzmZ1OY7kuq3E8kTToOvptetN3lqWG+z7Un13o7kESfCJ5+Wtm+S1xZeyZPpOcyrnMGCyhk8m57D1l5Zo87mnuap9BwWVM7g68rvuC89l24e3z/jYyvwwpcy04h6dRYsBCBz5sl471411/XrW1RTwekjCY44pEaZzfie5JXX4K1br1E3k4ccCz26kbn2irorZ3xP6uBjoj78EjIBiRtvJ3XIsaRffgI6dgjrzZ1HathxsHQpwaknQSYT1vv5SaTffA7at1ujPkpxOnvAS+k5tMX5a6IdSZzfBIt5Lj2HLVMbssgStPWAf6Xn4MDFifa0xTkrWMx26dlsl9qQ5fU/3FqyKfXRjEWBOjj0QOi32Ro15UN2r1Nmt9wVrhs0YI3ark/yr9djc+eTfuRufMDO4f569yI16mwSt40lOOc0ABL3PYLNmk365r/iB+8fblxRQfLKa0g89ATBiceUrI9S14nBEroScHSyEw8mwi/ySoxLgkUMD5ZxU7ItpwZL6EmG/qkN+MgqAJiP8bdgIQf4ch6yNRsArFNifDJRqY/VsHnR8yc36FKa9p95AW/dGt+jRIG6shJ74lm8b+9VQRrAh+6Dd2hP4tGnqvvy3sRwXVZffJsfhm8+n1qa/kleP45SHC9Yy1Vl/42C8RaE96XY0Sv5guSqIA0w2cLx16Ye33tXxFIRD7ctN42oV2fBAryigsQjT5G46Q6YORs225TMhefiew5cs7ZnzcbeeQ/fb09oU2vk87/JJP9yLfbmfyCTwX/4A4Lzz8J32TFcv2QJLFlaXb+yEpavgJmzqsvatoHPv8AWLSbYd8+a7adS+FZbkHh7AsydB507EfxsH3zrrWC9jtX1vp8ZvmaXSVk8lmjF+17BPKrTFxsTjvqqyo5I1X149VZRgP7akmXo5VqkCXLPhSppoDazvYDBhI9Cnw2Mc/eXS7nPRjd/IVZZSeLG2wlGHA3uJG64neTxp5J+5Uno26fBTSeeeRELAjI/3avmig8+JnXQcOjdk+CsUZBKYg8+QXLYcWQeuhMfsDOJG+8g+dcbarX4Poknn131KXPOafiW/QDwrhvW7cCGG4Sv07+Fzp3wQw+gxq9qOk3irvtxM4L99qy7vZTU/Yk2NT4n3Tk5WEoAPJloVad+V8+wh6/gvGARn5PkKatbR+oR41kfJQvUZnY3YYB+GZhK+Ej0s83sOHc/oVT7bXQ9uhHstQeZKy6C7psA4D27kxp1Dskb7yBz9Z8a3LQ98zxeUYHvM7hGefKiK6B9W9J3Xg+toj97hwwkNfhAErfcRWbAzgSHHYjvsG31NpdehW+wPsGoEavKvHdPbML74YeKHP/ULcI/l23ZcuqMJYKA5HkXk5j0EZnTfgFVKRBpEubODZkF7OiVXJVox3vWok6dWzLz2d9X8A0JDk11Zokps1mUdXREvY27b1er7Gozez/fBmY2EhgJcONVF/OLY48oYfcKE5z+Szj9lzXKfPddwzefTm54wwsWYm++g++6U/WsC4Cly7Dx72KZDBU/3qvudh/9L3zt3avGLBS/bgx03bDuCcuPo6l1CxfVbSsq89pplxUrSZ5xPoknniFz3BEEfzin2KOTRtTCnTsz8zjCl3NLog0XJNrnrPfnRHvGeUvOCJYwLj2bvVLrMykrdy3183V01sd0M7sReAFYQDii3gf4Ot8G7j4GGANQ+f2n8f16a9cWAJu/oMFN2L9exiorCX66d80VCxZimQzB4N0Ifnl83Q1bFPc/nvfqEe5v9ty6K+dEZT26VZctXUZy+Mkk3vwPmV+fQnDemUXtTxpXaw94KjOXQb6SyxLtuCjZIW/dtxMteJsWvG4teDszm9GZRQzLkcOWPGI866OUgfowYHj02oUwR/0S0Hz+z587j9QhxxEM/AnBpb+rLv8uPMHmG3dtcNOJfz4f5X6H1FzRsQOeTEIiWXd0POULWLykuB39YHO8Q3ts/ISa5cuWYx9+gm++WfWJwiAgedIZ2FvvkLniIoITjipuX9KozJ2HMvMY6Cs5LdGRW5Jta6zv4hleTc/hhURLfp2sPtn7UTTro59mfRQnxqmPkiWx3H2Fu9/u7se4+37uPtzd73T3laXaZ6PrtB7MnhOeoFu+YlVx4ol/AjR81seSpdirb+A79IeuG9Vc16Y1vvMO2Jvjw5N8q7ZZQurAY0j95o85m8w8Njb3xS6pFMHB+2PfzcRee3NVsT37ArZiJcGwodXHddtYEuP+TXDu6QrSMXB6sIT9fAUXJ9rXCdIAc0mwPgEHBctpkXUv5appfVM166M4mp7XTJkRnDWK5IWXkxx2HD5sf/jqGxJ33ItvsTnB8VEw++JLbPy7+M47QO2rF3M1+9Jr2PIVddMekczF55M6aDipfQ8LA2an9bCHn4R588n87bKiDyM4+xQSTz9H8uRfE5xyYnhl4g234d02JjhpeFhp2XISf78Z79gB77oh9sCjNRtp2wY/YL+i9y0N08qdC4LFzMP41hIcFyytsX4xxqOJ1lyZaMdVwUJeyszmH9aa9jinBktYQZizliLEeERtHtOnGsQpR233PUzy5rvgiy/D1MR+Q8j87mzo3Clc/8CjpM76Hem/X44fOWy17SVHnU3i8WeofOtf+QP7J5+F86jfGA9BgG+9JcE5p+G7/6RhBzF5KsnRV4YpEDN8wM5kLrkAenYP1381PffJy4h334T0hKafWdm6x5DVV1oL9PI0U9Iz866fRpK+FeFfY4cEyzgnWMyWnmYZxn+sBaOT7depE4npld+s8bXySy78ecExp+2lD5b12nwFamlW1pVALcVplED9+8MLD9SXPVTWQK3Uh4gI4Ol1c9aHiEjzEeMctQK1iAism5eQi4g0KxpRi4jEm8c4UOuuLSIiAOlM4UsBzOxsM3vRzFqZ2dNmNtHMxlqoTll9bSlQi4hAoz4z0cx6AVU36xkOTHf3/kAnYO88ZXkpUIuIQFGB2sxGmtmErGVkrdauAS6I3g8hvDkdhLd9HpynLC/lqEVEgGIu/su+02dtZnY0MBH4OCrqQngHUYCFwBZ5yvJSoBYRgcac9TEU6AnsSxiAA8LbPBO9zgba5SjLS6kPERFotBy1ux/t7rsBRwLvAucS3osfwpTHOMJbPtcuy0uBWkQE8HRQ8FKke4FuZjYJmEsYpHOV5aXUh4gIhAmKRuTu04CqW1IOrbV6RY6yvBSoRUSI9wUvCtQiIqBLyEVEYi++92RSoBYRAaU+RERiz9MK1CIi8abUh4hIvMX4uQEK1CIigEbUIiJxpxG1iEjMebqpe5CfArWICBpRi4jEngK1iEjceb2PLWxSCtQiImhELSISex5oRC0iEmtBRoFaRCTWlPoQEYm5Zpn6MLOBhTTg7q81XndERJqGx/fmefWOqO8uYHsH+jRSX0REmkyzHFG7e+9ydkREpCnpZKKISMw1yxG1iMi6xGN8ZWJiTTY2s20bqR8iIk3Kg8KXcitoRG1mA4AxQD9qBvcAqChBv0REyiqI8Yi60NTHzcCtwHrA5sCfos/3lqZbIiLlFefUR6GBujdwH9AFeNjdPzGz04CHgJtK1TkRkXKJ86yPQnPU7wEXA1OBzma2DdAa2KhUHRMRKScPrOCl3AodUY8Ebgc6AZcTBm4HritRv0REyqrZ56jd/RNg1+jjdWb2JNDe3T8sWc9ERMqo2eeo8933w8wG6l4fIrI2aK73+siWfd+PtsD6wApgBrrXh4isBRor9WFmKeB+YBPgU+BU4GGgBzAJOA5oWbvMPf9XRUEnE929d9ayIeEskH8Clzb8cERE4iMIrOBlNQ4GJrr7AGBj4FfAdHfvT3ieb29geI6yvBp0ZaK7fwkcAZzVkO1FROImcCt4WY3ngKujkfV6wPbAC9G6l4HBwJAcZXk16F4fZmbALsAGDdm+EO171fsFI+uoZd/+u6m7IGupYk4mmtlIwtlwVca4+5iwHV8c1RlPmB7uAiyI6i0EtshTllehJxMDwul42SqB8wrZXkQk7orJUUdBeUyudWbWBVhMOFPuZaAv0DFa3RGYDbTLUZZXoamP3oQnDauW3sB67n5NgduLiMSaF7GsxjnA4e6eAZYClwH7ROuGAOOAl3KU5VXoPOova5eZWYWZtXb3ZYW0ISISZ5lgjW4mmu0GYGx0m40phBcLPmJmk4CJhEG6BTCsVllehaY+7gBOdfflWcU/Ae4ENiv2KERE4qax7l7q7t8QjpKzDa31eUWOsrwK/Qo5nvAbINunhPMERUSaPccKXsqt3hG1mR1X9RY42syWZn3eE3inhH0TESmboBlfmTgienXgGCAdfQ6Az4CjStQvEZGyCppgpFyoegO1uw+GVdPz9nf3hWXplYhImTVFSqNQhV7wcjth8ltEZK2UiXGgLvReH7909xVmlgQws82iyyNFRNYKQRFLuRUUqM1sWzObAhwaFT0CfGZmW5esZyIiZdTsAzVwI/Ag4R3zAHYA7orKRUSavThPzys0UP8IuNbdlwBEl0beBmxbon6JiJRVYIUv5VZooJ5I9VS9KiOADxq3OyIiTSPACl7KrdATgqcCz5nZ8cA0wpsytQN+WqJ+iYiUVaapO1CPQm/KNMnM+hFem94D+IrwkvJzCB8rIyLSrAUW3+l5hd6UqQXhgwK2J7w134+AOYT3WhURafZifAV5/kAdTb3bJ1oGEj6F4C3CJxH8DHi+vocxiog0J00x7a5Q9Y2oJxF+ybwCDHP35wDMbB7wiYK0iKxNmmI2R6HqC9TbEz4Zdx/gUTNbTDiibkU4qv6q9N0TESmPZnkJubu/7+5XufveQGfCk4afR8u/zGymmd1fpn6KiJRUnOdRFzrrYznhI9Cr0h8bA/sCe5WuayIi5dNcc9R5ufsMwkvI72rMzoiINJU4n3TTHfBERGi+JxNFRNYZa13qQ0RkbZPRiFpEJN40ohYRiTkFahGRmNOsDxGRmNOsDxGRmFPqQ0Qk5pr9gwNERNZ2Sn2IiMScUh8iIjEX51kfhT6FXERkrRbgBS+rY2Z3m9nbZvakmbUzs6fNbKKZjbVQq9pl9bWnQC0iQngysdClPma2G5By912ADsCJwHR37w90Inwgy/AcZXkpUIuIEOaoC11W43vgmuh9AhgNvBB9fhkYDAzJUZaXctQiIhQ368PMRgIjs4rGuPsYAHefHNU5hDCuvwcsiOotJHyUYZccZXkpUIuIQEG55ypRUB6Tb72ZHQicARwA3Ax0jFZ1BGYD7XKU5aXUh4gI4ayPQpf6mFlX4FxgqLsvAl4ifEg4hCmPcXnK8lKgFhGhUXPUxwMbEz4E/HWgAuhmZpOAuYRB+t4cZXkp9SEiAmQaaSa1u18JXFmr+JZan1cAQwttU4FaRARdmSgiEnvFnEwsNwVqERF0CbkUoG9QyeOVs5izYjpfrPiGsZWz6ebpoutIedjrb1GxwWY5l8TvLy2+wa+/IXnS6aR+sBOprX9C8vTfwqx6Z2w1js8+J3nUSaT69Ce12bYkjzsZvppet97kKWG9Tbch1WtrkocfDx9/Wvr+lVEjnkxsdBpRx0BbD3i2chYOXJrsQFucMzKL2K5yFjtWbMRySxRUR8po/kIAMmedgvfZtOa6LTYvrq1vZ5Da+2Bo2YLgV7+EFStJjLmL1JvjSY97Gjq0b3A3kwcdDT26kbn+qrorZ3xH6oAjAQjOGAWZDIkbbiV14JGkX30GOnYI682dR+qgo2HpsrB/mQyJ68eQOuw40uNfhPYN71+cNNbJxFJQoI6BUZnF9CDD9hUb8XGiBQDzSfDXzHyGBst5ONmmoDpSRvPDi8qCww+Gfn3XqKnEbfdgc+aSfuof+C47AuCbb0bqpF+RuO9hglEj1rS3OSWvuhabO4/04/fiA3YJ99tnU1IjzyRx690Evzk97N+9D2KzZpMe83f8kAPCjVMpklf8jcSDjxOcdGxJ+lducc5RaxgWAzv4SqaRXBWAASZb+B3aK0ptFFJHysfmzw/fbLD+mrc1eSoA3n/rVWWr3n8+ZY3bz6myEnv8n3jfPquCNIAfsB/eoT2Jh5+o7t+7E8N1g3av27/JJepfE2isC15KQYE6Bo6uWJ8ftNykRtlWXgnAdEsWXEfKaP5CvKKCxMNPkNp2N1Kb/IDUwJ9iL75SdFO+YRTsZ85aVWbffR++2XCDmpX/9xnJE04htfn2pPr0J3ngUdhb71SvX7wEvp9VvVSuhOXLa5YtXgIf/w9btBjffpua7adS+A+3xKZ8AXPnARAM3ZfM+b+G9TpW1/tuZvjaab2ijzeuGvM2p41NqY+Y6eoZBgbLOTeziCmkeDrRukF1pMQWLMAqK0lcP4bgxGPBncT1Y0geezLpfz8LffsU3FQwYjiJh58k+ZsLyYw+H1u5ksSFl+HrdyY45vDqipM+CnPKvXsRnH0aJJPYg4+RPPhoMo+OxQfsQuLG20hedW2tPbxH4olnVn3KnHsGvmV4DyDfaKO6Har64vj6G+jcCT/soJqhKZ0mcde9uBnBfnsVfJxxp3nUUrAb03P5WbCcb0hyeEUXluQ4SVhIHSmxHt0J9h5M5i+XQPfwLx3v1Z3UyLNIXn8rmb//ufC2tt6SzO3XkTzhFCoG7R+21a4dmUfugW7Vf0Ul/3gZtG9H+p6boWXLsHDPPUjt8TMSN91BZsAuBIcdhO+wbfU2l1yJb7A+wSknrSrz3r2wCe+FHypyhIAWYXrNli2vO3YMApLnXkhi4odkTh8JWema5s5jnKOOVaDOvnVgKtWJZLJdE/eo/K5MduAVa8XpmUW8WDmLfSs24IOsvHShdaS0gjNOhjNOrlHmAweEbz6dXFRb9szzJEeeiQ8eSGbYUKhMk7jnAZKHHUfmH3fiO20PS5dhb0/AMhkqdtijbiMffhy+9tm0xiwUv/YW6LoRvmetbaqm1i1cVLetqMzb1PpLbcUKkr86l8Tj/yRz/FEEF/62qOOMu3V21oeZPQnsBWRPzDTA3b1f7frZtw5s1apnfH9qJTQ+0ZLxiZa8kWjBG5Uz+WNmAYcnNii6jjSBdm0BsHnzC98mkyH5699Bn03J3H0TJMK/jjJD9yO1/UCS540m/fKTYaolkyEYvDvByTlmgbSoKKqr3qtH2NfZc+qunDM3fO3Zvbps6TKSR59E4o3xZM4+jeCCs4vaX3OwLqc+DgUmRI+bkRy6eIaXK2fyYqIV56Q6rSr/2ML/8fp5uqA6UkZz55E66CiCgQMILruwujw6weabdC28rVlzsLnzCAbssipIA9CmNd6jG/ZJNPLt2BFPJiGZrDs6nvIFLF5c3DFs2Q/v0B57e0LN8mXLsQ8+wvv1rT55GAQkR5yKvfkfMn+5hGDEMcXtq5kIPL5jw5ImN929Eti5lPto7uaSoIsHHJhZRousX5SdfCUAUy1VUB0po07rwew54Qm65StWFSceexoA32tQ4W2t3xlv1w777/uwdFl1+Xczsc+mQM9w5Eub1vguO2JvvA3Tv62ut3gJqaE/J/Xr3+dsPvPEfbkvdkmlCIYdgH33PfbqG6uK7ZnnsRUrCYYdUH1cY+4m8fJrBOedudYGaYj39DzzmH6LrEupjzPTC7kys4C3rAUPJdrQHmdUZhGdCdi3YkPeTrQsqM66YNH0V5q6CwAkbrmT5B/+RLDDtviwA+Cr6SRuHwt9e5P+12PQpjVMnYaNn4DvvCPUvnoxu60r/07y/67Df/RDgp8fDJWVJO55AJv2Felrr8SPOiysWDXro00rghHDodN62EOPYxM/JDP2FnyfIcUdxHffk9pjf3AnOPUX0RWHt0LH9qRfeza8InLZclLb7Q7pNJnRF0Cy1tiubVv8wJ8Wt98SqFi/TxEP0srt6F6HFBxz7vvysTXeXzEUqGPi4MxSzsosYkuvZBnGO4kWXJLsWOMkYSF11nZxCdQA9v8eJHnzHTB1GqzXAd9vLzJ/OBc6h+kpu/9hUmecVzPY5uKOPfR4eIXilC/CucxbbE7wq5H4PrWeefrJpySv+Bv2+tsQOL71lgTnnl59IrNYk6eQ/OPlYQrEwHfbhcyfLqzOT381PffJy6qu9+hG+r+vNWzfjagxAvVRvQ4uOObc/+XjCtSw7gVqKUycArXER2ME6sN7HVRwzHnoyyfKGqiV3BQRQfOoRURib12enici0izENQ0MCtQiIkC8b3OqQC0iwjp8CbmISHOhEbWISMwpRy0iEnOa9SEiEnOaRy0iEnPKUYuIxFzG45v8UKAWEUGpDxGR2IvzgwMUqEVEaJoHAhRKgVpEhHifTCzpo7hERJqLAC94KYSZVZjZU9H7Vmb2tJlNNLOxFqpTlq8tBWoREcJZH4Uuq2NmrYF3gb2jouHA9OhB352i8lxlOSlQi4gQzvoo9D8zG2lmE7KWkTXacl/m7tsA06OiIcAL0fuXgcF5ynJSjlpEhOLu9eHuY4AxRTTfBVgQvV8IbJGnLCcFahERSn4ycTbQMXrfMfrcLkdZTkp9iIgQjqgLXRrgJWCf6P0QYFyespwUqEVEgAxBwUsD3At0M7NJwFzCIJ2rLCelPkREKM2Vie7eN3pdAQyttTpXWU4K1CIi6F4fIiKxp3t9iIjEnEbUIiIxpxG1iEjM6cEBIiIxp9SHiEjMuUbUIiLxFuf7UStQi4hQ3E2Zyk2BWkQEjahFRGIvEyhHLSISa5r1ISISc8pRi4jEnHLUIiIxpxG1iEjM6WSiiEjMKfUhIhJzSn2IiMScbnMqIhJzmkctIhJzGlGLiMRcoNuciojEm04miojEnAK1iEjMxTdMg8X5W0RCZjbS3cc0dT8kXvR7se5INHUHpCAjm7oDEkv6vVhHKFCLiMScArWISMwpUDcPykNKLvq9WEfoZKKISMxpRC0iEnMK1CIiMadAHWNm1srMnjaziWY21sysqfsk8WFmFWb2VFP3Q0pPgTrehgPT3b0/0AnYu4n7IzFhZq2Bd9HvxDpBgTrehgAvRO9fBgY3YV8kRtx9mbtvA0xv6r5I6SlQx1sXYEH0fiHQuQn7IiJNRIE63mYDHaP3HaPPIrKOUaCOt5eAfaL3Q4BxTdgXEWkiCtTxdi/QzcwmAXMJA7eIrGN0ZaKISMxpRC0iEnMK1CIiMadALSIScwrUIiIxp0AtjcrMBpmZR0ulmX1oZj9rxPY3NTOvVTbIzKY11j5E4kaBWkphCeG9SXoC1wAPmVmPEu7vdWCbYjcys2lmNqjReyPSyBSopSTcfb67z3D3W4GpwKAS7ivt7gtL1b5IU1OglnKoBCrMbLSZ3WVme5vZf83s6qoKZraZmT1vZgvNbJKZDcxaN9TMPjezOcAJtRvPl/ows8Fm9r6ZLTKzF8ysd1T+YpQ+6QWMi9I0oxv9qEUaiQK1lJSZ7Q1sCbwRFW0NXA1cDtwY1UkBTwAPROuvBx4ws5ZmthHwD+Aq4MdUX1K/uv32BJ4Crov2PwO4I1p9EGFq5mvggOj9FWtynCKllGrqDshaqa2ZzQdaASuBM9390+i5Bz8CtnT3qVn1dwa2IgzgVToCmwE7AV+5+y0AZnYx8FwBfTgGeMvdb4+2+y2wK4C7L4nKAmCxu89v2GGKlIcCtZTCUmBbwpTHt17zPgVP1QrSAN0J76s8sFb5DOBAwpFvlWkF9qFHdl13/w54tMBtRWJFqQ8pBXf3ae7+jde9mcziHPWnAxsAs9x9GvAlcDZhAJ8JbJJVt9DZI18Dm1Z9MLPuZvaBmbXNqhMAeryZxJ4CtcTBeMLR79VRbvls4EjgO+B5oK+ZnWhmfYCLCmzzfmBXMzvJzLoDfyBMcyzJqvMZsI+ZdTWzPRvpWEQanQK1NDl3TxOmODYDPiLMLx/o7kvcfXr0+Q+EJyTfKrDNaVGbZwCfEM7wOLJWtd8APyUcwV+5xgciUiK6zamISMxpRC0iEnMK1CIiMadALSIScwrUIiIxp0AtIhJzCtQiIjGnQC0iEnP/H+iaBl3UyOvUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix,annot=True,annot_kws={'size':20,'weight':'bold','color':'red'})\n",
    "plt.title('confusion matrix',fontsize=20)\n",
    "plt.xlabel('Predict',fontsize=14)\n",
    "plt.ylabel('Actual',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ee00d8",
   "metadata": {},
   "source": [
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59c6587e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.0%\n",
      "\n",
      "valid_acc:0.96\n",
      "confusion_matrix:[[578  14]\n",
      " [ 34 574]]\n",
      "general_index:{'accuracy_score': 0.96, 'precision_score': {'precision_score_micro': 0.96, 'precision_score_macro': 0.9603174603174602, 'precision_score_weighted': 0.9605291005291005, 'precision_score_None': array([0.94444444, 0.97619048])}, 'recall_score': {'recall_score_micro': 0.96, 'recall_score_macro': 0.9602151493598862, 'recall_score_weighted': 0.96, 'recall_score_None': array([0.97635135, 0.94407895])}, 'f1_score': {'f1_score_micro': 0.96, 'f1_score_macro': 0.9599995555506172, 'f1_score_weighted': 0.959997777753086, 'f1_score_None': array([0.96013289, 0.95986622])}}\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "valid_acc,confusion_matrix,general_index = test_loop(test_dataloader, model, mode='Test')\n",
    "print(f'valid_acc:{valid_acc}')\n",
    "print(f'confusion_matrix:{confusion_matrix}')\n",
    "print(f'general_index:{general_index}')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebeccd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix,annot=True,annot_kws={'size':20,'weight':'bold','color':'red'})\n",
    "plt.title('confusion matrix',fontsize=20)\n",
    "plt.xlabel('Predict',fontsize=14)\n",
    "plt.ylabel('Actual',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f20e40",
   "metadata": {},
   "source": [
    "# Longformer模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94870479",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device} device')\n",
    "checkpoint = \"bert-base-chinese\"\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.bert_encoder = AutoModel.from_pretrained(checkpoint)\n",
    "        self.classifier = nn.Linear(768, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        bert_output = self.bert_encoder(**x)\n",
    "        cls_vectors = bert_output.last_hidden_state[:, 0]\n",
    "        logits = self.classifier(cls_vectors)\n",
    "        return logits\n",
    "\n",
    "# 先把模型的类加载一下\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46037b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce8a82c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
