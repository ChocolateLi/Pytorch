{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e619aea5",
   "metadata": {},
   "source": [
    "# 背景\n",
    "时间：2023.1.30 <br/>\n",
    "对通用数据集，做BERT模型和Longformer模型的训练，探索BERT模型和Longformer模型在短文本领域的效果，是否符合BERT模型在短文本领域效果较好，Longformer模型在长文本领域效果较好"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010f0c8",
   "metadata": {},
   "source": [
    "# 通用模块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c8d55c",
   "metadata": {},
   "source": [
    "## 参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f87147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"bert-base-chinese\"\n",
    "# model_checkpoint = \"schen/longformer-chinese-base-4096\"\n",
    "batch_size = 2 # 每一批次的数量\n",
    "num_labels = 2 # 多少分类，这里是二分类问题，积极和消极\n",
    "output_dir = \"/home/chenli/pre_model/BERT_and_Longformer/BERT\" # 模型保存路径\n",
    "learning_rate = 1e-5 # 学习率\n",
    "# weight_decay=0.01 # 学习率衰减，设置0.01即可。如果weight_decay设置太小，几乎就不起作用了。\n",
    "num_train_epochs = 10 # 训练轮次，差不多设置为5左右。轮数不要设置太大。轮数设置的太大，Loss是下降了，但是微调的时候效果不是很好，有可能训练过头了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1556ee6",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a80e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import load_from_disk\n",
    "# 加载一个评估标准，默认的评估标准\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c886ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "dataset = load_from_disk('./data/ChnSentiCorp')\n",
    "metric = load_metric(\"glue\",\"mrpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b172392",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5be5fe9",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800fffa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900908ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分词\n",
    "def preprocess_function(data):\n",
    "    return tokenizer(data['text'],truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3c21d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset = dataset.map(function=preprocess_function,\n",
    "                     batched=True,\n",
    "                     remove_columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d528e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3977ea2c",
   "metadata": {},
   "source": [
    "## 微调预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a6835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3594d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_name = \"accuracy\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate = learning_rate,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = 1,\n",
    "    num_train_epochs = num_train_epochs,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=metric_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_metrics(eval_preds):\n",
    "    metric = load_metric('glue','mrpc')\n",
    "    logits,labels = eval_preds # 预测值和真实值\n",
    "    predictions = np.argmax(logits,axis=-1)\n",
    "    return metric.compute(predictions=predictions,references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de699b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5471da79",
   "metadata": {},
   "source": [
    "# BERT模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e29e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca3a6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
