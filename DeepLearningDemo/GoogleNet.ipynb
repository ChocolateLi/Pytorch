{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e342061f",
   "metadata": {},
   "source": [
    "# GoogleNet简单实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a6fc4f",
   "metadata": {},
   "source": [
    "## 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11c25f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "batch_size = 64\n",
    "# 使用torch把图像转化为tensor,图像 c * w * h\n",
    "# 把单通道转换成多通道，把一系列的图像进行转换，变成 [0,1]之间。0.1307是均值，0.3081是标准差\n",
    "# 使用Normalize也是希望像素值满足 0 1 分布\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,),(0.3081,))])\n",
    "# 变换好之后直接放进数据集里\n",
    "train_dataset = datasets.MNIST(root='./dataset/mnist',train=True,download=True,transform=transform)\n",
    "train_loader = DataLoader(train_dataset,shuffle=True,batch_size=batch_size)\n",
    "test_dataset = datasets.MNIST(root='./dataset/mnist',train=False,download=True,transform=transform)\n",
    "test_loader = DataLoader(test_dataset,shuffle=False,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5559d881",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3e061",
   "metadata": {},
   "source": [
    "### Inception模块的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f75395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改变的是channel大小\n",
    "class InceptionA(torch.nn.Module):\n",
    "    def __init__(self,in_channels):\n",
    "        super(InceptionA,self).__init__()\n",
    "        self.branch1x1 = torch.nn.Conv2d(in_channels,16,kernel_size=1)\n",
    "        \n",
    "        self.branch5x5_1 = torch.nn.Conv2d(in_channels,16,kernel_size=1)\n",
    "        self.branch5x5_2 = torch.nn.Conv2d(16,24,kernel_size=5,padding=2)# padding=2才能保持原有图像大小不变\n",
    "        \n",
    "        self.branch3x3_1 = torch.nn.Conv2d(in_channels,16,kernel_size=1)\n",
    "        self.branch3x3_2 = torch.nn.Conv2d(16,24,kernel_size=3,padding=1)\n",
    "        self.branch3x3_3 = torch.nn.Conv2d(24,24,kernel_size=3,padding=1)\n",
    "        \n",
    "        self.branch_pool = torch.nn.Conv2d(in_channels,24,kernel_size=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "        \n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "        \n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "        branch3x3 = self.branch3x3_3(branch3x3)\n",
    "        \n",
    "        branch_pool = F.avg_pool2d(x,kernel_size=3,stride=1,padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "        \n",
    "        # 将输出结果进行拼接\n",
    "        outputs = [branch1x1,branch5x5,branch3x3,branch_pool]\n",
    "        # dim(batch,channel,width,height)，我们要将channel拼接在一起\n",
    "        return torch.cat(outputs,dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04827e91",
   "metadata": {},
   "source": [
    "### 定义网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdd60afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        # 先定义两个卷积层\n",
    "        self.conv1 = torch.nn.Conv2d(1,10,kernel_size=5)\n",
    "        self.conv2 = torch.nn.Conv2d(88,20,kernel_size=5)\n",
    "        \n",
    "        self.incep1 = InceptionA(in_channels=10)\n",
    "        self.incep2 = InceptionA(in_channels=20)\n",
    "        \n",
    "        # 经过Maxpooling之后，图像的高度和宽度是一直在减小的\n",
    "        self.mp = torch.nn.MaxPool2d(2)\n",
    "        # 1408是算出来的\n",
    "        self.fc = torch.nn.Linear(1408,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        in_size = x.size(0)\n",
    "        # 先做一次卷积，然后做一次池化，最后做激活\n",
    "        x = F.relu(self.mp(self.conv1(x))) # 做完这个，输入通道变成10个\n",
    "        x = self.incep1(x) # 经过计算，最后输出通道是88个\n",
    "        x = F.relu(self.mp(self.conv2(x))) # 把输入88个通道降成20个通道\n",
    "        x = self.incep2(x) # 最后又输出88个通道\n",
    "        x = x.view(in_size,-1) \n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "        \n",
    "    \n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bad68ab",
   "metadata": {},
   "source": [
    "## 构造损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "491cd86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f58b1b",
   "metadata": {},
   "source": [
    "## 构造训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aab4540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx,data in enumerate(train_loader,0):\n",
    "        inputs,target = data\n",
    "        # 把inputs,target都迁移到GPU中\n",
    "        # inputs,target = inputs.to(device),target.to(device)\n",
    "        # 优化器在优化之前先清零\n",
    "        optimizer.zero_grad()\n",
    "        # forward backward update\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        # 每300输出一次\n",
    "        if batch_idx % 300 == 299:\n",
    "            print('[%d,%5d] loss:%.3f' % (epoch+1,batch_idx+1,running_loss/300))\n",
    "            # 每300一组数据跑完，清零\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce2409d",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db1f1a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test里面不需要计算反向传播，只需要计算正向的就行了\n",
    "def test():\n",
    "    # 表示正确了多少\n",
    "    correct = 0\n",
    "    # 表示总数有多少\n",
    "    total = 0\n",
    "    # 在test过程中是不需要计算梯度的\n",
    "    # 这部分的代码不会求导\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images,labels = data\n",
    "            # 把数据迁移到GPU上\n",
    "            # images,labels = images.to(device),labels.to(device)\n",
    "            outputs = model(images)\n",
    "            # dim=1 返回每一个行的最大值和索引\n",
    "            # dim=0 返回每一列的最大值和索引\n",
    "            # 这里的索引或者下标对应的是它的分类\n",
    "            _,predicted = torch.max(outputs.data,dim=1)\n",
    "            # label是一个元组，(N,1)\n",
    "            # size是计算元素的个数，0表示计算行数，1表示计算列数\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted==labels).sum().item()\n",
    "            \n",
    "    # 使用正确的数除以总数\n",
    "    print('Accuracy on test set: %d %%' % (100 * correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5477a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  300] loss:0.992\n",
      "[1,  600] loss:0.213\n",
      "[1,  900] loss:0.131\n",
      "Accuracy on test set: 96 %\n",
      "[2,  300] loss:0.108\n",
      "[2,  600] loss:0.092\n",
      "[2,  900] loss:0.088\n",
      "Accuracy on test set: 98 %\n",
      "[3,  300] loss:0.072\n",
      "[3,  600] loss:0.073\n",
      "[3,  900] loss:0.064\n",
      "Accuracy on test set: 98 %\n",
      "[4,  300] loss:0.058\n",
      "[4,  600] loss:0.057\n",
      "[4,  900] loss:0.058\n",
      "Accuracy on test set: 98 %\n",
      "[5,  300] loss:0.051\n",
      "[5,  600] loss:0.050\n",
      "[5,  900] loss:0.048\n",
      "Accuracy on test set: 98 %\n",
      "[6,  300] loss:0.046\n",
      "[6,  600] loss:0.042\n",
      "[6,  900] loss:0.045\n",
      "Accuracy on test set: 98 %\n",
      "[7,  300] loss:0.038\n",
      "[7,  600] loss:0.039\n",
      "[7,  900] loss:0.041\n",
      "Accuracy on test set: 98 %\n",
      "[8,  300] loss:0.033\n",
      "[8,  600] loss:0.040\n",
      "[8,  900] loss:0.036\n",
      "Accuracy on test set: 98 %\n",
      "[9,  300] loss:0.034\n",
      "[9,  600] loss:0.033\n",
      "[9,  900] loss:0.031\n",
      "Accuracy on test set: 98 %\n",
      "[10,  300] loss:0.029\n",
      "[10,  600] loss:0.033\n",
      "[10,  900] loss:0.028\n",
      "Accuracy on test set: 98 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    # 一轮训练\n",
    "    train(epoch)\n",
    "    # 一轮测试\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3d9b9e",
   "metadata": {},
   "source": [
    "## 总结\n",
    "第二轮就达到98%,效果还是杠杠的"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
