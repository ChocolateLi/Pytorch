{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8ae886e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddb7268b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b626ed6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "700b63c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AVG',\n",
       " 'AggregationType',\n",
       " 'AliasDb',\n",
       " 'AnyType',\n",
       " 'Argument',\n",
       " 'ArgumentSpec',\n",
       " 'BFloat16Storage',\n",
       " 'BFloat16Tensor',\n",
       " 'BenchmarkConfig',\n",
       " 'BenchmarkExecutionStats',\n",
       " 'Block',\n",
       " 'BoolStorage',\n",
       " 'BoolTensor',\n",
       " 'BoolType',\n",
       " 'BufferDict',\n",
       " 'ByteStorage',\n",
       " 'ByteTensor',\n",
       " 'CONV_BN_FUSION',\n",
       " 'CallStack',\n",
       " 'Capsule',\n",
       " 'CharStorage',\n",
       " 'CharTensor',\n",
       " 'ClassType',\n",
       " 'Code',\n",
       " 'CompilationUnit',\n",
       " 'CompleteArgumentSpec',\n",
       " 'ComplexDoubleStorage',\n",
       " 'ComplexFloatStorage',\n",
       " 'ComplexType',\n",
       " 'ConcreteModuleType',\n",
       " 'ConcreteModuleTypeBuilder',\n",
       " 'CudaByteStorageBase',\n",
       " 'DeepCopyMemoTable',\n",
       " 'DeserializationStorageContext',\n",
       " 'DeviceObjType',\n",
       " 'DictType',\n",
       " 'DisableTorchFunction',\n",
       " 'DoubleStorage',\n",
       " 'DoubleTensor',\n",
       " 'EnumType',\n",
       " 'ErrorReport',\n",
       " 'ExecutionPlan',\n",
       " 'FUSE_ADD_RELU',\n",
       " 'FatalError',\n",
       " 'FileCheck',\n",
       " 'FloatStorage',\n",
       " 'FloatTensor',\n",
       " 'FloatType',\n",
       " 'FunctionSchema',\n",
       " 'Future',\n",
       " 'FutureType',\n",
       " 'Generator',\n",
       " 'Gradient',\n",
       " 'Graph',\n",
       " 'GraphExecutorState',\n",
       " 'HOIST_CONV_PACKED_PARAMS',\n",
       " 'HalfStorage',\n",
       " 'HalfTensor',\n",
       " 'INSERT_FOLD_PREPACK_OPS',\n",
       " 'IODescriptor',\n",
       " 'InferredType',\n",
       " 'IntStorage',\n",
       " 'IntTensor',\n",
       " 'IntType',\n",
       " 'InterfaceType',\n",
       " 'JITException',\n",
       " 'ListType',\n",
       " 'LiteScriptModule',\n",
       " 'LockingLogger',\n",
       " 'LoggerBase',\n",
       " 'LongStorage',\n",
       " 'LongTensor',\n",
       " 'MobileOptimizerType',\n",
       " 'ModuleDict',\n",
       " 'Node',\n",
       " 'NoneType',\n",
       " 'NoopLogger',\n",
       " 'NumberType',\n",
       " 'OperatorInfo',\n",
       " 'OptionalType',\n",
       " 'PRIVATE_OPS',\n",
       " 'ParameterDict',\n",
       " 'PyObjectType',\n",
       " 'PyTorchFileReader',\n",
       " 'PyTorchFileWriter',\n",
       " 'QInt32Storage',\n",
       " 'QInt8Storage',\n",
       " 'QUInt2x4Storage',\n",
       " 'QUInt4x2Storage',\n",
       " 'QUInt8Storage',\n",
       " 'REMOVE_DROPOUT',\n",
       " 'RRefType',\n",
       " 'SUM',\n",
       " 'ScriptClass',\n",
       " 'ScriptClassFunction',\n",
       " 'ScriptDict',\n",
       " 'ScriptDictIterator',\n",
       " 'ScriptDictKeyIterator',\n",
       " 'ScriptFunction',\n",
       " 'ScriptList',\n",
       " 'ScriptListIterator',\n",
       " 'ScriptMethod',\n",
       " 'ScriptModule',\n",
       " 'ScriptModuleSerializer',\n",
       " 'ScriptObject',\n",
       " 'ScriptObjectProperty',\n",
       " 'SerializationStorageContext',\n",
       " 'Set',\n",
       " 'ShortStorage',\n",
       " 'ShortTensor',\n",
       " 'Size',\n",
       " 'StaticModule',\n",
       " 'Storage',\n",
       " 'Stream',\n",
       " 'StreamObjType',\n",
       " 'StringType',\n",
       " 'TYPE_CHECKING',\n",
       " 'Tensor',\n",
       " 'TensorType',\n",
       " 'ThroughputBenchmark',\n",
       " 'TracingState',\n",
       " 'TupleType',\n",
       " 'Type',\n",
       " 'USE_GLOBAL_DEPS',\n",
       " 'USE_RTLD_GLOBAL_WITH_LIBTORCH',\n",
       " 'Union',\n",
       " 'UnionType',\n",
       " 'Use',\n",
       " 'Value',\n",
       " '_C',\n",
       " '_StorageBase',\n",
       " '_TypedStorage',\n",
       " '_UntypedStorage',\n",
       " '_VF',\n",
       " '__all__',\n",
       " '__annotations__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__config__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__future__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_adaptive_avg_pool2d',\n",
       " '_adaptive_avg_pool3d',\n",
       " '_add_batch_dim',\n",
       " '_add_relu',\n",
       " '_add_relu_',\n",
       " '_aminmax',\n",
       " '_amp_foreach_non_finite_check_and_unscale_',\n",
       " '_amp_update_scale_',\n",
       " '_assert',\n",
       " '_assert_async',\n",
       " '_batch_norm_impl_index',\n",
       " '_cast_Byte',\n",
       " '_cast_Char',\n",
       " '_cast_Double',\n",
       " '_cast_Float',\n",
       " '_cast_Half',\n",
       " '_cast_Int',\n",
       " '_cast_Long',\n",
       " '_cast_Short',\n",
       " '_cat',\n",
       " '_choose_qparams_per_tensor',\n",
       " '_classes',\n",
       " '_coalesce',\n",
       " '_compute_linear_combination',\n",
       " '_conj',\n",
       " '_conj_physical',\n",
       " '_convert_indices_from_coo_to_csr',\n",
       " '_convert_indices_from_csr_to_coo',\n",
       " '_convolution',\n",
       " '_convolution_mode',\n",
       " '_copy_from',\n",
       " '_copy_from_and_resize',\n",
       " '_ctc_loss',\n",
       " '_cudnn_ctc_loss',\n",
       " '_cudnn_init_dropout_state',\n",
       " '_cudnn_rnn',\n",
       " '_cudnn_rnn_flatten_weight',\n",
       " '_cufft_clear_plan_cache',\n",
       " '_cufft_get_plan_cache_max_size',\n",
       " '_cufft_get_plan_cache_size',\n",
       " '_cufft_set_plan_cache_max_size',\n",
       " '_cummax_helper',\n",
       " '_cummin_helper',\n",
       " '_debug_has_internal_overlap',\n",
       " '_det_lu_based_helper',\n",
       " '_det_lu_based_helper_backward_helper',\n",
       " '_dim_arange',\n",
       " '_dirichlet_grad',\n",
       " '_disable_functionalization',\n",
       " '_efficientzerotensor',\n",
       " '_embedding_bag',\n",
       " '_embedding_bag_forward_only',\n",
       " '_empty_affine_quantized',\n",
       " '_empty_per_channel_affine_quantized',\n",
       " '_enable_functionalization',\n",
       " '_euclidean_dist',\n",
       " '_fake_quantize_learnable_per_channel_affine',\n",
       " '_fake_quantize_learnable_per_tensor_affine',\n",
       " '_fake_quantize_per_tensor_affine_cachemask_tensor_qparams',\n",
       " '_fft_c2c',\n",
       " '_fft_c2r',\n",
       " '_fft_r2c',\n",
       " '_foreach_abs',\n",
       " '_foreach_abs_',\n",
       " '_foreach_acos',\n",
       " '_foreach_acos_',\n",
       " '_foreach_add',\n",
       " '_foreach_add_',\n",
       " '_foreach_addcdiv',\n",
       " '_foreach_addcdiv_',\n",
       " '_foreach_addcmul',\n",
       " '_foreach_addcmul_',\n",
       " '_foreach_asin',\n",
       " '_foreach_asin_',\n",
       " '_foreach_atan',\n",
       " '_foreach_atan_',\n",
       " '_foreach_ceil',\n",
       " '_foreach_ceil_',\n",
       " '_foreach_cos',\n",
       " '_foreach_cos_',\n",
       " '_foreach_cosh',\n",
       " '_foreach_cosh_',\n",
       " '_foreach_div',\n",
       " '_foreach_div_',\n",
       " '_foreach_erf',\n",
       " '_foreach_erf_',\n",
       " '_foreach_erfc',\n",
       " '_foreach_erfc_',\n",
       " '_foreach_exp',\n",
       " '_foreach_exp_',\n",
       " '_foreach_expm1',\n",
       " '_foreach_expm1_',\n",
       " '_foreach_floor',\n",
       " '_foreach_floor_',\n",
       " '_foreach_frac',\n",
       " '_foreach_frac_',\n",
       " '_foreach_lgamma',\n",
       " '_foreach_lgamma_',\n",
       " '_foreach_log',\n",
       " '_foreach_log10',\n",
       " '_foreach_log10_',\n",
       " '_foreach_log1p',\n",
       " '_foreach_log1p_',\n",
       " '_foreach_log2',\n",
       " '_foreach_log2_',\n",
       " '_foreach_log_',\n",
       " '_foreach_maximum',\n",
       " '_foreach_minimum',\n",
       " '_foreach_mul',\n",
       " '_foreach_mul_',\n",
       " '_foreach_neg',\n",
       " '_foreach_neg_',\n",
       " '_foreach_norm',\n",
       " '_foreach_reciprocal',\n",
       " '_foreach_reciprocal_',\n",
       " '_foreach_round',\n",
       " '_foreach_round_',\n",
       " '_foreach_sigmoid',\n",
       " '_foreach_sigmoid_',\n",
       " '_foreach_sin',\n",
       " '_foreach_sin_',\n",
       " '_foreach_sinh',\n",
       " '_foreach_sinh_',\n",
       " '_foreach_sqrt',\n",
       " '_foreach_sqrt_',\n",
       " '_foreach_sub',\n",
       " '_foreach_sub_',\n",
       " '_foreach_tan',\n",
       " '_foreach_tan_',\n",
       " '_foreach_tanh',\n",
       " '_foreach_tanh_',\n",
       " '_foreach_trunc',\n",
       " '_foreach_trunc_',\n",
       " '_foreach_zero_',\n",
       " '_from_functional_tensor',\n",
       " '_fused_dropout',\n",
       " '_fused_moving_avg_obs_fq_helper',\n",
       " '_grid_sampler_2d_cpu_fallback',\n",
       " '_has_compatible_shallow_copy_type',\n",
       " '_histogramdd_bin_edges',\n",
       " '_histogramdd_from_bin_cts',\n",
       " '_histogramdd_from_bin_tensors',\n",
       " '_import_dotted_name',\n",
       " '_index_copy_',\n",
       " '_index_put_impl_',\n",
       " '_initExtension',\n",
       " '_is_functional_tensor',\n",
       " '_is_zerotensor',\n",
       " '_jit_internal',\n",
       " '_linalg_check_errors',\n",
       " '_linalg_inv_out_helper_',\n",
       " '_linalg_qr_helper',\n",
       " '_linalg_svd',\n",
       " '_linalg_utils',\n",
       " '_load_global_deps',\n",
       " '_lobpcg',\n",
       " '_log_softmax',\n",
       " '_log_softmax_backward_data',\n",
       " '_logcumsumexp',\n",
       " '_lowrank',\n",
       " '_lu_with_info',\n",
       " '_make_dual',\n",
       " '_make_per_channel_quantized_tensor',\n",
       " '_make_per_tensor_quantized_tensor',\n",
       " '_masked',\n",
       " '_masked_scale',\n",
       " '_masked_softmax',\n",
       " '_mkldnn',\n",
       " '_mkldnn_reshape',\n",
       " '_mkldnn_transpose',\n",
       " '_mkldnn_transpose_',\n",
       " '_namedtensor_internals',\n",
       " '_native_multi_head_self_attention',\n",
       " '_neg_view',\n",
       " '_nnpack_available',\n",
       " '_nnpack_spatial_convolution',\n",
       " '_ops',\n",
       " '_pack_padded_sequence',\n",
       " '_pad_packed_sequence',\n",
       " '_pin_memory',\n",
       " '_register_device_module',\n",
       " '_remove_batch_dim',\n",
       " '_reshape_from_tensor',\n",
       " '_rowwise_prune',\n",
       " '_s_where',\n",
       " '_sample_dirichlet',\n",
       " '_saturate_weight_to_fp16',\n",
       " '_shape_as_tensor',\n",
       " '_six',\n",
       " '_sobol_engine_draw',\n",
       " '_sobol_engine_ff_',\n",
       " '_sobol_engine_initialize_state_',\n",
       " '_sobol_engine_scramble_',\n",
       " '_softmax',\n",
       " '_softmax_backward_data',\n",
       " '_sources',\n",
       " '_sparse_broadcast_to',\n",
       " '_sparse_coo_tensor_unsafe',\n",
       " '_sparse_csr_tensor_unsafe',\n",
       " '_sparse_log_softmax_backward_data',\n",
       " '_sparse_mask_helper',\n",
       " '_sparse_mm',\n",
       " '_sparse_softmax_backward_data',\n",
       " '_sparse_sparse_matmul',\n",
       " '_sparse_sum',\n",
       " '_stack',\n",
       " '_standard_gamma',\n",
       " '_standard_gamma_grad',\n",
       " '_storage_classes',\n",
       " '_string_classes',\n",
       " '_sync',\n",
       " '_tensor',\n",
       " '_tensor_classes',\n",
       " '_tensor_str',\n",
       " '_test_serialization_subcmul',\n",
       " '_to_cpu',\n",
       " '_to_functional_tensor',\n",
       " '_torch_cuda_cu_linker_symbol_op',\n",
       " '_trilinear',\n",
       " '_unique',\n",
       " '_unique2',\n",
       " '_unpack_dual',\n",
       " '_use_cudnn_ctc_loss',\n",
       " '_use_cudnn_rnn_flatten_weight',\n",
       " '_utils',\n",
       " '_utils_internal',\n",
       " '_validate_sparse_coo_tensor_args',\n",
       " '_validate_sparse_csr_tensor_args',\n",
       " '_vmap_internals',\n",
       " '_weight_norm',\n",
       " '_weight_norm_cuda_interface',\n",
       " 'abs',\n",
       " 'abs_',\n",
       " 'absolute',\n",
       " 'acos',\n",
       " 'acos_',\n",
       " 'acosh',\n",
       " 'acosh_',\n",
       " 'adaptive_avg_pool1d',\n",
       " 'adaptive_max_pool1d',\n",
       " 'add',\n",
       " 'addbmm',\n",
       " 'addcdiv',\n",
       " 'addcmul',\n",
       " 'addmm',\n",
       " 'addmv',\n",
       " 'addmv_',\n",
       " 'addr',\n",
       " 'adjoint',\n",
       " 'affine_grid_generator',\n",
       " 'align_tensors',\n",
       " 'all',\n",
       " 'allclose',\n",
       " 'alpha_dropout',\n",
       " 'alpha_dropout_',\n",
       " 'amax',\n",
       " 'amin',\n",
       " 'aminmax',\n",
       " 'angle',\n",
       " 'any',\n",
       " 'ao',\n",
       " 'arange',\n",
       " 'arccos',\n",
       " 'arccos_',\n",
       " 'arccosh',\n",
       " 'arccosh_',\n",
       " 'arcsin',\n",
       " 'arcsin_',\n",
       " 'arcsinh',\n",
       " 'arcsinh_',\n",
       " 'arctan',\n",
       " 'arctan2',\n",
       " 'arctan_',\n",
       " 'arctanh',\n",
       " 'arctanh_',\n",
       " 'are_deterministic_algorithms_enabled',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'argwhere',\n",
       " 'as_strided',\n",
       " 'as_strided_',\n",
       " 'as_tensor',\n",
       " 'asarray',\n",
       " 'asin',\n",
       " 'asin_',\n",
       " 'asinh',\n",
       " 'asinh_',\n",
       " 'atan',\n",
       " 'atan2',\n",
       " 'atan_',\n",
       " 'atanh',\n",
       " 'atanh_',\n",
       " 'atleast_1d',\n",
       " 'atleast_2d',\n",
       " 'atleast_3d',\n",
       " 'attr',\n",
       " 'autocast',\n",
       " 'autocast_decrement_nesting',\n",
       " 'autocast_increment_nesting',\n",
       " 'autocast_mode',\n",
       " 'autograd',\n",
       " 'avg_pool1d',\n",
       " 'backends',\n",
       " 'baddbmm',\n",
       " 'bartlett_window',\n",
       " 'batch_norm',\n",
       " 'batch_norm_backward_elemt',\n",
       " 'batch_norm_backward_reduce',\n",
       " 'batch_norm_elemt',\n",
       " 'batch_norm_gather_stats',\n",
       " 'batch_norm_gather_stats_with_counts',\n",
       " 'batch_norm_stats',\n",
       " 'batch_norm_update_stats',\n",
       " 'bernoulli',\n",
       " 'bfloat16',\n",
       " 'bilinear',\n",
       " 'binary_cross_entropy_with_logits',\n",
       " 'bincount',\n",
       " 'binomial',\n",
       " 'bitwise_and',\n",
       " 'bitwise_left_shift',\n",
       " 'bitwise_not',\n",
       " 'bitwise_or',\n",
       " 'bitwise_right_shift',\n",
       " 'bitwise_xor',\n",
       " 'blackman_window',\n",
       " 'block_diag',\n",
       " 'bmm',\n",
       " 'bool',\n",
       " 'broadcast_shapes',\n",
       " 'broadcast_tensors',\n",
       " 'broadcast_to',\n",
       " 'bucketize',\n",
       " 'builtins',\n",
       " 'can_cast',\n",
       " 'candidate',\n",
       " 'cartesian_prod',\n",
       " 'cat',\n",
       " 'cdist',\n",
       " 'cdouble',\n",
       " 'ceil',\n",
       " 'ceil_',\n",
       " 'celu',\n",
       " 'celu_',\n",
       " 'cfloat',\n",
       " 'chain_matmul',\n",
       " 'channel_shuffle',\n",
       " 'channels_last',\n",
       " 'channels_last_3d',\n",
       " 'cholesky',\n",
       " 'cholesky_inverse',\n",
       " 'cholesky_solve',\n",
       " 'choose_qparams_optimized',\n",
       " 'chunk',\n",
       " 'clamp',\n",
       " 'clamp_',\n",
       " 'clamp_max',\n",
       " 'clamp_max_',\n",
       " 'clamp_min',\n",
       " 'clamp_min_',\n",
       " 'classes',\n",
       " 'classproperty',\n",
       " 'clear_autocast_cache',\n",
       " 'clip',\n",
       " 'clip_',\n",
       " 'clone',\n",
       " 'column_stack',\n",
       " 'combinations',\n",
       " 'compiled_with_cxx11_abi',\n",
       " 'complex',\n",
       " 'complex128',\n",
       " 'complex64',\n",
       " 'concat',\n",
       " 'conj',\n",
       " 'conj_physical',\n",
       " 'conj_physical_',\n",
       " 'constant_pad_nd',\n",
       " 'contiguous_format',\n",
       " 'conv1d',\n",
       " 'conv2d',\n",
       " 'conv3d',\n",
       " 'conv_tbc',\n",
       " 'conv_transpose1d',\n",
       " 'conv_transpose2d',\n",
       " 'conv_transpose3d',\n",
       " 'convolution',\n",
       " 'copysign',\n",
       " 'corrcoef',\n",
       " 'cos',\n",
       " 'cos_',\n",
       " 'cosh',\n",
       " 'cosh_',\n",
       " 'cosine_embedding_loss',\n",
       " 'cosine_similarity',\n",
       " 'count_nonzero',\n",
       " 'cov',\n",
       " 'cpp',\n",
       " 'cpu',\n",
       " 'cross',\n",
       " 'ctc_loss',\n",
       " 'ctypes',\n",
       " 'cuda',\n",
       " 'cudnn_affine_grid_generator',\n",
       " 'cudnn_batch_norm',\n",
       " 'cudnn_convolution',\n",
       " 'cudnn_convolution_add_relu',\n",
       " 'cudnn_convolution_relu',\n",
       " 'cudnn_convolution_transpose',\n",
       " 'cudnn_grid_sampler',\n",
       " 'cudnn_is_acceptable',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'cumulative_trapezoid',\n",
       " 'default_generator',\n",
       " 'deg2rad',\n",
       " 'deg2rad_',\n",
       " 'dequantize',\n",
       " 'det',\n",
       " 'detach',\n",
       " 'detach_',\n",
       " 'device',\n",
       " 'diag',\n",
       " 'diag_embed',\n",
       " 'diagflat',\n",
       " 'diagonal',\n",
       " 'diagonal_scatter',\n",
       " 'diff',\n",
       " 'digamma',\n",
       " 'dist',\n",
       " 'distributed',\n",
       " 'distributions',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'dot',\n",
       " 'double',\n",
       " 'dropout',\n",
       " 'dropout_',\n",
       " 'dsmm',\n",
       " 'dsplit',\n",
       " 'dstack',\n",
       " 'dtype',\n",
       " 'e',\n",
       " 'eig',\n",
       " 'einsum',\n",
       " 'embedding',\n",
       " 'embedding_bag',\n",
       " 'embedding_renorm_',\n",
       " 'empty',\n",
       " 'empty_like',\n",
       " 'empty_quantized',\n",
       " 'empty_strided',\n",
       " 'enable_grad',\n",
       " 'eq',\n",
       " 'equal',\n",
       " 'erf',\n",
       " 'erf_',\n",
       " 'erfc',\n",
       " 'erfc_',\n",
       " 'erfinv',\n",
       " 'exp',\n",
       " 'exp2',\n",
       " 'exp2_',\n",
       " 'exp_',\n",
       " 'expm1',\n",
       " 'expm1_',\n",
       " 'eye',\n",
       " 'fake_quantize_per_channel_affine',\n",
       " 'fake_quantize_per_tensor_affine',\n",
       " 'fbgemm_linear_fp16_weight',\n",
       " 'fbgemm_linear_fp16_weight_fp32_activation',\n",
       " 'fbgemm_linear_int8_weight',\n",
       " 'fbgemm_linear_int8_weight_fp32_activation',\n",
       " 'fbgemm_linear_quantize_weight',\n",
       " 'fbgemm_pack_gemm_matrix_fp16',\n",
       " 'fbgemm_pack_quantized_matrix',\n",
       " 'feature_alpha_dropout',\n",
       " 'feature_alpha_dropout_',\n",
       " 'feature_dropout',\n",
       " 'feature_dropout_',\n",
       " 'fft',\n",
       " 'fill_',\n",
       " 'finfo',\n",
       " 'fix',\n",
       " 'fix_',\n",
       " 'flatten',\n",
       " 'flip',\n",
       " 'fliplr',\n",
       " 'flipud',\n",
       " 'float',\n",
       " 'float16',\n",
       " 'float32',\n",
       " 'float64',\n",
       " 'float_power',\n",
       " 'floor',\n",
       " 'floor_',\n",
       " 'floor_divide',\n",
       " 'fmax',\n",
       " 'fmin',\n",
       " 'fmod',\n",
       " 'fork',\n",
       " 'frac',\n",
       " 'frac_',\n",
       " 'frexp',\n",
       " 'frobenius_norm',\n",
       " 'from_dlpack',\n",
       " 'from_file',\n",
       " 'from_numpy',\n",
       " 'frombuffer',\n",
       " 'full',\n",
       " 'full_like',\n",
       " 'functional',\n",
       " 'fused_moving_avg_obs_fake_quant',\n",
       " 'futures',\n",
       " 'gather',\n",
       " 'gcd',\n",
       " 'gcd_',\n",
       " 'ge',\n",
       " 'geqrf',\n",
       " 'ger',\n",
       " 'get_autocast_cpu_dtype',\n",
       " 'get_autocast_gpu_dtype',\n",
       " 'get_default_dtype',\n",
       " 'get_deterministic_debug_mode',\n",
       " 'get_device',\n",
       " 'get_file_path',\n",
       " 'get_num_interop_threads',\n",
       " 'get_num_threads',\n",
       " 'get_rng_state',\n",
       " 'gradient',\n",
       " 'greater',\n",
       " 'greater_equal',\n",
       " 'grid_sampler',\n",
       " 'grid_sampler_2d',\n",
       " 'grid_sampler_3d',\n",
       " 'group_norm',\n",
       " 'gru',\n",
       " 'gru_cell',\n",
       " 'gt',\n",
       " 'half',\n",
       " 'hamming_window',\n",
       " 'hann_window',\n",
       " 'hardshrink',\n",
       " 'has_cuda',\n",
       " 'has_cudnn',\n",
       " 'has_lapack',\n",
       " 'has_mkl',\n",
       " 'has_mkldnn',\n",
       " 'has_mlc',\n",
       " 'has_openmp',\n",
       " 'has_spectral',\n",
       " 'heaviside',\n",
       " 'hinge_embedding_loss',\n",
       " 'histc',\n",
       " 'histogram',\n",
       " 'histogramdd',\n",
       " 'hsmm',\n",
       " 'hsplit',\n",
       " 'hspmm',\n",
       " 'hstack',\n",
       " 'hub',\n",
       " 'hypot',\n",
       " 'i0',\n",
       " 'i0_',\n",
       " 'igamma',\n",
       " 'igammac',\n",
       " 'iinfo',\n",
       " 'imag',\n",
       " 'import_ir_module',\n",
       " 'import_ir_module_from_buffer',\n",
       " 'index_add',\n",
       " 'index_copy',\n",
       " 'index_fill',\n",
       " 'index_put',\n",
       " 'index_put_',\n",
       " 'index_select',\n",
       " 'inf',\n",
       " 'inference_mode',\n",
       " 'init_num_threads',\n",
       " 'initial_seed',\n",
       " 'inner',\n",
       " 'instance_norm',\n",
       " 'int',\n",
       " 'int16',\n",
       " 'int32',\n",
       " 'int64',\n",
       " 'int8',\n",
       " 'int_repr',\n",
       " 'inverse',\n",
       " 'is_anomaly_enabled',\n",
       " 'is_autocast_cache_enabled',\n",
       " 'is_autocast_cpu_enabled',\n",
       " 'is_autocast_enabled',\n",
       " 'is_complex',\n",
       " 'is_conj',\n",
       " 'is_deterministic_algorithms_warn_only_enabled',\n",
       " 'is_distributed',\n",
       " 'is_floating_point',\n",
       " 'is_grad_enabled',\n",
       " 'is_inference',\n",
       " 'is_inference_mode_enabled',\n",
       " 'is_neg',\n",
       " 'is_nonzero',\n",
       " 'is_same_size',\n",
       " 'is_signed',\n",
       " 'is_storage',\n",
       " 'is_tensor',\n",
       " 'is_vulkan_available',\n",
       " 'is_warn_always_enabled',\n",
       " 'isclose',\n",
       " 'isfinite',\n",
       " 'isin',\n",
       " 'isinf',\n",
       " 'isnan',\n",
       " 'isneginf',\n",
       " 'isposinf',\n",
       " 'isreal',\n",
       " 'istft',\n",
       " 'jit',\n",
       " 'kaiser_window',\n",
       " 'kl_div',\n",
       " 'kron',\n",
       " 'kthvalue',\n",
       " 'layer_norm',\n",
       " 'layout',\n",
       " 'lcm',\n",
       " 'lcm_',\n",
       " 'ldexp',\n",
       " 'ldexp_',\n",
       " 'le',\n",
       " 'legacy_contiguous_format',\n",
       " 'lerp',\n",
       " 'less',\n",
       " 'less_equal',\n",
       " 'lgamma',\n",
       " 'linalg',\n",
       " 'linspace',\n",
       " 'load',\n",
       " 'lobpcg',\n",
       " 'log',\n",
       " 'log10',\n",
       " 'log10_',\n",
       " 'log1p',\n",
       " 'log1p_',\n",
       " 'log2',\n",
       " 'log2_',\n",
       " 'log_',\n",
       " 'log_softmax',\n",
       " 'logaddexp',\n",
       " 'logaddexp2',\n",
       " 'logcumsumexp',\n",
       " 'logdet',\n",
       " 'logical_and',\n",
       " 'logical_not',\n",
       " 'logical_or',\n",
       " 'logical_xor',\n",
       " 'logit',\n",
       " 'logit_',\n",
       " 'logspace',\n",
       " 'logsumexp',\n",
       " 'long',\n",
       " 'lstm',\n",
       " 'lstm_cell',\n",
       " 'lstsq',\n",
       " 'lt',\n",
       " 'lu',\n",
       " 'lu_solve',\n",
       " 'lu_unpack',\n",
       " 'manual_seed',\n",
       " 'margin_ranking_loss',\n",
       " 'masked_fill',\n",
       " 'masked_scatter',\n",
       " 'masked_select',\n",
       " 'matmul',\n",
       " 'matrix_exp',\n",
       " 'matrix_power',\n",
       " 'matrix_rank',\n",
       " 'max',\n",
       " 'max_pool1d',\n",
       " 'max_pool1d_with_indices',\n",
       " 'max_pool2d',\n",
       " 'max_pool3d',\n",
       " 'maximum',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'memory_format',\n",
       " 'merge_type_from_type_comment',\n",
       " 'meshgrid',\n",
       " 'min',\n",
       " 'minimum',\n",
       " 'miopen_batch_norm',\n",
       " 'miopen_convolution',\n",
       " 'miopen_convolution_transpose',\n",
       " 'miopen_depthwise_convolution',\n",
       " 'miopen_rnn',\n",
       " 'mkldnn_adaptive_avg_pool2d',\n",
       " 'mkldnn_convolution',\n",
       " 'mkldnn_linear_backward_weights',\n",
       " 'mkldnn_max_pool2d',\n",
       " 'mkldnn_max_pool3d',\n",
       " 'mm',\n",
       " 'mode',\n",
       " 'moveaxis',\n",
       " 'movedim',\n",
       " 'msort',\n",
       " 'mul',\n",
       " 'multinomial',\n",
       " 'multiply',\n",
       " 'multiprocessing',\n",
       " 'mv',\n",
       " 'mvlgamma',\n",
       " 'name',\n",
       " 'nan',\n",
       " 'nan_to_num',\n",
       " 'nan_to_num_',\n",
       " 'nanmean',\n",
       " 'nanmedian',\n",
       " 'nanquantile',\n",
       " 'nansum',\n",
       " 'narrow',\n",
       " 'narrow_copy',\n",
       " 'native_batch_norm',\n",
       " 'native_channel_shuffle',\n",
       " 'native_dropout',\n",
       " 'native_group_norm',\n",
       " 'native_layer_norm',\n",
       " 'native_norm',\n",
       " 'ne',\n",
       " 'neg',\n",
       " 'neg_',\n",
       " 'negative',\n",
       " 'negative_',\n",
       " 'nextafter',\n",
       " 'nn',\n",
       " 'no_grad',\n",
       " 'nonzero',\n",
       " 'norm',\n",
       " 'norm_except_dim',\n",
       " 'normal',\n",
       " 'not_equal',\n",
       " 'nuclear_norm',\n",
       " 'numel',\n",
       " 'ones',\n",
       " 'ones_like',\n",
       " 'onnx',\n",
       " 'ops',\n",
       " 'optim',\n",
       " 'orgqr',\n",
       " 'ormqr',\n",
       " 'os',\n",
       " 'outer',\n",
       " 'overrides',\n",
       " 'package',\n",
       " 'pairwise_distance',\n",
       " 'parse_ir',\n",
       " 'parse_schema',\n",
       " 'parse_type_comment',\n",
       " 'pca_lowrank',\n",
       " 'pdist',\n",
       " 'per_channel_affine',\n",
       " 'per_channel_affine_float_qparams',\n",
       " 'per_channel_symmetric',\n",
       " 'per_tensor_affine',\n",
       " 'per_tensor_symmetric',\n",
       " 'permute',\n",
       " 'pi',\n",
       " 'pinverse',\n",
       " 'pixel_shuffle',\n",
       " 'pixel_unshuffle',\n",
       " 'platform',\n",
       " 'poisson',\n",
       " 'poisson_nll_loss',\n",
       " 'polar',\n",
       " 'polygamma',\n",
       " 'positive',\n",
       " 'pow',\n",
       " 'prelu',\n",
       " 'prepare_multiprocessing_environment',\n",
       " 'preserve_format',\n",
       " 'prod',\n",
       " 'profiler',\n",
       " 'promote_types',\n",
       " 'put',\n",
       " 'q_per_channel_axis',\n",
       " 'q_per_channel_scales',\n",
       " 'q_per_channel_zero_points',\n",
       " 'q_scale',\n",
       " 'q_zero_point',\n",
       " 'qint32',\n",
       " 'qint8',\n",
       " 'qr',\n",
       " 'qscheme',\n",
       " 'quantile',\n",
       " 'quantization',\n",
       " 'quantize_per_channel',\n",
       " 'quantize_per_tensor',\n",
       " 'quantize_per_tensor_dynamic',\n",
       " 'quantized_batch_norm',\n",
       " 'quantized_gru',\n",
       " 'quantized_gru_cell',\n",
       " 'quantized_lstm',\n",
       " 'quantized_lstm_cell',\n",
       " 'quantized_max_pool1d',\n",
       " 'quantized_max_pool2d',\n",
       " 'quantized_rnn_relu_cell',\n",
       " 'quantized_rnn_tanh_cell',\n",
       " 'quasirandom',\n",
       " 'quint2x4',\n",
       " 'quint4x2',\n",
       " 'quint8',\n",
       " 'rad2deg',\n",
       " 'rad2deg_',\n",
       " 'rand',\n",
       " 'rand_like',\n",
       " 'randint',\n",
       " 'randint_like',\n",
       " 'randn',\n",
       " 'randn_like',\n",
       " 'random',\n",
       " 'randperm',\n",
       " 'range',\n",
       " 'ravel',\n",
       " 'read_vitals',\n",
       " 'real',\n",
       " 'reciprocal',\n",
       " 'reciprocal_',\n",
       " 'relu',\n",
       " 'relu_',\n",
       " 'remainder',\n",
       " 'renorm',\n",
       " 'repeat_interleave',\n",
       " 'reshape',\n",
       " 'resize_as_',\n",
       " 'resize_as_sparse_',\n",
       " 'resolve_conj',\n",
       " 'resolve_neg',\n",
       " 'result_type',\n",
       " 'return_types',\n",
       " 'rnn_relu',\n",
       " 'rnn_relu_cell',\n",
       " 'rnn_tanh',\n",
       " 'rnn_tanh_cell',\n",
       " 'roll',\n",
       " 'rot90',\n",
       " 'round',\n",
       " 'round_',\n",
       " 'row_stack',\n",
       " 'rrelu',\n",
       " 'rrelu_',\n",
       " 'rsqrt',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看pytorch有什么工具箱\n",
    "dir(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54eeb6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Any',\n",
       " 'BFloat16Storage',\n",
       " 'BFloat16Tensor',\n",
       " 'BoolStorage',\n",
       " 'BoolTensor',\n",
       " 'ByteStorage',\n",
       " 'ByteTensor',\n",
       " 'CUDAGraph',\n",
       " 'CharStorage',\n",
       " 'CharTensor',\n",
       " 'ComplexDoubleStorage',\n",
       " 'ComplexFloatStorage',\n",
       " 'CudaError',\n",
       " 'DeferredCudaCallError',\n",
       " 'Device',\n",
       " 'Dict',\n",
       " 'DoubleStorage',\n",
       " 'DoubleTensor',\n",
       " 'Event',\n",
       " 'ExternalStream',\n",
       " 'FloatStorage',\n",
       " 'FloatTensor',\n",
       " 'HalfStorage',\n",
       " 'HalfTensor',\n",
       " 'IntStorage',\n",
       " 'IntTensor',\n",
       " 'List',\n",
       " 'LongStorage',\n",
       " 'LongTensor',\n",
       " 'Optional',\n",
       " 'ShortStorage',\n",
       " 'ShortTensor',\n",
       " 'Stream',\n",
       " 'StreamContext',\n",
       " 'Tuple',\n",
       " 'Union',\n",
       " '_CudaBase',\n",
       " '_CudaDeviceProperties',\n",
       " '_LazySeedTracker',\n",
       " '_StorageBase',\n",
       " '_TypedStorage',\n",
       " '_UntypedStorage',\n",
       " '__annotations__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_check_capability',\n",
       " '_check_cubins',\n",
       " '_cudart',\n",
       " '_device',\n",
       " '_device_t',\n",
       " '_dummy_type',\n",
       " '_get_device_index',\n",
       " '_initialization_lock',\n",
       " '_initialized',\n",
       " '_is_in_bad_fork',\n",
       " '_lazy_call',\n",
       " '_lazy_init',\n",
       " '_lazy_new',\n",
       " '_lazy_seed_tracker',\n",
       " '_queued_calls',\n",
       " '_sleep',\n",
       " '_tls',\n",
       " '_utils',\n",
       " 'amp',\n",
       " 'caching_allocator_alloc',\n",
       " 'caching_allocator_delete',\n",
       " 'can_device_access_peer',\n",
       " 'check_error',\n",
       " 'classproperty',\n",
       " 'collections',\n",
       " 'contextlib',\n",
       " 'cudaStatus',\n",
       " 'cudart',\n",
       " 'current_blas_handle',\n",
       " 'current_device',\n",
       " 'current_stream',\n",
       " 'default_generators',\n",
       " 'default_stream',\n",
       " 'device',\n",
       " 'device_count',\n",
       " 'device_of',\n",
       " 'empty_cache',\n",
       " 'get_arch_list',\n",
       " 'get_device_capability',\n",
       " 'get_device_name',\n",
       " 'get_device_properties',\n",
       " 'get_gencode_flags',\n",
       " 'get_rng_state',\n",
       " 'get_rng_state_all',\n",
       " 'get_sync_debug_mode',\n",
       " 'graph',\n",
       " 'graph_pool_handle',\n",
       " 'graphs',\n",
       " 'has_half',\n",
       " 'has_magma',\n",
       " 'init',\n",
       " 'initial_seed',\n",
       " 'ipc_collect',\n",
       " 'is_available',\n",
       " 'is_bf16_supported',\n",
       " 'is_initialized',\n",
       " 'list_gpu_processes',\n",
       " 'make_graphed_callables',\n",
       " 'manual_seed',\n",
       " 'manual_seed_all',\n",
       " 'max_memory_allocated',\n",
       " 'max_memory_cached',\n",
       " 'max_memory_reserved',\n",
       " 'mem_get_info',\n",
       " 'memory',\n",
       " 'memory_allocated',\n",
       " 'memory_cached',\n",
       " 'memory_reserved',\n",
       " 'memory_snapshot',\n",
       " 'memory_stats',\n",
       " 'memory_stats_as_nested_dict',\n",
       " 'memory_summary',\n",
       " 'memory_usage',\n",
       " 'nccl',\n",
       " 'nvtx',\n",
       " 'os',\n",
       " 'profiler',\n",
       " 'random',\n",
       " 'reset_accumulated_memory_stats',\n",
       " 'reset_max_memory_allocated',\n",
       " 'reset_max_memory_cached',\n",
       " 'reset_peak_memory_stats',\n",
       " 'seed',\n",
       " 'seed_all',\n",
       " 'set_device',\n",
       " 'set_per_process_memory_fraction',\n",
       " 'set_rng_state',\n",
       " 'set_rng_state_all',\n",
       " 'set_stream',\n",
       " 'set_sync_debug_mode',\n",
       " 'sparse',\n",
       " 'stream',\n",
       " 'streams',\n",
       " 'synchronize',\n",
       " 'threading',\n",
       " 'torch',\n",
       " 'traceback',\n",
       " 'utilization',\n",
       " 'warnings']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看torch里面的cuda有什么工具箱,可以看到is_available\n",
    "dir(torch.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94e054ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__closure__',\n",
       " '__code__',\n",
       " '__defaults__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get__',\n",
       " '__getattribute__',\n",
       " '__globals__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__kwdefaults__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__name__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__qualname__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看torch.cuda.is_available里面的工具箱\n",
    "# __双下划线表示里面的是函数变量不可变不可修改\n",
    "dir(torch.cuda.is_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f080cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function is_available in module torch.cuda:\n",
      "\n",
      "is_available() -> bool\n",
      "    Returns a bool indicating if CUDA is currently available.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 查看用法\n",
    "help(torch.cuda.is_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af34402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4de2bb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dataset in module torch.utils.data.dataset:\n",
      "\n",
      "class Dataset(typing.Generic)\n",
      " |  Dataset(*args, **kwds)\n",
      " |  \n",
      " |  An abstract class representing a :class:`Dataset`.\n",
      " |  \n",
      " |  All datasets that represent a map from keys to data samples should subclass\n",
      " |  it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
      " |  data sample for a given key. Subclasses could also optionally overwrite\n",
      " |  :meth:`__len__`, which is expected to return the size of the dataset by many\n",
      " |  :class:`~torch.utils.data.Sampler` implementations and the default options\n",
      " |  of :class:`~torch.utils.data.DataLoader`.\n",
      " |  \n",
      " |  .. note::\n",
      " |    :class:`~torch.utils.data.DataLoader` by default constructs a index\n",
      " |    sampler that yields integral indices.  To make it work with a map-style\n",
      " |    dataset with non-integral indices/keys, a custom sampler must be provided.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dataset\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      " |  \n",
      " |  __getitem__(self, index) -> +T_co\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |  \n",
      " |  __parameters__ = (+T_co,)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __new__(cls, *args, **kwds)\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e511151",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7543db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f85f41c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15],\n",
       "       [16, 17, 18, 19],\n",
       "       [20, 21, 22, 23]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = np.arange(24).reshape((6,4))\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70f9ba3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100, 101, 102, 103],\n",
       "       [104, 105, 106, 107],\n",
       "       [108, 109, 110, 111],\n",
       "       [112, 113, 114, 115],\n",
       "       [116, 117, 118, 119],\n",
       "       [120, 121, 122, 123]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = np.arange(100,124).reshape((6,4))\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e38ff9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100 102 104 106]\n",
      " [108 110 112 114]\n",
      " [116 118 120 122]\n",
      " [124 126 128 130]\n",
      " [132 134 136 138]\n",
      " [140 142 144 146]]\n",
      "[[   0  101  204  309]\n",
      " [ 416  525  636  749]\n",
      " [ 864  981 1100 1221]\n",
      " [1344 1469 1596 1725]\n",
      " [1856 1989 2124 2261]\n",
      " [2400 2541 2684 2829]]\n"
     ]
    }
   ],
   "source": [
    "print(t1+t2)\n",
    "print(t1*t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60ba6f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = np.arange(0,6)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f39c52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5],\n",
       "       [ 6,  7,  8,  9, 10, 11],\n",
       "       [12, 13, 14, 15, 16, 17],\n",
       "       [18, 19, 20, 21, 22, 23]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = np.arange(0,24).reshape(4,6)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a078b7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2,  4,  6,  8, 10],\n",
       "       [ 6,  8, 10, 12, 14, 16],\n",
       "       [12, 14, 16, 18, 20, 22],\n",
       "       [18, 20, 22, 24, 26, 28]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 + t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6714591a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = np.arange(4).reshape(4,1)\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dfb4b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5],\n",
       "       [ 7,  8,  9, 10, 11, 12],\n",
       "       [14, 15, 16, 17, 18, 19],\n",
       "       [21, 22, 23, 24, 25, 26]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 + t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26ee9fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3],[4,5,6]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84d2e55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(a,[7,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f43e010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3],\n",
       "       [ 4,  5,  6],\n",
       "       [ 7,  8,  9],\n",
       "       [10, 11, 12]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(a,[[7,8,9],[10,11,12]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3cc00952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 5, 5],\n",
       "       [4, 5, 6, 6, 6]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(a,[[5,5],[6,6]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8488ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1707e-18, 7.0952e+22, 1.7748e+28],\n",
       "        [1.8176e+31, 7.2708e+31, 5.0778e+31],\n",
       "        [3.2608e-12, 1.7728e+28, 7.0367e+22],\n",
       "        [2.1715e-18, 2.1161e-07, 6.7126e-07],\n",
       "        [8.2733e+20, 3.3237e+21, 1.6520e-04]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.empty(5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9f987cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4497, 0.4502, 0.6884],\n",
       "        [0.5651, 0.7263, 0.4247],\n",
       "        [0.9453, 0.1676, 0.7574],\n",
       "        [0.0711, 0.5405, 0.4692],\n",
       "        [0.9445, 0.9967, 0.1637]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cd20bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(5,3,dtype=torch.long)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6115ed5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5000, 3.0000])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([5.5000,3.0000])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "349e4a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.new_ones(5,3,dtype=torch.double)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63bb6bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7572, 0.7440, 0.3584],\n",
       "        [0.5905, 0.9170, 0.9294],\n",
       "        [0.4617, 0.9569, 0.8635],\n",
       "        [0.7150, 0.7602, 0.6920],\n",
       "        [0.0264, 0.6339, 0.0375]], dtype=torch.float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand_like(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e0fa096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7a61db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Size([5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c7c70f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2677, 0.1299, 0.1890],\n",
       "        [0.6326, 0.1407, 0.3221],\n",
       "        [0.3323, 0.8445, 0.7135],\n",
       "        [0.0367, 0.9599, 0.2367],\n",
       "        [0.4054, 0.4392, 0.3517]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(5,3)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c64b8d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0250, 0.8739, 0.5474],\n",
       "        [1.2231, 1.0577, 1.2514],\n",
       "        [0.7940, 1.8014, 1.5770],\n",
       "        [0.7517, 1.7201, 0.9288],\n",
       "        [0.4319, 1.0731, 0.3892]], dtype=torch.float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f8fcf9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0250, 0.8739, 0.5474],\n",
       "        [1.2231, 1.0577, 1.2514],\n",
       "        [0.7940, 1.8014, 1.5770],\n",
       "        [0.7517, 1.7201, 0.9288],\n",
       "        [0.4319, 1.0731, 0.3892]], dtype=torch.float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec00c92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1299, 0.4633],\n",
       "        [0.2712, 0.2878],\n",
       "        [0.4780, 0.7575],\n",
       "        [0.1674, 0.1296],\n",
       "        [0.7508, 0.2605],\n",
       "        [0.8407, 0.2996],\n",
       "        [0.9600, 0.6874],\n",
       "        [0.5020, 0.1798]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(4,4)\n",
    "y = x.view(16)\n",
    "z = y.view(8,2)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b136003a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4848886728286743"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "x.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b612830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "torch.randn??\n",
    "torch.ones??\n",
    "torch.full??\n",
    "F.mse_loss??\n",
    "torch.autograd.grad??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "52583792",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'float64' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31968/3613651605.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 对 pred = xw + b进行求导,初始化 x=1,w=2,b=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# mse_loss第一参数是预测的值，第二个参数是真实值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'float64' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# 对 pred = xw + b进行求导,初始化 x=1,w=2,b=0\n",
    "x = torch.ones(1)\n",
    "w = torch.full([1],2)\n",
    "\n",
    "# mse_loss第一参数是预测的值，第二个参数是真实值\n",
    "MSE = F.mse_loss(x*w,torch.ones(1)) # MSE = 1\n",
    "\n",
    "# 表示MSE对w求导\n",
    "torch.autograd.grad(MSE,[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "74175e13",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Float but expected Double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31968/1023121536.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 表示MSE对w求导\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#torch.autograd.grad(MSE,[w])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mMSE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found dtype Float but expected Double"
     ]
    }
   ],
   "source": [
    "#w.requires_grad_()\n",
    "w.requires_grad_() # tensor([2.], requires_grad=True) 设置w的梯度 不然会报错\n",
    "MSE = F.mse_loss(x*w,torch.ones(1)) # MSE = 1\n",
    "# 表示MSE对w求导\n",
    "#torch.autograd.grad(MSE,[w])\n",
    "MSE.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "93f8d5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9514]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x的特征有10个\n",
    "x = torch.randn(1,10)\n",
    "w = torch.randn(1,10,requires_grad=True)\n",
    "o = torch.sigmoid(x@w.t()) # t()表示转置，答案是一个数\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c4f5bc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0058,  0.0020, -0.0031, -0.0031, -0.0013, -0.0009,  0.0004,  0.0009,\n",
       "          0.0035,  0.0066]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = F.mse_loss(torch.ones(1,1),o)\n",
    "loss.backward()\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "12e83cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape\n",
    "x.t().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4b864a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000e+00, 1.6655e-34, 7.4564e-25, 3.3382e-15, 1.4945e-05, 9.9999e-01,\n",
       "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.linspace(-100,100,10)\n",
    "torch.sigmoid(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "35a90e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0561,  0.0070,  0.0154,  0.1262,  0.0777, -0.0880,  0.2638, -0.1206,\n",
       "         -0.1128,  0.1552],\n",
       "        [ 0.0378,  0.0047,  0.0104,  0.0851,  0.0524, -0.0593,  0.1778, -0.0813,\n",
       "         -0.0760,  0.1046]])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "x = torch.randn(1,10) # 1行10列\n",
    "w = torch.randn(2,10,requires_grad=True) # 2行10列\n",
    "o = torch.sigmoid(x@w.t()) # @这个符号表示是按照矩阵运算的乘积的形式，不是单纯的对应元素相乘。所以o是一个1行2列的数torch.Size([1, 2])\n",
    "loss = F.mse_loss(torch.ones(1,2),o)\n",
    "loss.backward() # 对权值w求导\n",
    "w.grad # 取出对w求导后的值，2行10列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "bf3cfd1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 链式法则验证\n",
    "x = torch.tensor(1.)\n",
    "w1 = torch.tensor(2.,requires_grad=True)\n",
    "b1 = torch.tensor(1.)\n",
    "w2 = torch.tensor(2.,requires_grad=True)\n",
    "b2 = torch.tensor(1.)\n",
    "\n",
    "y1 = x * w1 + b1\n",
    "y2 = y1 * w2 + b2\n",
    "\n",
    "# y2对y1求导\n",
    "dy2_dy1 = torch.autograd.grad(y2,[y1],retain_graph=True)[0]\n",
    "# y1对w1求导\n",
    "dy1_dw1 = torch.autograd.grad(y1,[w1],retain_graph=True)[0]\n",
    "# y2直接对W1求导\n",
    "dy2_dw1 = torch.autograd.grad(y2,[w1],retain_graph=True)[0]\n",
    "\n",
    "# 看两者是否相同\n",
    "dy2_dw1 == dy2_dy1 * dy1_dw1 # 返回true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "900d9f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "09a0d0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.,2.])\n",
    "# print(type(x.item()))\n",
    "print(x.data[1])\n",
    "print(x.numpy()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "a5fbf0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([1,2,3.], requires_grad = True)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0b779885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "b = a.data\n",
    "print(b.requires_grad)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "15c19f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor([1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "c = a.detach()\n",
    "print(c.requires_grad)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "30f494a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], requires_grad=True)\n",
      "tensor([0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3.], requires_grad = True)\n",
    "c = a.data  # 需要走注意的是，通过.data “分离”得到的的变量会和原来的变量共用同样的数据，而且新分离得到的张量是不可求导的，c发生了变化，原来的张量也会发生变化\n",
    "print(a) # tensor([1., 2., 3.], requires_grad=True)\n",
    "c.zero_() # c发生变化\n",
    "print(a) # tensor([0., 0., 0.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "baf6be58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], requires_grad=True)\n",
      "tensor([0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3.], requires_grad = True)\n",
    "c = a.detach()  # 需要走注意的是，通过.data “分离”得到的的变量会和原来的变量共用同样的数据，而且新分离得到的张量是不可求导的，c发生了变化，原来的张量也会发生变化\n",
    "print(a) # tensor([1., 2., 3.], requires_grad=True)\n",
    "c.zero_() # c发生变化\n",
    "print(a) # tensor([0., 0., 0.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e230cfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor([0., 0., 0.])\n",
      "True\n",
      "tensor([0., 0., 0.], grad_fn=<SigmoidBackward0>)\n",
      "----------------------------------------------\n",
      "tensor([0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    " \n",
    "a = torch.tensor([1,2,3.], requires_grad = True)\n",
    "out = a.sigmoid()\n",
    "c = out.data  # 需要走注意的是，通过.data “分离”得到的的变量会和原来的变量共用同样的数据，而且新分离得到的张量是不可求导的，c发生了变化，原来的张量也会发生变化\n",
    "c.zero_()     # 改变c的值，原来的out也会改变\n",
    "print(c.requires_grad)\n",
    "print(c)\n",
    "print(out.requires_grad)\n",
    "print(out)\n",
    "print(\"----------------------------------------------\")\n",
    "out.sum().backward() # 对原来的out求导，\n",
    "print(a.grad)  # 不会报错，但是结果却并不正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "244242e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "tensor([0., 0., 0.])\n",
      "True\n",
      "tensor([0., 0., 0.], grad_fn=<SigmoidBackward0>)\n",
      "----------------------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [3]], which is output 0 of SigmoidBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31968/3211141522.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 对原来的out求导，\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 此时会报错，错误结果参考下面,显示梯度计算所需要的张量已经被“原位操作inplace”所更改了。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [3]], which is output 0 of SigmoidBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True)."
     ]
    }
   ],
   "source": [
    "import torch\n",
    " \n",
    "a = torch.tensor([1,2,3.], requires_grad = True)\n",
    "out = a.sigmoid()\n",
    "c = out.detach()  # 需要走注意的是，通过.detach() “分离”得到的的变量会和原来的变量共用同样的数据，而且新分离得到的张量是不可求导的，c发生了变化，原来的张量也会发生变化\n",
    "c.zero_()     # 改变c的值，原来的out也会改变\n",
    "print(c.requires_grad)\n",
    "print(c)\n",
    "print(out.requires_grad)\n",
    "print(out)\n",
    "print(\"----------------------------------------------\")\n",
    " \n",
    "out.sum().backward() # 对原来的out求导，\n",
    "print(a.grad)  # 此时会报错，错误结果参考下面,显示梯度计算所需要的张量已经被“原位操作inplace”所更改了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e53b7ee",
   "metadata": {},
   "source": [
    "# 交叉熵测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c4c69395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37797814 0.34200877 0.28001309]\n",
      "0.9729189131256584\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 真实值\n",
    "y = np.array([1,0,0])\n",
    "# 输出值\n",
    "z = np.array([0.2,0.1,-0.1])\n",
    "# 输出值先经过softmax\n",
    "y_pred = np.exp(z) / np.exp(z).sum() # 概率之和为1\n",
    "print(y_pred)\n",
    "loss = (-y * np.log(y_pred)).sum()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "69aad067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9729189157226387"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(0.37797814)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4e44b9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9729)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "y = torch.LongTensor([0])\n",
    "z = torch.Tensor([[0.2,0.1,-0.1]])\n",
    "# 不用再经过softmax，已经包含在CrossEntropyLoss里面了\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "loss = criterion(z,y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6cd434e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1= tensor(0.4966) \n",
      "loss2= tensor(1.2389)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "# 真实值\n",
    "# longtensor表示的是第几个标签分类，第一个真实的标签是第2个类别，第二个真实标签是第0个类别，第三个真实标签是第1个类别\n",
    "Y = torch.LongTensor([2,0,1])\n",
    "# 预测值，线性层输出。没有经过Softmax\n",
    "Y_pred1 = torch.tensor([[0.1,0.2,0.9],[1.1,0.1,0.2],[0.2,2.1,0.1]])\n",
    "Y_pred2 = torch.tensor([[0.8,0.2,0.3],[0.2,0.3,0.5],[0.2,0.2,0.5]])\n",
    "\n",
    "l1 = criterion(Y_pred1,Y)\n",
    "l2 = criterion(Y_pred2,Y)\n",
    "\n",
    "print(\"loss1=\",l1.data,\"\\nloss2=\",l2.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3cfa63bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1= tensor(1.7633) \n",
      "loss2= tensor(0.9389)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "# 真实值\n",
    "# longtensor表示的是第几个标签分类，第一个真实的标签是第0个类别，第二个真实标签是第1个类别，第三个真实标签是第2个类别\n",
    "Y = torch.LongTensor([0,1,2])\n",
    "# 预测值，线性层输出。没有经过Softmax\n",
    "Y_pred1 = torch.tensor([[0.1,0.2,0.9],[1.1,0.1,0.2],[0.2,2.1,0.1]])\n",
    "Y_pred2 = torch.tensor([[0.8,0.2,0.3],[0.2,0.3,0.5],[0.2,0.2,0.5]])\n",
    "\n",
    "l1 = criterion(Y_pred1,Y)\n",
    "l2 = criterion(Y_pred2,Y)\n",
    "\n",
    "print(\"loss1=\",l1.data,\"\\nloss2=\",l2.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8914b595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
