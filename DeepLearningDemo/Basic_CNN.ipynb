{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb889fa",
   "metadata": {},
   "source": [
    "# 基础的卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15d90e2",
   "metadata": {},
   "source": [
    "## 基本卷积的构成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1be26b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# 输入通道和输出通道\n",
    "in_channels,out_channels = 5,10\n",
    "# 图像的宽高\n",
    "width,height = 100,100\n",
    "# 卷积核大小\n",
    "kernel_size = 3\n",
    "# pytorch里面的数据必须是小批量的数据\n",
    "batch_size = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320800bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-8.4643e-01, -5.8046e-01,  1.6872e+00,  ..., -8.2302e-01,\n",
       "           -5.5077e-01,  6.6146e-01],\n",
       "          [-1.0910e+00,  1.4095e+00,  6.3339e-01,  ...,  1.7499e+00,\n",
       "           -6.5943e-01, -1.6500e+00],\n",
       "          [ 4.7274e-01, -3.8538e-01,  4.3977e-01,  ..., -4.5004e-01,\n",
       "           -1.0148e+00,  2.1304e-01],\n",
       "          ...,\n",
       "          [-1.8466e+00,  9.1769e-01,  9.4826e-01,  ...,  9.1058e-01,\n",
       "            1.3262e+00,  2.9851e+00],\n",
       "          [-4.8437e-01,  6.7868e-01, -1.1628e+00,  ..., -9.3004e-01,\n",
       "           -6.7007e-02,  3.0856e-01],\n",
       "          [ 2.4550e-01,  1.3549e+00,  7.7241e-01,  ..., -1.2235e+00,\n",
       "           -1.1682e+00, -6.2993e-01]],\n",
       "\n",
       "         [[ 3.4457e-01,  7.0932e-01,  5.0585e-01,  ..., -1.3123e+00,\n",
       "            6.3619e-01, -3.1562e+00],\n",
       "          [ 6.4439e-01, -1.3469e-01,  1.2464e+00,  ...,  8.0558e-01,\n",
       "           -7.1414e-01,  2.7259e-04],\n",
       "          [ 1.1583e+00, -1.4840e-01,  1.0533e+00,  ...,  7.1159e-01,\n",
       "            1.5288e+00, -4.1921e-02],\n",
       "          ...,\n",
       "          [ 1.4913e-01,  9.0364e-02, -1.5631e-01,  ...,  1.1383e-02,\n",
       "            6.0947e-01, -1.6851e-01],\n",
       "          [-1.7456e+00,  5.2861e-01, -1.9975e+00,  ...,  3.0119e-01,\n",
       "           -1.5209e+00, -2.7313e-01],\n",
       "          [-5.9485e-01,  2.2168e+00,  7.9720e-01,  ..., -2.1770e+00,\n",
       "           -1.2745e+00,  7.4255e-01]],\n",
       "\n",
       "         [[ 3.2122e-01,  2.0423e+00, -2.7626e-01,  ...,  1.2977e+00,\n",
       "           -1.0853e+00,  1.2359e+00],\n",
       "          [ 3.2911e-01,  5.0245e-01, -4.7968e-01,  ...,  1.0190e+00,\n",
       "            1.2016e+00, -1.3868e+00],\n",
       "          [ 1.0706e+00, -1.5791e+00,  2.1170e+00,  ...,  9.7166e-01,\n",
       "           -1.4821e+00, -1.0683e+00],\n",
       "          ...,\n",
       "          [ 1.3758e+00, -7.7870e-01,  1.1560e+00,  ..., -5.4622e-01,\n",
       "           -1.2637e+00, -3.7681e-01],\n",
       "          [-1.1231e+00,  5.9802e-01,  5.7897e-01,  ..., -1.5196e-02,\n",
       "           -2.0114e+00, -6.8653e-01],\n",
       "          [-1.8381e+00, -1.4234e+00, -1.9261e+00,  ..., -1.0358e+00,\n",
       "            1.8230e-01,  2.3640e-01]],\n",
       "\n",
       "         [[ 1.0686e+00,  6.9975e-01, -7.0747e-01,  ..., -1.4940e-01,\n",
       "           -1.3679e+00, -3.4927e-01],\n",
       "          [ 1.8537e+00, -1.8620e-01,  1.3690e+00,  ..., -1.0491e-01,\n",
       "           -7.3021e-01,  1.5235e+00],\n",
       "          [ 3.4346e-01, -2.2876e-01,  7.4815e-01,  ..., -3.1348e-01,\n",
       "            1.6505e+00,  1.0321e+00],\n",
       "          ...,\n",
       "          [ 5.6523e-01,  2.0585e+00, -9.3083e-01,  ..., -1.5126e-02,\n",
       "            7.5597e-01, -2.3328e+00],\n",
       "          [-1.8275e-01, -1.6407e-01,  6.2423e-01,  ..., -1.2411e+00,\n",
       "            1.7636e+00,  1.8907e+00],\n",
       "          [ 1.3275e+00,  2.6449e-01, -2.0654e-01,  ..., -9.6388e-01,\n",
       "            1.7118e+00,  1.7000e-01]],\n",
       "\n",
       "         [[-6.9893e-01,  2.6920e-01,  2.9073e-01,  ...,  6.0906e-01,\n",
       "           -5.8419e-01, -3.3515e-01],\n",
       "          [ 1.0334e+00,  1.4692e+00, -1.0206e+00,  ...,  1.6194e+00,\n",
       "           -4.8379e-01, -1.2056e-01],\n",
       "          [-2.3136e+00,  5.8423e-01,  1.0165e+00,  ..., -1.7784e+00,\n",
       "           -1.1522e+00, -4.1670e-01],\n",
       "          ...,\n",
       "          [ 7.9995e-01, -7.6983e-01, -4.2495e-01,  ...,  3.9271e-01,\n",
       "            1.7446e+00,  1.4966e+00],\n",
       "          [ 6.7201e-02, -7.9398e-01, -5.4365e-01,  ...,  7.7361e-01,\n",
       "           -1.4494e+00, -1.2931e+00],\n",
       "          [-2.5572e+00,  5.7613e-01,  5.0046e-01,  ..., -7.8325e-01,\n",
       "           -9.6061e-01, -7.8469e-01]]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 输入的图像张量\n",
    "input = torch.randn(batch_size,in_channels,width,height)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf28af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 卷积生成,2维卷积层\n",
    "conv_layer = torch.nn.Conv2d(in_channels=in_channels,out_channels=out_channels,kernel_size=kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ec2f824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.3372e-01, -2.5594e-01,  1.8515e-01,  ...,  7.7881e-01,\n",
       "           -2.4440e-02, -1.8127e-02],\n",
       "          [ 4.3289e-01, -2.7195e-01,  6.4697e-01,  ..., -3.1034e-01,\n",
       "            6.6424e-02, -8.8279e-01],\n",
       "          [ 4.9335e-01, -3.5963e-01,  2.7641e-01,  ..., -1.6746e-01,\n",
       "            2.5143e-01,  5.2255e-01],\n",
       "          ...,\n",
       "          [ 2.7859e-01, -9.2822e-01,  2.1141e-01,  ..., -4.6467e-01,\n",
       "            4.6481e-01, -4.1446e-01],\n",
       "          [-6.0661e-01,  4.8515e-01, -2.9640e-01,  ..., -1.0958e-01,\n",
       "            7.5240e-01,  1.1881e+00],\n",
       "          [-3.4446e-01,  1.8836e-03,  3.0658e-01,  ..., -8.2286e-01,\n",
       "           -4.8712e-01,  3.0689e-01]],\n",
       "\n",
       "         [[ 2.5905e-01,  1.8637e-01, -1.0172e+00,  ...,  8.1164e-01,\n",
       "            2.6819e-01,  1.1422e+00],\n",
       "          [-2.6802e-01, -1.6541e-01, -3.1709e-01,  ..., -3.8122e-01,\n",
       "            5.2809e-01, -9.6966e-01],\n",
       "          [ 5.9662e-01,  8.8899e-01,  3.9614e-01,  ..., -6.5002e-01,\n",
       "            5.9954e-01,  8.6902e-01],\n",
       "          ...,\n",
       "          [-5.8163e-01, -7.6744e-01, -3.3735e-01,  ...,  1.5308e-01,\n",
       "            5.4775e-01, -1.4009e-01],\n",
       "          [-4.0383e-01, -1.1685e-01,  1.4146e-01,  ..., -7.3041e-02,\n",
       "            2.4872e-01, -1.2538e+00],\n",
       "          [ 2.1501e+00,  3.3045e-01, -3.6177e-01,  ..., -4.1802e-02,\n",
       "           -1.8776e-01,  6.1146e-02]],\n",
       "\n",
       "         [[ 1.2030e+00, -2.8316e-01,  4.8968e-01,  ...,  5.3886e-01,\n",
       "           -1.0091e+00, -2.3986e-01],\n",
       "          [ 4.2609e-01, -2.5235e-01, -4.5424e-02,  ..., -5.5195e-02,\n",
       "           -7.3099e-02,  5.2135e-01],\n",
       "          [ 9.0216e-01,  1.2864e+00, -1.6986e-01,  ...,  4.3049e-01,\n",
       "           -9.3870e-02,  3.2818e-01],\n",
       "          ...,\n",
       "          [ 1.3368e-01,  9.1802e-01, -4.8551e-01,  ..., -2.2639e-01,\n",
       "           -1.1049e+00,  1.3585e+00],\n",
       "          [-3.5544e-01,  3.9422e-01, -7.9795e-02,  ...,  5.9692e-01,\n",
       "            2.3982e-01, -2.7046e-01],\n",
       "          [-4.1692e-01,  1.0854e+00,  8.4824e-01,  ..., -5.5409e-01,\n",
       "           -1.1363e-01, -3.0331e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.6579e-01, -1.0115e+00,  1.0321e+00,  ...,  6.7475e-02,\n",
       "            2.4950e-01, -8.0853e-01],\n",
       "          [ 5.1199e-01, -9.3922e-01, -2.1131e-01,  ..., -4.4539e-01,\n",
       "           -1.2669e+00,  2.9458e-01],\n",
       "          [ 3.7444e-01, -3.7101e-01, -6.8699e-01,  ..., -2.9313e-01,\n",
       "            1.9608e-01, -9.9678e-01],\n",
       "          ...,\n",
       "          [ 1.0764e+00,  6.0794e-01, -3.2487e-01,  ..., -6.9814e-01,\n",
       "           -5.1459e-01,  2.8272e-01],\n",
       "          [-1.1770e-01, -2.9361e-01,  4.7704e-01,  ..., -2.8644e-01,\n",
       "           -1.6128e-01,  1.2612e+00],\n",
       "          [-8.6535e-01, -6.8205e-01, -2.9181e-01,  ...,  9.2972e-01,\n",
       "            6.1343e-01, -3.5370e-01]],\n",
       "\n",
       "         [[-7.6737e-01, -2.0266e-01,  7.0759e-01,  ...,  9.6809e-02,\n",
       "            1.0691e-02, -7.7689e-01],\n",
       "          [-6.8584e-02, -2.1069e-01,  1.7862e-01,  ...,  2.5965e-01,\n",
       "           -2.0627e-01, -5.0271e-02],\n",
       "          [ 1.9980e+00, -7.3443e-02, -7.3524e-01,  ...,  2.4617e-01,\n",
       "           -3.9100e-01,  1.3318e+00],\n",
       "          ...,\n",
       "          [ 1.5325e-01, -4.5631e-01,  3.3369e-01,  ..., -1.5376e+00,\n",
       "            1.2598e-01,  3.0764e-01],\n",
       "          [ 8.1615e-01,  1.7285e-01, -9.7447e-02,  ...,  3.5682e-01,\n",
       "           -6.9760e-01, -4.2378e-01],\n",
       "          [ 5.4316e-01,  8.9017e-01,  8.6019e-01,  ..., -5.0799e-01,\n",
       "           -4.4856e-01, -5.0444e-02]],\n",
       "\n",
       "         [[-5.1158e-01,  3.7566e-01, -2.8984e-01,  ..., -1.6237e+00,\n",
       "            1.0416e-01,  5.0158e-01],\n",
       "          [-4.9337e-01,  9.5377e-01, -1.3980e+00,  ...,  6.1118e-01,\n",
       "           -5.6773e-01, -5.1856e-01],\n",
       "          [-4.3635e-01, -2.2445e-02,  3.4923e-01,  ...,  2.3797e-01,\n",
       "           -4.6444e-01,  7.7947e-02],\n",
       "          ...,\n",
       "          [-4.8070e-01, -2.8349e-01, -1.0468e-01,  ...,  2.0444e-01,\n",
       "            5.1466e-01, -4.3659e-01],\n",
       "          [-2.3843e-01,  1.5580e-01, -2.2543e-02,  ..., -2.0205e-01,\n",
       "           -3.5609e-01, -8.2094e-01],\n",
       "          [ 3.9394e-01, -1.1079e+00,  5.5257e-02,  ..., -2.7391e-01,\n",
       "            7.3004e-01,  3.1457e-01]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 把input数据传给卷积层\n",
    "output = conv_layer(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c603f946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 100, 100])\n",
      "torch.Size([1, 10, 98, 98])\n",
      "torch.Size([10, 5, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(input.shape) # 输入是5个通道，100 * 100\n",
    "print(output.shape) # 输出是10个通道，98 * 98\n",
    "print(conv_layer.weight.shape) # 卷积层权重的形状，10是输出的通道，表示10组卷积核，5是输入通道，表示每组里有5个3*3卷积核，5也可以表示卷积核的channel\n",
    "\n",
    "# 卷积层并不在意输入的数据张量，你图像大，将来输出也大，你图像小，将来输出也小\n",
    "# 它在意的是输入层的channel和卷积层的channel必须一致"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464df1a6",
   "metadata": {},
   "source": [
    "## 填充 padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f9aefab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 6, 5, 7, 2, 4, 6, 8, 2, 1, 6, 7, 8, 4, 9, 7, 4, 6, 2, 3, 7, 5, 4, 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "input = [ 3 ,4 ,6 ,5 ,7,\n",
    "2 ,4 ,6 ,8, 2,\n",
    "1 ,6 ,7 ,8 ,4,\n",
    "9 ,7 ,4 ,6, 2,\n",
    "3, 7 ,5 ,4, 1]\n",
    "\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa9b64d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3., 4., 6., 5., 7.],\n",
       "          [2., 4., 6., 8., 2.],\n",
       "          [1., 6., 7., 8., 4.],\n",
       "          [9., 7., 4., 6., 2.],\n",
       "          [3., 7., 5., 4., 1.]]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view第一个参数表示batch，第二个表示channel,其他是宽度和高度\n",
    "input = torch.Tensor(input).view(1,1,5,5)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f9978f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding=1表示输出层外面填充了一圈0\n",
    "conv_layer = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,padding=1,bias=False)\n",
    "conv_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05519b8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 2., 3.],\n",
       "          [4., 5., 6.],\n",
       "          [7., 8., 9.]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view第一个参数表示输入的通道数，第二个参数表示输出的通道数\n",
    "kernel = torch.Tensor([1,2,3,4,5,6,7,8,9]).view(1,1,3,3)\n",
    "# 卷积层权重的初始化\n",
    "conv_layer.weight.data = kernel.data\n",
    "conv_layer.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1da6745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 91., 168., 224., 215., 127.],\n",
      "          [114., 211., 295., 262., 149.],\n",
      "          [192., 259., 282., 214., 122.],\n",
      "          [194., 251., 253., 169.,  86.],\n",
      "          [ 96., 112., 110.,  68.,  31.]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# padding=1输出是5*5的矩阵，padding=0输出是3*3的矩阵\n",
    "output = conv_layer(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e5a44a",
   "metadata": {},
   "source": [
    "## 添加stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8af26fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[211., 262.],\n",
      "          [251., 169.]]]], grad_fn=<ConvolutionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "input = [ 3 ,4 ,6 ,5 ,7,\n",
    "2 ,4 ,6 ,8, 2,\n",
    "1 ,6 ,7 ,8 ,4,\n",
    "9 ,7 ,4 ,6, 2,\n",
    "3, 7 ,5 ,4, 1]\n",
    "\n",
    "# view第一个参数表示batch，第二个表示channel,其他是宽度和高度\n",
    "input = torch.Tensor(input).view(1,1,5,5)\n",
    "\n",
    "# stride=2,表示卷积核向前移动2格进行扫描\n",
    "conv_layer = torch.nn.Conv2d(in_channels=1,out_channels=1,kernel_size=3,stride=2,bias=False)\n",
    "\n",
    "# view第一个参数表示输入的通道数，第二个参数表示输出的通道数\n",
    "kernel = torch.Tensor([1,2,3,4,5,6,7,8,9]).view(1,1,3,3)\n",
    "# 卷积层权重的初始化\n",
    "conv_layer.weight.data = kernel.data\n",
    "\n",
    "# 最后输出是 2 * 2 矩阵 \n",
    "output = conv_layer(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ec5a1f",
   "metadata": {},
   "source": [
    "## 下采样"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f3fccb",
   "metadata": {},
   "source": [
    "下采样用的比较多的是MaxPooling，最大池化层，它是没有权重的\n",
    "比如 2 * 2 的MaxPooling，默认 stride=2,相当于把图像分成 2 * 2 一组\n",
    "池化的时候，batch和channel是不会变的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe1b546d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[4., 8.],\n",
      "          [9., 8.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input = [3,4,6,5,\n",
    "        2,4,6,8,\n",
    "        1,6,7,8,\n",
    "        9,7,4,6]\n",
    "\n",
    "input = torch.Tensor(input).view(1,1,4,4)\n",
    "\n",
    "maxpooling_layer = torch.nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "output = maxpooling_layer(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e10b5c8",
   "metadata": {},
   "source": [
    "## 卷积神经网络基本应用"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84c46fa1",
   "metadata": {},
   "source": [
    "### 准备数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8aa02e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "batch_size = 64\n",
    "# 使用torch把图像转化为tensor,图像 c * w * h\n",
    "# 把单通道转换成多通道，把一系列的图像进行转换，变成 [0,1]之间。0.1307是均值，0.3081是标准差\n",
    "# 使用Normalize也是希望像素值满足 0 1 分布\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,),(0.3081,))])\n",
    "# 变换好之后直接放进数据集里\n",
    "train_dataset = datasets.MNIST(root='./dataset/mnist',train=True,download=True,transform=transform)\n",
    "train_loader = DataLoader(train_dataset,shuffle=True,batch_size=batch_size)\n",
    "test_dataset = datasets.MNIST(root='./dataset/mnist',train=False,download=True,transform=transform)\n",
    "test_loader = DataLoader(test_dataset,shuffle=False,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167a3d80",
   "metadata": {},
   "source": [
    "### 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2f1c757",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        # 由1个通道变成10个\n",
    "        self.conv1 = torch.nn.Conv2d(1,10,kernel_size=5)\n",
    "        # 由10个通道变成20个\n",
    "        self.conv2 = torch.nn.Conv2d(10,20,kernel_size=5)\n",
    "        # 池化层\n",
    "        self.pooling = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # 最后一层是线性层，320是最后算出来的，输出10维\n",
    "        self.fc = torch.nn.Linear(320,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # 铺平数据，data from (n,1,28,28) to (n,748)\n",
    "        batch_size = x.size(0)\n",
    "        x = self.pooling(F.relu(self.conv1(x)))\n",
    "        x = self.pooling(F.relu(self.conv2(x)))\n",
    "        x = x.view(batch_size,-1) # flatten\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    \n",
    "model = Net()\n",
    "\n",
    "# 把模型迁移到GPU上进行计算\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97078465",
   "metadata": {},
   "source": [
    "### 构造损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce104398",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.01,momentum=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34774483",
   "metadata": {},
   "source": [
    "### 构造训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f345b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx,data in enumerate(train_loader,0):\n",
    "        inputs,target = data\n",
    "        # 把inputs,target都迁移到GPU中\n",
    "        # inputs,target = inputs.to(device),target.to(device)\n",
    "        # 优化器在优化之前先清零\n",
    "        optimizer.zero_grad()\n",
    "        # forward backward update\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        # 每300输出一次\n",
    "        if batch_idx % 300 == 299:\n",
    "            print('[%d,%5d] loss:%.3f' % (epoch+1,batch_idx+1,running_loss/300))\n",
    "            # 每300一组数据跑完，清零\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266283cd",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3419e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test里面不需要计算反向传播，只需要计算正向的就行了\n",
    "def test():\n",
    "    # 表示正确了多少\n",
    "    correct = 0\n",
    "    # 表示总数有多少\n",
    "    total = 0\n",
    "    # 在test过程中是不需要计算梯度的\n",
    "    # 这部分的代码不会求导\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images,labels = data\n",
    "            # 把数据迁移到GPU上\n",
    "            # images,labels = images.to(device),labels.to(device)\n",
    "            outputs = model(images)\n",
    "            # dim=1 返回每一个行的最大值和索引\n",
    "            # dim=0 返回每一列的最大值和索引\n",
    "            # 这里的索引或者下标对应的是它的分类\n",
    "            _,predicted = torch.max(outputs.data,dim=1)\n",
    "            # label是一个元组，(N,1)\n",
    "            # size是计算元素的个数，0表示计算行数，1表示计算列数\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted==labels).sum().item()\n",
    "            \n",
    "    # 使用正确的数除以总数\n",
    "    print('Accuracy on test set: %d %%' % (100 * correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da57651c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  300] loss:0.640\n",
      "[1,  600] loss:0.203\n",
      "[1,  900] loss:0.142\n",
      "Accuracy on test set: 96 %\n",
      "[2,  300] loss:0.110\n",
      "[2,  600] loss:0.096\n",
      "[2,  900] loss:0.094\n",
      "Accuracy on test set: 97 %\n",
      "[3,  300] loss:0.081\n",
      "[3,  600] loss:0.070\n",
      "[3,  900] loss:0.076\n",
      "Accuracy on test set: 97 %\n",
      "[4,  300] loss:0.066\n",
      "[4,  600] loss:0.062\n",
      "[4,  900] loss:0.060\n",
      "Accuracy on test set: 98 %\n",
      "[5,  300] loss:0.062\n",
      "[5,  600] loss:0.051\n",
      "[5,  900] loss:0.054\n",
      "Accuracy on test set: 98 %\n",
      "[6,  300] loss:0.048\n",
      "[6,  600] loss:0.051\n",
      "[6,  900] loss:0.048\n",
      "Accuracy on test set: 98 %\n",
      "[7,  300] loss:0.043\n",
      "[7,  600] loss:0.045\n",
      "[7,  900] loss:0.047\n",
      "Accuracy on test set: 98 %\n",
      "[8,  300] loss:0.041\n",
      "[8,  600] loss:0.041\n",
      "[8,  900] loss:0.043\n",
      "Accuracy on test set: 98 %\n",
      "[9,  300] loss:0.040\n",
      "[9,  600] loss:0.038\n",
      "[9,  900] loss:0.036\n",
      "Accuracy on test set: 98 %\n",
      "[10,  300] loss:0.034\n",
      "[10,  600] loss:0.038\n",
      "[10,  900] loss:0.035\n",
      "Accuracy on test set: 98 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    # 一轮训练\n",
    "    train(epoch)\n",
    "    # 一轮测试\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b12842",
   "metadata": {},
   "source": [
    "### 总结\n",
    "之前22轮才能达到98%，现在只需要6轮就能达到98%，模型确实大大改进了许多"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
